{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions in Deep Learning: Complete Mathematical Guide\n",
    "\n",
    "This notebook provides a comprehensive mathematical explanation of loss functions, logits, probability distributions, and their applications in machine learning and deep learning.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction and Mathematical Foundations](#introduction)\n",
    "2. [Logits and Probability Theory](#logits)\n",
    "3. [Binary Classification and Cross-Entropy](#binary)\n",
    "4. [Multiclass Classification and Softmax](#multiclass)\n",
    "5. [Regression Loss Functions](#regression)\n",
    "6. [Information Theory and Loss Functions](#information-theory)\n",
    "7. [Probabilistic Interpretation of Loss Functions](#probabilistic)\n",
    "8. [Advanced Loss Functions](#advanced)\n",
    "9. [Numerical Stability and Implementation](#stability)\n",
    "10. [Gradient Analysis and Optimization](#gradients)\n",
    "11. [Loss Function Selection and Design](#selection)\n",
    "12. [Applications and Case Studies](#applications)\n",
    "13. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Mathematical Foundations {#introduction}\n",
    "\n",
    "### The Role of Loss Functions in Machine Learning\n",
    "\n",
    "A loss function $\\mathcal{L}(\\hat{y}, y)$ measures the discrepancy between predicted values $\\hat{y}$ and true values $y$. The fundamental optimization problem in supervised learning is:\n",
    "\n",
    "$$\\theta^* = \\arg\\min_{\\theta} \\mathbb{E}_{(x,y) \\sim \\mathcal{D}}[\\mathcal{L}(f(x; \\theta), y)]$$\n",
    "\n",
    "where:\n",
    "- $\\theta$ represents model parameters\n",
    "- $f(x; \\theta)$ is the model's prediction function\n",
    "- $\\mathcal{D}$ is the data distribution\n",
    "- $\\mathcal{L}$ is the loss function\n",
    "\n",
    "### Empirical Risk Minimization\n",
    "\n",
    "In practice, we approximate the expected loss using empirical risk:\n",
    "\n",
    "$$\\hat{\\mathcal{R}}(\\theta) = \\frac{1}{N} \\sum_{i=1}^N \\mathcal{L}(f(x_i; \\theta), y_i)$$\n",
    "\n",
    "### Mathematical Properties of Good Loss Functions\n",
    "\n",
    "**1. Convexity:**\n",
    "A loss function $\\mathcal{L}$ is convex if:\n",
    "$$\\mathcal{L}(\\lambda \\hat{y}_1 + (1-\\lambda) \\hat{y}_2, y) \\leq \\lambda \\mathcal{L}(\\hat{y}_1, y) + (1-\\lambda) \\mathcal{L}(\\hat{y}_2, y)$$\n",
    "for all $\\lambda \\in [0,1]$.\n",
    "\n",
    "**2. Differentiability:**\n",
    "For gradient-based optimization, we need:\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\text{ exists and is well-defined}$$\n",
    "\n",
    "**3. Proper Scoring Rules:**\n",
    "A loss function is a proper scoring rule if the expected loss is minimized when predictions match the true distribution:\n",
    "$$\\mathbb{E}[\\mathcal{L}(p, Y)] \\leq \\mathbb{E}[\\mathcal{L}(q, Y)]$$\n",
    "for all $q$ when $p$ is the true distribution.\n",
    "\n",
    "### Connection to Maximum Likelihood Estimation\n",
    "\n",
    "Many loss functions arise naturally from maximum likelihood estimation (MLE):\n",
    "$$\\theta^* = \\arg\\max_{\\theta} \\prod_{i=1}^N p(y_i | x_i; \\theta)$$\n",
    "\n",
    "Taking the negative log-likelihood:\n",
    "$$\\mathcal{L} = -\\log p(y | x; \\theta)$$\n",
    "\n",
    "This connection explains why cross-entropy emerges naturally for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logits and Probability Theory {#logits}\n",
    "\n",
    "### What are Logits?\n",
    "\n",
    "**Definition:** Logits are the raw, unnormalized outputs of a neural network before applying an activation function like sigmoid or softmax.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "For a probability $p \\in (0, 1)$, the logit is:\n",
    "$$\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$$\n",
    "\n",
    "This is also called the **log-odds** because:\n",
    "$$\\frac{p}{1-p} = \\text{odds ratio}$$\n",
    "\n",
    "### The Sigmoid Function and Its Inverse\n",
    "\n",
    "**Sigmoid Function:**\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{e^z}{1 + e^z}$$\n",
    "\n",
    "**Inverse Relationship:**\n",
    "$$\\text{logit}(\\sigma(z)) = z$$\n",
    "$$\\sigma(\\text{logit}(p)) = p$$\n",
    "\n",
    "**Proof:**\n",
    "$$\\text{logit}(\\sigma(z)) = \\ln\\left(\\frac{\\sigma(z)}{1-\\sigma(z)}\\right) = \\ln\\left(\\frac{\\frac{1}{1+e^{-z}}}{1-\\frac{1}{1+e^{-z}}}\\right) = \\ln\\left(\\frac{\\frac{1}{1+e^{-z}}}{\\frac{e^{-z}}{1+e^{-z}}}\\right) = \\ln(e^z) = z$$\n",
    "\n",
    "### Properties of Logits\n",
    "\n",
    "**1. Range:**\n",
    "- Logits: $z \\in (-\\infty, +\\infty)$\n",
    "- Probabilities: $p \\in (0, 1)$\n",
    "\n",
    "**2. Symmetry:**\n",
    "$$\\text{logit}(1-p) = -\\text{logit}(p)$$\n",
    "\n",
    "**3. Linear Separability:**\n",
    "Logits provide a linear decision boundary in the transformed space.\n",
    "\n",
    "### Why Use Logits?\n",
    "\n",
    "**1. Numerical Stability:**\n",
    "Working with logits avoids numerical issues when probabilities are very close to 0 or 1.\n",
    "\n",
    "**2. Computational Efficiency:**\n",
    "Many operations are more efficient in logit space.\n",
    "\n",
    "**3. Theoretical Benefits:**\n",
    "Logits naturally arise from linear models and provide unbounded outputs.\n",
    "\n",
    "### Softmax and Multiclass Logits\n",
    "\n",
    "For multiclass problems with $K$ classes, logits $\\mathbf{z} = [z_1, z_2, \\ldots, z_K]$ are converted to probabilities via softmax:\n",
    "\n",
    "$$p_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$$\n",
    "\n",
    "**Properties:**\n",
    "- $\\sum_{i=1}^K p_i = 1$ (probability simplex)\n",
    "- $p_i > 0$ for all $i$\n",
    "- Differentiable everywhere\n",
    "\n",
    "**Relationship to Logistic Regression:**\n",
    "Binary logistic regression is a special case where $K=2$ and we can represent with a single logit:\n",
    "$$p_1 = \\sigma(z), \\quad p_2 = \\sigma(-z) = 1 - \\sigma(z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binary Classification and Cross-Entropy {#binary}\n",
    "\n",
    "### Binary Cross-Entropy Loss\n",
    "\n",
    "**Mathematical Definition:**\n",
    "For binary classification with true label $y \\in \\{0, 1\\}$ and predicted probability $\\hat{p} \\in [0, 1]$:\n",
    "\n",
    "$$\\mathcal{L}_{BCE}(\\hat{p}, y) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})]$$\n",
    "\n",
    "**Expanded Form:**\n",
    "$$\\mathcal{L}_{BCE}(\\hat{p}, y) = \\begin{cases}\n",
    "-\\log(\\hat{p}) & \\text{if } y = 1 \\\\\n",
    "-\\log(1-\\hat{p}) & \\text{if } y = 0\n",
    "\\end{cases}$$\n",
    "\n",
    "### Derivation from Maximum Likelihood\n",
    "\n",
    "**Bernoulli Distribution:**\n",
    "$$P(Y = y | p) = p^y (1-p)^{1-y}$$\n",
    "\n",
    "**Log-Likelihood:**\n",
    "$$\\ell(p) = \\log P(Y = y | p) = y \\log(p) + (1-y) \\log(1-p)$$\n",
    "\n",
    "**Negative Log-Likelihood = Binary Cross-Entropy:**\n",
    "$$\\mathcal{L}_{BCE} = -\\ell(p)$$\n",
    "\n",
    "### Binary Cross-Entropy with Logits\n",
    "\n",
    "**Direct Formulation:**\n",
    "Instead of first computing $\\hat{p} = \\sigma(z)$ and then BCE, we can work directly with logits $z$:\n",
    "\n",
    "$$\\mathcal{L}_{BCE}(z, y) = -[y \\log(\\sigma(z)) + (1-y) \\log(1-\\sigma(z))]$$\n",
    "\n",
    "**Simplified Form:**\n",
    "$$\\mathcal{L}_{BCE}(z, y) = \\log(1 + e^{-z}) + (1-y)z$$\n",
    "\n",
    "**Even More Stable Form:**\n",
    "$$\\mathcal{L}_{BCE}(z, y) = \\max(z, 0) - yz + \\log(1 + e^{-|z|})$$\n",
    "\n",
    "### Mathematical Properties\n",
    "\n",
    "**1. Convexity:**\n",
    "Binary cross-entropy is convex in the logits, ensuring no local minima.\n",
    "\n",
    "**2. Gradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{BCE}}{\\partial z} = \\sigma(z) - y$$\n",
    "\n",
    "**3. Hessian:**\n",
    "$$\\frac{\\partial^2 \\mathcal{L}_{BCE}}{\\partial z^2} = \\sigma(z)(1-\\sigma(z)) \\geq 0$$\n",
    "\n",
    "**4. Fisher Information:**\n",
    "The Hessian equals the Fisher information, connecting to optimal statistical properties.\n",
    "\n",
    "### Behavior Analysis\n",
    "\n",
    "**As $z \\to +\\infty$ (confident correct prediction):**\n",
    "- If $y = 1$: $\\mathcal{L} \\to 0$\n",
    "- If $y = 0$: $\\mathcal{L} \\to +\\infty$\n",
    "\n",
    "**As $z \\to -\\infty$ (confident incorrect prediction):**\n",
    "- If $y = 1$: $\\mathcal{L} \\to +\\infty$\n",
    "- If $y = 0$: $\\mathcal{L} \\to 0$\n",
    "\n",
    "**At $z = 0$ (maximum uncertainty):**\n",
    "$$\\mathcal{L} = \\log(2) \\approx 0.693$$\n",
    "\n",
    "### Comparison with Other Binary Loss Functions\n",
    "\n",
    "**Mean Squared Error (MSE):**\n",
    "$$\\mathcal{L}_{MSE} = (\\sigma(z) - y)^2$$\n",
    "\n",
    "**Hinge Loss (SVM):**\n",
    "$$\\mathcal{L}_{hinge} = \\max(0, 1 - y'z)$$\n",
    "where $y' \\in \\{-1, +1\\}$.\n",
    "\n",
    "**Key Differences:**\n",
    "- **Cross-entropy:** Smooth, probabilistic, penalizes confidence on wrong predictions\n",
    "- **MSE:** Smooth but can lead to vanishing gradients\n",
    "- **Hinge:** Non-smooth, focuses on margin, doesn't provide probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiclass Classification and Softmax {#multiclass}\n",
    "\n",
    "### Categorical Cross-Entropy Loss\n",
    "\n",
    "**Mathematical Definition:**\n",
    "For $K$ classes with true label $y \\in \\{1, 2, \\ldots, K\\}$ and predicted probabilities $\\hat{\\mathbf{p}} = [\\hat{p}_1, \\hat{p}_2, \\ldots, \\hat{p}_K]$:\n",
    "\n",
    "$$\\mathcal{L}_{CCE}(\\hat{\\mathbf{p}}, y) = -\\log(\\hat{p}_y)$$\n",
    "\n",
    "**One-Hot Encoding Form:**\n",
    "If $\\mathbf{y}$ is one-hot encoded (e.g., $\\mathbf{y} = [0, 1, 0, \\ldots, 0]$ for class 2):\n",
    "\n",
    "$$\\mathcal{L}_{CCE}(\\hat{\\mathbf{p}}, \\mathbf{y}) = -\\sum_{i=1}^K y_i \\log(\\hat{p}_i)$$\n",
    "\n",
    "### Derivation from Multinomial Distribution\n",
    "\n",
    "**Categorical/Multinomial Distribution:**\n",
    "$$P(Y = k | \\mathbf{p}) = p_k$$\n",
    "\n",
    "**Log-Likelihood for Single Sample:**\n",
    "$$\\ell(\\mathbf{p}) = \\sum_{i=1}^K y_i \\log(p_i) = \\log(p_y)$$\n",
    "\n",
    "**Negative Log-Likelihood = Categorical Cross-Entropy:**\n",
    "$$\\mathcal{L}_{CCE} = -\\ell(\\mathbf{p})$$\n",
    "\n",
    "### Softmax Function Deep Dive\n",
    "\n",
    "**Definition:**\n",
    "$$\\text{softmax}(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$$\n",
    "\n",
    "**Properties:**\n",
    "1. **Probability Simplex:** $\\sum_{i=1}^K \\text{softmax}(\\mathbf{z})_i = 1$\n",
    "2. **Monotonicity:** If $z_i > z_j$, then $\\text{softmax}(\\mathbf{z})_i > \\text{softmax}(\\mathbf{z})_j$\n",
    "3. **Translation Invariance:** $\\text{softmax}(\\mathbf{z} + c\\mathbf{1}) = \\text{softmax}(\\mathbf{z})$\n",
    "\n",
    "**Gradient of Softmax:**\n",
    "$$\\frac{\\partial \\text{softmax}(\\mathbf{z})_i}{\\partial z_j} = \\text{softmax}(\\mathbf{z})_i (\\delta_{ij} - \\text{softmax}(\\mathbf{z})_j)$$\n",
    "\n",
    "where $\\delta_{ij}$ is the Kronecker delta.\n",
    "\n",
    "### Cross-Entropy with Logits\n",
    "\n",
    "**Direct Formulation:**\n",
    "$$\\mathcal{L}_{CCE}(\\mathbf{z}, y) = -z_y + \\log\\left(\\sum_{j=1}^K e^{z_j}\\right)$$\n",
    "\n",
    "**Numerically Stable Version:**\n",
    "$$\\mathcal{L}_{CCE}(\\mathbf{z}, y) = -z_y + \\text{LogSumExp}(\\mathbf{z})$$\n",
    "\n",
    "where $\\text{LogSumExp}(\\mathbf{z}) = \\log\\left(\\sum_{j=1}^K e^{z_j}\\right)$.\n",
    "\n",
    "**Stable Computation:**\n",
    "$$\\text{LogSumExp}(\\mathbf{z}) = \\max(\\mathbf{z}) + \\log\\left(\\sum_{j=1}^K e^{z_j - \\max(\\mathbf{z})}\\right)$$\n",
    "\n",
    "### Mathematical Properties\n",
    "\n",
    "**1. Convexity:**\n",
    "Categorical cross-entropy is convex in the logits.\n",
    "\n",
    "**2. Gradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{CCE}}{\\partial z_i} = \\text{softmax}(\\mathbf{z})_i - y_i$$\n",
    "\n",
    "This beautiful result shows the gradient is simply the difference between predicted and true probabilities!\n",
    "\n",
    "**3. Hessian:**\n",
    "$$\\frac{\\partial^2 \\mathcal{L}_{CCE}}{\\partial z_i \\partial z_j} = \\text{softmax}(\\mathbf{z})_i (\\delta_{ij} - \\text{softmax}(\\mathbf{z})_j)$$\n",
    "\n",
    "### Temperature Scaling\n",
    "\n",
    "**Temperature Softmax:**\n",
    "$$\\text{softmax}(\\mathbf{z}/T)_i = \\frac{e^{z_i/T}}{\\sum_{j=1}^K e^{z_j/T}}$$\n",
    "\n",
    "**Effects of Temperature:**\n",
    "- $T \\to 0$: Approaches one-hot (argmax)\n",
    "- $T = 1$: Standard softmax\n",
    "- $T \\to \\infty$: Approaches uniform distribution\n",
    "\n",
    "**Applications:**\n",
    "- **Calibration:** Adjusting confidence of predictions\n",
    "- **Knowledge Distillation:** Soft targets for training\n",
    "- **Exploration:** Controlling randomness in policy gradients\n",
    "\n",
    "### Sparse Categorical Cross-Entropy\n",
    "\n",
    "When labels are integers (not one-hot):\n",
    "$$\\mathcal{L}_{SCCE}(\\mathbf{z}, y) = -z_y + \\text{LogSumExp}(\\mathbf{z})$$\n",
    "\n",
    "This is computationally more efficient as it avoids creating one-hot vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regression Loss Functions {#regression}\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{MSE}(\\hat{y}, y) = \\frac{1}{2}(\\hat{y} - y)^2$$\n",
    "\n",
    "**Probabilistic Interpretation:**\n",
    "MSE corresponds to maximum likelihood estimation under Gaussian noise:\n",
    "$$y = f(x) + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$$\n",
    "\n",
    "**Log-Likelihood:**\n",
    "$$\\ell = -\\frac{1}{2\\sigma^2}(y - \\hat{y})^2 - \\frac{1}{2}\\log(2\\pi\\sigma^2)$$\n",
    "\n",
    "**Properties:**\n",
    "- **Convex:** Ensures global minimum\n",
    "- **Smooth:** Differentiable everywhere\n",
    "- **Sensitive to Outliers:** Quadratic penalty amplifies large errors\n",
    "\n",
    "**Gradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{MSE}}{\\partial \\hat{y}} = \\hat{y} - y$$\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{MAE}(\\hat{y}, y) = |\\hat{y} - y|$$\n",
    "\n",
    "**Probabilistic Interpretation:**\n",
    "MAE corresponds to maximum likelihood estimation under Laplace noise:\n",
    "$$y = f(x) + \\epsilon, \\quad \\epsilon \\sim \\text{Laplace}(0, b)$$\n",
    "\n",
    "**Properties:**\n",
    "- **Robust to Outliers:** Linear penalty for large errors\n",
    "- **Non-smooth:** Not differentiable at $\\hat{y} = y$\n",
    "- **Median Estimator:** Minimized by the median\n",
    "\n",
    "**Subgradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{MAE}}{\\partial \\hat{y}} = \\begin{cases}\n",
    "+1 & \\text{if } \\hat{y} > y \\\\\n",
    "[-1, +1] & \\text{if } \\hat{y} = y \\\\\n",
    "-1 & \\text{if } \\hat{y} < y\n",
    "\\end{cases}$$\n",
    "\n",
    "### Huber Loss\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{\\text{Huber}}(\\hat{y}, y) = \\begin{cases}\n",
    "\\frac{1}{2}(\\hat{y} - y)^2 & \\text{if } |\\hat{y} - y| \\leq \\delta \\\\\n",
    "\\delta |\\hat{y} - y| - \\frac{1}{2}\\delta^2 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "**Properties:**\n",
    "- **Smooth:** Differentiable everywhere\n",
    "- **Robust:** Combines MSE (small errors) and MAE (large errors)\n",
    "- **Tunable:** Parameter $\\delta$ controls transition point\n",
    "\n",
    "**Gradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{\\text{Huber}}}{\\partial \\hat{y}} = \\begin{cases}\n",
    "\\hat{y} - y & \\text{if } |\\hat{y} - y| \\leq \\delta \\\\\n",
    "\\delta \\cdot \\text{sign}(\\hat{y} - y) & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "### Log-Cosh Loss\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{\\text{LogCosh}}(\\hat{y}, y) = \\log(\\cosh(\\hat{y} - y))$$\n",
    "\n",
    "**Properties:**\n",
    "- **Smooth:** Twice differentiable\n",
    "- **Approximately MSE:** For small errors\n",
    "- **Approximately MAE:** For large errors\n",
    "- **Robust:** Less sensitive to outliers than MSE\n",
    "\n",
    "**Gradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{\\text{LogCosh}}}{\\partial \\hat{y}} = \\tanh(\\hat{y} - y)$$\n",
    "\n",
    "### Quantile Loss\n",
    "\n",
    "**Mathematical Definition:**\n",
    "For quantile $\\tau \\in (0, 1)$:\n",
    "$$\\mathcal{L}_{\\tau}(\\hat{y}, y) = \\begin{cases}\n",
    "\\tau(y - \\hat{y}) & \\text{if } y \\geq \\hat{y} \\\\\n",
    "(\\tau - 1)(y - \\hat{y}) & \\text{if } y < \\hat{y}\n",
    "\\end{cases}$$\n",
    "\n",
    "**Simplified Form:**\n",
    "$$\\mathcal{L}_{\\tau}(\\hat{y}, y) = (y - \\hat{y})(\\tau - \\mathbf{1}_{y < \\hat{y}})$$\n",
    "\n",
    "**Applications:**\n",
    "- **Quantile Regression:** Estimating conditional quantiles\n",
    "- **Uncertainty Quantification:** Prediction intervals\n",
    "- **Risk Management:** Value-at-Risk estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Information Theory and Loss Functions {#information-theory}\n",
    "\n",
    "### Information-Theoretic Foundations\n",
    "\n",
    "**Self-Information:**\n",
    "For an event with probability $p$:\n",
    "$$I(x) = -\\log(p(x))$$\n",
    "\n",
    "**Entropy:**\n",
    "Expected self-information:\n",
    "$$H(X) = -\\mathbb{E}[\\log(p(X))] = -\\sum_x p(x) \\log(p(x))$$\n",
    "\n",
    "**Cross-Entropy:**\n",
    "Expected log-likelihood under a different distribution:\n",
    "$$H(p, q) = -\\mathbb{E}_{x \\sim p}[\\log(q(x))] = -\\sum_x p(x) \\log(q(x))$$\n",
    "\n",
    "**Kullback-Leibler (KL) Divergence:**\n",
    "$$D_{KL}(p \\| q) = \\mathbb{E}_{x \\sim p}\\left[\\log\\frac{p(x)}{q(x)}\\right] = H(p, q) - H(p)$$\n",
    "\n",
    "### Connection to Loss Functions\n",
    "\n",
    "**Cross-Entropy Loss as KL Divergence:**\n",
    "When $p$ is the true distribution (e.g., one-hot) and $q$ is the predicted distribution:\n",
    "$$\\mathcal{L}_{CE} = H(p, q) = H(p) + D_{KL}(p \\| q)$$\n",
    "\n",
    "Since $H(p)$ is constant for fixed true labels, minimizing cross-entropy is equivalent to minimizing KL divergence.\n",
    "\n",
    "**Jensen-Shannon (JS) Divergence:**\n",
    "$$D_{JS}(p \\| q) = \\frac{1}{2}D_{KL}(p \\| m) + \\frac{1}{2}D_{KL}(q \\| m)$$\n",
    "where $m = \\frac{1}{2}(p + q)$.\n",
    "\n",
    "**Properties:**\n",
    "- **Symmetric:** $D_{JS}(p \\| q) = D_{JS}(q \\| p)$\n",
    "- **Bounded:** $D_{JS}(p \\| q) \\in [0, \\log(2)]$\n",
    "- **Smooth:** Better numerical properties than KL divergence\n",
    "\n",
    "### Mutual Information and Loss Design\n",
    "\n",
    "**Mutual Information:**\n",
    "$$I(X; Y) = D_{KL}(p(x,y) \\| p(x)p(y))$$\n",
    "\n",
    "**Applications in Deep Learning:**\n",
    "- **Information Bottleneck:** Balance compression and prediction\n",
    "- **Representation Learning:** Maximize mutual information between representations and targets\n",
    "- **Contrastive Learning:** Learn representations that distinguish between similar and dissimilar examples\n",
    "\n",
    "### Entropy-Based Regularization\n",
    "\n",
    "**Entropy Regularization:**\n",
    "$$\\mathcal{L}_{total} = \\mathcal{L}_{task} + \\lambda H(\\hat{p})$$\n",
    "\n",
    "**Effects:**\n",
    "- **Encourages Exploration:** Prevents overconfident predictions\n",
    "- **Smooths Distribution:** Reduces overfitting\n",
    "- **Temperature Scaling:** Equivalent to using temperature $T > 1$ in softmax\n",
    "\n",
    "### Information-Theoretic Bounds\n",
    "\n",
    "**Data Processing Inequality:**\n",
    "If $X \\to Y \\to Z$ forms a Markov chain:\n",
    "$$I(X; Z) \\leq I(X; Y)$$\n",
    "\n",
    "**Implications for Deep Learning:**\n",
    "- Information can only decrease through processing layers\n",
    "- Motivates skip connections and residual architectures\n",
    "- Explains the information bottleneck principle\n",
    "\n",
    "**Fano's Inequality:**\n",
    "Lower bound on error probability:\n",
    "$$P_e \\geq \\frac{H(Y|\\hat{Y}) - 1}{\\log(|\\mathcal{Y}| - 1)}$$\n",
    "\n",
    "This provides fundamental limits on classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Probabilistic Interpretation of Loss Functions {#probabilistic}\n",
    "\n",
    "### Maximum Likelihood Framework\n",
    "\n",
    "**General Framework:**\n",
    "Assume outputs follow a parametric distribution:\n",
    "$$y \\sim p(y | f(x; \\theta), \\phi)$$\n",
    "\n",
    "where $f(x; \\theta)$ is the neural network output and $\\phi$ are distribution parameters.\n",
    "\n",
    "**Negative Log-Likelihood Loss:**\n",
    "$$\\mathcal{L} = -\\log p(y | f(x; \\theta), \\phi)$$\n",
    "\n",
    "### Common Probabilistic Models\n",
    "\n",
    "**Gaussian Regression:**\n",
    "$$y \\sim \\mathcal{N}(f(x; \\theta), \\sigma^2)$$\n",
    "$$\\mathcal{L} = \\frac{1}{2\\sigma^2}(y - f(x; \\theta))^2 + \\frac{1}{2}\\log(2\\pi\\sigma^2)$$\n",
    "\n",
    "**Bernoulli Classification:**\n",
    "$$y \\sim \\text{Bernoulli}(\\sigma(f(x; \\theta)))$$\n",
    "$$\\mathcal{L} = -[y \\log(\\sigma(f(x; \\theta))) + (1-y) \\log(1-\\sigma(f(x; \\theta)))]$$\n",
    "\n",
    "**Categorical Classification:**\n",
    "$$y \\sim \\text{Categorical}(\\text{softmax}(f(x; \\theta)))$$\n",
    "$$\\mathcal{L} = -\\sum_{k=1}^K y_k \\log(\\text{softmax}(f(x; \\theta))_k)$$\n",
    "\n",
    "### Heteroscedastic Regression\n",
    "\n",
    "**Model:**\n",
    "Neural network predicts both mean and variance:\n",
    "$$f(x; \\theta) = [\\mu(x; \\theta), \\log(\\sigma^2(x; \\theta))]$$\n",
    "$$y \\sim \\mathcal{N}(\\mu(x; \\theta), \\sigma^2(x; \\theta))$$\n",
    "\n",
    "**Loss Function:**\n",
    "$$\\mathcal{L} = \\frac{1}{2\\sigma^2(x; \\theta)}(y - \\mu(x; \\theta))^2 + \\frac{1}{2}\\log(\\sigma^2(x; \\theta)) + \\frac{1}{2}\\log(2\\pi)$$\n",
    "\n",
    "**Benefits:**\n",
    "- **Uncertainty Quantification:** Model provides confidence estimates\n",
    "- **Adaptive Weighting:** Automatically weights samples by uncertainty\n",
    "- **Better Calibration:** More reliable probability estimates\n",
    "\n",
    "### Mixture Models\n",
    "\n",
    "**Gaussian Mixture Model:**\n",
    "$$p(y | x) = \\sum_{k=1}^K \\pi_k(x) \\mathcal{N}(y | \\mu_k(x), \\sigma_k^2(x))$$\n",
    "\n",
    "**Neural Network Outputs:**\n",
    "- Mixture weights: $\\pi_k(x) = \\text{softmax}(f_{\\pi}(x))_k$\n",
    "- Means: $\\mu_k(x) = f_{\\mu,k}(x)$\n",
    "- Variances: $\\sigma_k^2(x) = \\exp(f_{\\sigma,k}(x))$\n",
    "\n",
    "**Loss Function:**\n",
    "$$\\mathcal{L} = -\\log\\left(\\sum_{k=1}^K \\pi_k(x) \\mathcal{N}(y | \\mu_k(x), \\sigma_k^2(x))\\right)$$\n",
    "\n",
    "### Bayesian Neural Networks\n",
    "\n",
    "**Variational Inference:**\n",
    "Approximate posterior over weights:\n",
    "$$q(\\theta | \\phi) \\approx p(\\theta | \\mathcal{D})$$\n",
    "\n",
    "**ELBO (Evidence Lower Bound):**\n",
    "$$\\mathcal{L}_{ELBO} = \\mathbb{E}_{q(\\theta)}[\\log p(y | x, \\theta)] - D_{KL}(q(\\theta | \\phi) \\| p(\\theta))$$\n",
    "\n",
    "**Practical Implementation:**\n",
    "$$\\mathcal{L} = \\mathcal{L}_{data} + \\frac{1}{N} D_{KL}(q(\\theta) \\| p(\\theta))$$\n",
    "\n",
    "where the KL term acts as a regularizer.\n",
    "\n",
    "### Robust Loss Functions from Heavy-Tailed Distributions\n",
    "\n",
    "**Student's t-Distribution:**\n",
    "$$p(y | \\mu, \\sigma, \\nu) \\propto \\left(1 + \\frac{(y - \\mu)^2}{\\nu \\sigma^2}\\right)^{-\\frac{\\nu + 1}{2}}$$\n",
    "\n",
    "**Corresponding Loss:**\n",
    "$$\\mathcal{L} = \\frac{\\nu + 1}{2} \\log\\left(1 + \\frac{(y - \\mu)^2}{\\nu \\sigma^2}\\right) + \\text{constants}$$\n",
    "\n",
    "**Properties:**\n",
    "- **Robust to Outliers:** Heavy tails accommodate extreme values\n",
    "- **Tunable Robustness:** Parameter $\\nu$ controls tail heaviness\n",
    "- **Gaussian Limit:** As $\\nu \\to \\infty$, approaches Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Loss Functions {#advanced}\n",
    "\n",
    "### Focal Loss\n",
    "\n",
    "**Motivation:**\n",
    "Address class imbalance by down-weighting easy examples and focusing on hard examples.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{\\text{focal}} = -\\alpha (1 - \\hat{p})^\\gamma \\log(\\hat{p})$$\n",
    "\n",
    "where:\n",
    "- $\\hat{p}$ is the predicted probability for the true class\n",
    "- $\\alpha$ is a weighting factor\n",
    "- $\\gamma$ is the focusing parameter\n",
    "\n",
    "**Properties:**\n",
    "- When $\\gamma = 0$: Reduces to weighted cross-entropy\n",
    "- When $\\hat{p} \\to 1$: Loss approaches 0 faster than standard cross-entropy\n",
    "- When $\\hat{p} \\to 0$: Loss remains significant\n",
    "\n",
    "**Gradient Analysis:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{\\text{focal}}}{\\partial \\hat{p}} = -\\alpha (1 - \\hat{p})^{\\gamma-1} [\\gamma \\hat{p} \\log(\\hat{p}) + (1 - \\hat{p})]$$\n",
    "\n",
    "### Contrastive Loss\n",
    "\n",
    "**Motivation:**\n",
    "Learn representations where similar examples are close and dissimilar examples are far apart.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{\\text{contrastive}} = \\frac{1}{2}[y d^2 + (1-y) \\max(0, m - d)^2]$$\n",
    "\n",
    "where:\n",
    "- $d$ is the Euclidean distance between embeddings\n",
    "- $y \\in \\{0, 1\\}$ indicates similarity (1 = similar, 0 = dissimilar)\n",
    "- $m$ is the margin parameter\n",
    "\n",
    "**Interpretation:**\n",
    "- **Similar pairs ($y = 1$):** Minimize distance $d$\n",
    "- **Dissimilar pairs ($y = 0$):** Ensure distance is at least $m$\n",
    "\n",
    "### Triplet Loss\n",
    "\n",
    "**Motivation:**\n",
    "Learn embeddings where anchor is closer to positive than to negative examples.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{\\text{triplet}} = \\max(0, d(a, p) - d(a, n) + \\alpha)$$\n",
    "\n",
    "where:\n",
    "- $a$ is the anchor embedding\n",
    "- $p$ is the positive embedding (same class as anchor)\n",
    "- $n$ is the negative embedding (different class)\n",
    "- $\\alpha$ is the margin\n",
    "\n",
    "**Variants:**\n",
    "- **Hard Triplet Mining:** Select hardest negatives/positives\n",
    "- **Semi-Hard Mining:** Select negatives within margin\n",
    "- **Online Mining:** Select triplets within batch\n",
    "\n",
    "### Center Loss\n",
    "\n",
    "**Motivation:**\n",
    "Minimize intra-class variation by penalizing distance from class centers.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "$$\\mathcal{L}_{\\text{center}} = \\frac{1}{2} \\sum_{i=1}^N \\|\\mathbf{x}_i - \\mathbf{c}_{y_i}\\|^2$$\n",
    "\n",
    "where $\\mathbf{c}_{y_i}$ is the center of class $y_i$.\n",
    "\n",
    "**Combined Loss:**\n",
    "$$\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{CE}} + \\lambda \\mathcal{L}_{\\text{center}}$$\n",
    "\n",
    "**Center Update Rule:**\n",
    "$$\\mathbf{c}_j^{(t+1)} = \\mathbf{c}_j^{(t)} - \\alpha \\Delta \\mathbf{c}_j^{(t)}$$\n",
    "$$\\Delta \\mathbf{c}_j^{(t)} = \\frac{\\sum_{i=1}^N \\delta(y_i = j)(\\mathbf{c}_j - \\mathbf{x}_i)}{1 + \\sum_{i=1}^N \\delta(y_i = j)}$$\n",
    "\n",
    "### Dice Loss\n",
    "\n",
    "**Motivation:**\n",
    "Address class imbalance in segmentation tasks by focusing on overlap.\n",
    "\n",
    "**Dice Coefficient:**\n",
    "$$\\text{Dice} = \\frac{2|\\hat{Y} \\cap Y|}{|\\hat{Y}| + |Y|}$$\n",
    "\n",
    "**Differentiable Approximation:**\n",
    "$$\\text{Dice} = \\frac{2\\sum_{i} \\hat{p}_i y_i + \\epsilon}{\\sum_{i} \\hat{p}_i + \\sum_{i} y_i + \\epsilon}$$\n",
    "\n",
    "**Dice Loss:**\n",
    "$$\\mathcal{L}_{\\text{Dice}} = 1 - \\text{Dice}$$\n",
    "\n",
    "**Properties:**\n",
    "- **Scale Invariant:** Not affected by class frequency\n",
    "- **Smooth:** Differentiable approximation enables gradient-based training\n",
    "- **Balanced:** Treats all classes equally regardless of size\n",
    "\n",
    "### Wasserstein Loss\n",
    "\n",
    "**Motivation:**\n",
    "Use optimal transport distance for comparing probability distributions.\n",
    "\n",
    "**1-Wasserstein Distance:**\n",
    "$$W_1(p, q) = \\inf_{\\gamma \\in \\Pi(p,q)} \\mathbb{E}_{(x,y) \\sim \\gamma}[|x - y|]$$\n",
    "\n",
    "**Kantorovich-Rubinstein Duality:**\n",
    "$$W_1(p, q) = \\sup_{\\|f\\|_L \\leq 1} \\mathbb{E}_{x \\sim p}[f(x)] - \\mathbb{E}_{x \\sim q}[f(x)]$$\n",
    "\n",
    "**Applications:**\n",
    "- **GANs:** Wasserstein GANs use this as discriminator loss\n",
    "- **Domain Adaptation:** Minimize distribution shift\n",
    "- **Robust Optimization:** Less sensitive to outliers than KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Numerical Stability and Implementation {#stability}\n",
    "\n",
    "### Numerical Issues in Loss Computation\n",
    "\n",
    "**Common Problems:**\n",
    "1. **Overflow:** $e^{large\\_number} \\to \\infty$\n",
    "2. **Underflow:** $e^{-large\\_number} \\to 0$\n",
    "3. **Log of Zero:** $\\log(0) \\to -\\infty$\n",
    "4. **Catastrophic Cancellation:** Subtracting nearly equal numbers\n",
    "\n",
    "### Stable Softmax Computation\n",
    "\n",
    "**Naive Implementation (Unstable):**\n",
    "$$\\text{softmax}(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$$\n",
    "\n",
    "**Problem:** If $\\max(\\mathbf{z})$ is large, $e^{z_i}$ can overflow.\n",
    "\n",
    "**Stable Implementation:**\n",
    "$$\\text{softmax}(\\mathbf{z})_i = \\frac{e^{z_i - \\max(\\mathbf{z})}}{\\sum_{j=1}^K e^{z_j - \\max(\\mathbf{z})}}$$\n",
    "\n",
    "**Mathematical Justification:**\n",
    "Translation invariance: $\\text{softmax}(\\mathbf{z} + c\\mathbf{1}) = \\text{softmax}(\\mathbf{z})$\n",
    "\n",
    "### Stable Log-Sum-Exp\n",
    "\n",
    "**Definition:**\n",
    "$$\\text{LSE}(\\mathbf{z}) = \\log\\left(\\sum_{i=1}^K e^{z_i}\\right)$$\n",
    "\n",
    "**Stable Computation:**\n",
    "$$\\text{LSE}(\\mathbf{z}) = \\max(\\mathbf{z}) + \\log\\left(\\sum_{i=1}^K e^{z_i - \\max(\\mathbf{z})}\\right)$$\n",
    "\n",
    "**Even More Stable (for extreme cases):**\n",
    "```\n",
    "max_z = max(z)\n",
    "shifted_z = z - max_z\n",
    "exp_shifted = exp(shifted_z)\n",
    "sum_exp = sum(exp_shifted)\n",
    "if sum_exp == 0:  # All exponentials underflowed\n",
    "    return max_z  # Approximation\n",
    "else:\n",
    "    return max_z + log(sum_exp)\n",
    "```\n",
    "\n",
    "### Stable Cross-Entropy with Logits\n",
    "\n",
    "**Binary Case:**\n",
    "Instead of computing $\\hat{p} = \\sigma(z)$ then $-y \\log(\\hat{p}) - (1-y) \\log(1-\\hat{p})$:\n",
    "\n",
    "$$\\mathcal{L} = \\max(z, 0) - yz + \\log(1 + e^{-|z|})$$\n",
    "\n",
    "**Multiclass Case:**\n",
    "$$\\mathcal{L} = -z_y + \\text{LSE}(\\mathbf{z})$$\n",
    "\n",
    "### Gradient Clipping\n",
    "\n",
    "**Problem:** Exploding gradients can destabilize training.\n",
    "\n",
    "**Global Gradient Clipping:**\n",
    "$$\\mathbf{g}_{\\text{clipped}} = \\min\\left(1, \\frac{\\text{clip\\_norm}}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}$$\n",
    "\n",
    "**Per-Parameter Clipping:**\n",
    "$$g_i = \\text{clip}(g_i, -\\text{clip\\_value}, \\text{clip\\_value})$$\n",
    "\n",
    "### Mixed Precision Training\n",
    "\n",
    "**Loss Scaling:**\n",
    "To prevent gradient underflow in FP16:\n",
    "$$\\mathcal{L}_{\\text{scaled}} = S \\cdot \\mathcal{L}$$\n",
    "$$\\mathbf{g}_{\\text{scaled}} = S \\cdot \\nabla \\mathcal{L}$$\n",
    "$$\\mathbf{g} = \\mathbf{g}_{\\text{scaled}} / S$$\n",
    "\n",
    "**Dynamic Loss Scaling:**\n",
    "- Start with large scale factor\n",
    "- Reduce if overflow detected\n",
    "- Increase if no overflow for many iterations\n",
    "\n",
    "### Label Smoothing\n",
    "\n",
    "**Standard One-Hot:**\n",
    "$$\\mathbf{y} = [0, \\ldots, 0, 1, 0, \\ldots, 0]$$\n",
    "\n",
    "**Smoothed Labels:**\n",
    "$$\\mathbf{y}_{\\text{smooth}} = (1 - \\alpha) \\mathbf{y} + \\frac{\\alpha}{K} \\mathbf{1}$$\n",
    "\n",
    "where $\\alpha \\in [0, 1]$ is the smoothing parameter.\n",
    "\n",
    "**Benefits:**\n",
    "- **Regularization:** Prevents overconfident predictions\n",
    "- **Calibration:** Improves probability estimates\n",
    "- **Generalization:** Often improves test performance\n",
    "\n",
    "**Mathematical Interpretation:**\n",
    "Label smoothing is equivalent to adding entropy regularization:\n",
    "$$\\mathcal{L}_{\\text{smooth}} = \\mathcal{L}_{\\text{CE}} + \\frac{\\alpha}{K} H(\\hat{\\mathbf{p}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Gradient Analysis and Optimization {#gradients}\n",
    "\n",
    "### Gradient Flow Analysis\n",
    "\n",
    "**Chain Rule for Loss Functions:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\theta}$$\n",
    "\n",
    "**Key Insight:** The choice of loss function directly affects $\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}}$, which influences gradient flow.\n",
    "\n",
    "### Gradient Analysis for Common Loss Functions\n",
    "\n",
    "**Mean Squared Error:**\n",
    "$$\\frac{\\partial \\mathcal{L}_{MSE}}{\\partial \\hat{y}} = \\hat{y} - y$$\n",
    "\n",
    "**Properties:**\n",
    "- Linear in error\n",
    "- Can lead to vanishing gradients when error is small\n",
    "- Exploding gradients when error is large\n",
    "\n",
    "**Cross-Entropy (Binary):**\n",
    "For $\\hat{p} = \\sigma(z)$:\n",
    "$$\\frac{\\partial \\mathcal{L}_{BCE}}{\\partial z} = \\hat{p} - y$$\n",
    "\n",
    "**Properties:**\n",
    "- Gradient is difference between prediction and target\n",
    "- Automatically scaled by prediction confidence\n",
    "- Larger gradients for confident wrong predictions\n",
    "\n",
    "**Cross-Entropy (Multiclass):**\n",
    "$$\\frac{\\partial \\mathcal{L}_{CCE}}{\\partial z_i} = \\hat{p}_i - y_i$$\n",
    "\n",
    "**Elegant Property:** Gradient equals prediction error!\n",
    "\n",
    "### Vanishing and Exploding Gradients\n",
    "\n",
    "**Vanishing Gradients:**\n",
    "- **Cause:** Gradients become exponentially small in deep networks\n",
    "- **Loss Function Impact:** Some losses exacerbate this problem\n",
    "- **Example:** Squared loss with sigmoid activation\n",
    "\n",
    "**Exploding Gradients:**\n",
    "- **Cause:** Gradients become exponentially large\n",
    "- **Loss Function Impact:** Unbounded losses can cause instability\n",
    "- **Solution:** Gradient clipping, careful loss design\n",
    "\n",
    "### Curvature and Second-Order Information\n",
    "\n",
    "**Hessian of Loss Functions:**\n",
    "\n",
    "**MSE:**\n",
    "$$\\frac{\\partial^2 \\mathcal{L}_{MSE}}{\\partial \\hat{y}^2} = 1$$\n",
    "Constant curvature (good for optimization).\n",
    "\n",
    "**Cross-Entropy:**\n",
    "$$\\frac{\\partial^2 \\mathcal{L}_{BCE}}{\\partial z^2} = \\hat{p}(1 - \\hat{p})$$\n",
    "Curvature depends on prediction confidence.\n",
    "\n",
    "**Implications:**\n",
    "- **Near boundaries ($\\hat{p} \\approx 0$ or $1$):** Small curvature, slow convergence\n",
    "- **Near decision boundary ($\\hat{p} \\approx 0.5$):** Maximum curvature, fast convergence\n",
    "\n",
    "### Natural Gradients\n",
    "\n",
    "**Fisher Information Matrix:**\n",
    "$$F_{ij} = \\mathbb{E}\\left[\\frac{\\partial \\log p(y|\\theta)}{\\partial \\theta_i} \\frac{\\partial \\log p(y|\\theta)}{\\partial \\theta_j}\\right]$$\n",
    "\n",
    "**Natural Gradient:**\n",
    "$$\\tilde{\\nabla} \\mathcal{L} = F^{-1} \\nabla \\mathcal{L}$$\n",
    "\n",
    "**Connection to Cross-Entropy:**\n",
    "For exponential family distributions, the Hessian of cross-entropy equals the Fisher information matrix, making natural gradients particularly relevant.\n",
    "\n",
    "### Adaptive Learning Rates\n",
    "\n",
    "**Adam Update with Loss-Dependent Scaling:**\n",
    "$$\\mathbf{m}_t = \\beta_1 \\mathbf{m}_{t-1} + (1-\\beta_1) \\nabla \\mathcal{L}_t$$\n",
    "$$\\mathbf{v}_t = \\beta_2 \\mathbf{v}_{t-1} + (1-\\beta_2) (\\nabla \\mathcal{L}_t)^2$$\n",
    "$$\\theta_t = \\theta_{t-1} - \\alpha \\frac{\\hat{\\mathbf{m}}_t}{\\sqrt{\\hat{\\mathbf{v}}_t} + \\epsilon}$$\n",
    "\n",
    "**Loss Function Impact:**\n",
    "- Different losses produce different gradient magnitudes\n",
    "- Adam adapts to these differences automatically\n",
    "- Some losses may require learning rate adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Loss Function Selection and Design {#selection}\n",
    "\n",
    "### Decision Framework for Loss Function Selection\n",
    "\n",
    "**1. Problem Type Classification:**\n",
    "\n",
    "| Problem Type | Recommended Loss | Alternative Options |\n",
    "|--------------|------------------|--------------------|\n",
    "| **Binary Classification** | Binary Cross-Entropy | Focal Loss (imbalanced), Hinge Loss |\n",
    "| **Multiclass Classification** | Categorical Cross-Entropy | Sparse Categorical Cross-Entropy |\n",
    "| **Multilabel Classification** | Binary Cross-Entropy per label | Focal Loss, Asymmetric Loss |\n",
    "| **Regression** | MSE (Gaussian noise) | MAE (outliers), Huber (robust) |\n",
    "| **Ranking** | Pairwise Hinge | Triplet Loss, ListNet |\n",
    "| **Segmentation** | Cross-Entropy | Dice Loss, Focal Loss |\n",
    "| **Detection** | Combined (classification + regression) | Focal Loss + Smooth L1 |\n",
    "\n",
    "**2. Data Characteristics:**\n",
    "\n",
    "**Class Imbalance:**\n",
    "- **Severe imbalance:** Focal Loss, Weighted Cross-Entropy\n",
    "- **Moderate imbalance:** Class weighting, oversampling\n",
    "- **Balanced:** Standard Cross-Entropy\n",
    "\n",
    "**Noise Level:**\n",
    "- **High noise:** Robust losses (Huber, MAE, Heavy-tailed distributions)\n",
    "- **Low noise:** Standard losses (MSE, Cross-Entropy)\n",
    "- **Label noise:** Label smoothing, noise-aware losses\n",
    "\n",
    "**Outliers:**\n",
    "- **Present:** MAE, Huber Loss, Quantile Loss\n",
    "- **Absent:** MSE, standard losses\n",
    "\n",
    "### Custom Loss Function Design\n",
    "\n",
    "**Design Principles:**\n",
    "\n",
    "**1. Differentiability:**\n",
    "Ensure the loss is differentiable (or at least subdifferentiable) everywhere.\n",
    "\n",
    "**2. Convexity:**\n",
    "Convex losses guarantee global minima (though neural networks are non-convex overall).\n",
    "\n",
    "**3. Proper Scoring:**\n",
    "The loss should be minimized when predictions match the true distribution.\n",
    "\n",
    "**4. Computational Efficiency:**\n",
    "Consider the computational cost, especially for large-scale problems.\n",
    "\n",
    "**Example: Custom Asymmetric Loss for Imbalanced Classification:**\n",
    "$$\\mathcal{L}_{\\text{asym}} = \\begin{cases}\n",
    "\\alpha \\mathcal{L}_{\\text{CE}} & \\text{if } y = 1 \\text{ (positive class)} \\\\\n",
    "\\beta \\mathcal{L}_{\\text{CE}} & \\text{if } y = 0 \\text{ (negative class)}\n",
    "\\end{cases}$$\n",
    "\n",
    "Choose $\\alpha > \\beta$ to penalize false negatives more than false positives.\n",
    "\n",
    "### Multi-Task Learning Loss Design\n",
    "\n",
    "**Weighted Combination:**\n",
    "$$\\mathcal{L}_{\\text{total}} = \\sum_{i=1}^T \\lambda_i \\mathcal{L}_i$$\n",
    "\n",
    "**Challenges:**\n",
    "- **Scale Differences:** Different tasks may have vastly different loss scales\n",
    "- **Gradient Conflicts:** Tasks may require contradictory updates\n",
    "- **Weighting:** Choosing appropriate $\\lambda_i$ is difficult\n",
    "\n",
    "**Uncertainty Weighting:**\n",
    "Learn task weights based on homoscedastic uncertainty:\n",
    "$$\\mathcal{L}_{\\text{total}} = \\sum_{i=1}^T \\frac{1}{2\\sigma_i^2} \\mathcal{L}_i + \\frac{1}{2} \\log \\sigma_i^2$$\n",
    "\n",
    "**GradNorm:**\n",
    "Balance gradients across tasks:\n",
    "$$\\|\\nabla_{\\text{shared}} \\mathcal{L}_i\\| \\approx \\bar{G} \\times (r_i)^{\\alpha}$$\n",
    "where $r_i$ is the relative training rate of task $i$.\n",
    "\n",
    "### Domain-Specific Loss Functions\n",
    "\n",
    "**Computer Vision:**\n",
    "- **Object Detection:** Combination of classification and regression losses\n",
    "- **Segmentation:** Dice loss, IoU loss, Boundary loss\n",
    "- **GANs:** Adversarial loss, Wasserstein loss\n",
    "\n",
    "**Natural Language Processing:**\n",
    "- **Language Modeling:** Cross-entropy with teacher forcing\n",
    "- **Machine Translation:** Cross-entropy, BLEU-based losses\n",
    "- **Sequence Labeling:** CTC loss, CRF loss\n",
    "\n",
    "**Recommendation Systems:**\n",
    "- **Implicit Feedback:** BPR loss, WARP loss\n",
    "- **Rating Prediction:** MSE, ordinal regression losses\n",
    "- **Ranking:** Pairwise ranking losses\n",
    "\n",
    "### Loss Function Debugging and Analysis\n",
    "\n",
    "**Diagnostic Questions:**\n",
    "\n",
    "**1. Is the loss decreasing?**\n",
    "- If not: Learning rate too high/low, gradient issues, implementation bug\n",
    "\n",
    "**2. Are gradients reasonable?**\n",
    "- Check gradient magnitudes and distributions\n",
    "- Look for vanishing/exploding gradients\n",
    "\n",
    "**3. Is the model learning the right thing?**\n",
    "- Visualize predictions on validation set\n",
    "- Check if loss aligns with evaluation metrics\n",
    "\n",
    "**4. How does loss behave on different data subsets?**\n",
    "- Analyze performance by class, difficulty, etc.\n",
    "- Identify if loss is appropriate for all cases\n",
    "\n",
    "**Visualization Techniques:**\n",
    "- Loss landscapes\n",
    "- Gradient flow analysis\n",
    "- Per-example loss distributions\n",
    "- Loss vs. confidence plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Applications and Case Studies {#applications}\n",
    "\n",
    "### Case Study 1: Image Classification with Class Imbalance\n",
    "\n",
    "**Problem:** Medical image classification with 95% normal cases, 5% abnormal cases.\n",
    "\n",
    "**Standard Cross-Entropy Issues:**\n",
    "- Model predicts \"normal\" for everything\n",
    "- High accuracy (95%) but useless for medical diagnosis\n",
    "- False negative rate too high\n",
    "\n",
    "**Solutions:**\n",
    "\n",
    "**1. Weighted Cross-Entropy:**\n",
    "$$\\mathcal{L} = -[w_1 y \\log(\\hat{p}) + w_0 (1-y) \\log(1-\\hat{p})]$$\n",
    "with $w_1 = 19, w_0 = 1$ (inverse class frequencies).\n",
    "\n",
    "**2. Focal Loss:**\n",
    "$$\\mathcal{L} = -\\alpha (1-\\hat{p})^\\gamma \\log(\\hat{p})$$\n",
    "with $\\alpha = 0.25, \\gamma = 2$.\n",
    "\n",
    "**3. Custom Asymmetric Loss:**\n",
    "$$\\mathcal{L} = \\begin{cases}\n",
    "5 \\times \\text{BCE} & \\text{if false negative} \\\\\n",
    "1 \\times \\text{BCE} & \\text{if false positive} \\\\\n",
    "0.1 \\times \\text{BCE} & \\text{if correct}\n",
    "\\end{cases}$$\n",
    "\n",
    "### Case Study 2: Machine Translation\n",
    "\n",
    "**Problem:** Sequence-to-sequence translation with cross-entropy loss.\n",
    "\n",
    "**Issues with Standard Approach:**\n",
    "- **Exposure Bias:** Training uses ground truth, inference uses predictions\n",
    "- **Loss-Evaluation Mismatch:** Cross-entropy doesn't correlate with BLEU\n",
    "\n",
    "**Advanced Solutions:**\n",
    "\n",
    "**1. Scheduled Sampling:**\n",
    "During training, sometimes use model predictions instead of ground truth:\n",
    "$$p(\\text{use ground truth}) = \\epsilon_t = k/(k + \\exp(t/k))$$\n",
    "\n",
    "**2. REINFORCE with BLEU:**\n",
    "$$\\mathcal{L} = -\\mathbb{E}[\\text{BLEU}(\\hat{y}, y) \\sum_t \\log p(\\hat{y}_t | \\hat{y}_{<t}, x)]$$\n",
    "\n",
    "**3. Minimum Risk Training:**\n",
    "$$\\mathcal{L} = \\sum_{\\hat{y} \\in \\mathcal{S}} p(\\hat{y} | x) \\times \\text{Risk}(\\hat{y}, y)$$\n",
    "where $\\mathcal{S}$ is a set of sampled translations.\n",
    "\n",
    "### Case Study 3: Object Detection\n",
    "\n",
    "**Problem:** Detect and classify objects in images.\n",
    "\n",
    "**Multi-Component Loss:**\n",
    "$$\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{cls}} + \\lambda \\mathcal{L}_{\\text{box}} + \\mu \\mathcal{L}_{\\text{obj}}$$\n",
    "\n",
    "**Components:**\n",
    "\n",
    "**1. Classification Loss (Focal Loss):**\n",
    "$$\\mathcal{L}_{\\text{cls}} = -\\alpha (1-\\hat{p})^\\gamma \\log(\\hat{p})$$\n",
    "Handles class imbalance (many background regions).\n",
    "\n",
    "**2. Bounding Box Regression (Smooth L1):**\n",
    "$$\\mathcal{L}_{\\text{box}} = \\sum_{i \\in \\{x,y,w,h\\}} \\text{SmoothL1}(\\hat{b}_i - b_i)$$\n",
    "Robust to outliers in box coordinates.\n",
    "\n",
    "**3. Objectness Score (Binary Cross-Entropy):**\n",
    "$$\\mathcal{L}_{\\text{obj}} = -[o \\log(\\hat{o}) + (1-o) \\log(1-\\hat{o})]$$\n",
    "Distinguishes objects from background.\n",
    "\n",
    "### Case Study 4: Generative Adversarial Networks\n",
    "\n",
    "**Problem:** Train generator and discriminator networks simultaneously.\n",
    "\n",
    "**Original GAN Loss:**\n",
    "$$\\min_G \\max_D \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]$$\n",
    "\n",
    "**Issues:**\n",
    "- **Vanishing Gradients:** When discriminator is too good\n",
    "- **Mode Collapse:** Generator produces limited diversity\n",
    "- **Training Instability:** Difficult to balance G and D\n",
    "\n",
    "**Improved Losses:**\n",
    "\n",
    "**1. Wasserstein GAN:**\n",
    "$$\\mathcal{L}_D = \\mathbb{E}_{x \\sim p_{\\text{data}}}[D(x)] - \\mathbb{E}_{x \\sim p_g}[D(x)]$$\n",
    "$$\\mathcal{L}_G = -\\mathbb{E}_{x \\sim p_g}[D(x)]$$\n",
    "\n",
    "**2. Least Squares GAN:**\n",
    "$$\\mathcal{L}_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_{\\text{data}}}[(D(x) - 1)^2] + \\frac{1}{2}\\mathbb{E}_{x \\sim p_g}[D(x)^2]$$\n",
    "$$\\mathcal{L}_G = \\frac{1}{2}\\mathbb{E}_{x \\sim p_g}[(D(x) - 1)^2]$$\n",
    "\n",
    "### Case Study 5: Reinforcement Learning\n",
    "\n",
    "**Problem:** Learn optimal policies through trial and error.\n",
    "\n",
    "**Policy Gradient Loss:**\n",
    "$$\\mathcal{L} = -\\mathbb{E}[\\sum_t \\log \\pi(a_t | s_t) A_t]$$\n",
    "where $A_t$ is the advantage function.\n",
    "\n",
    "**Value Function Loss (MSE):**\n",
    "$$\\mathcal{L}_V = \\mathbb{E}[(V(s_t) - R_t)^2]$$\n",
    "\n",
    "**Combined Actor-Critic Loss:**\n",
    "$$\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{policy}} + c_1 \\mathcal{L}_{\\text{value}} - c_2 H(\\pi)$$\n",
    "\n",
    "where $H(\\pi)$ is entropy regularization to encourage exploration.\n",
    "\n",
    "### Lessons Learned\n",
    "\n",
    "**1. Domain Knowledge Matters:**\n",
    "Understanding the problem structure helps design appropriate losses.\n",
    "\n",
    "**2. Multiple Objectives:**\n",
    "Real applications often require balancing multiple objectives.\n",
    "\n",
    "**3. Data Characteristics:**\n",
    "Class imbalance, noise, and outliers significantly impact loss choice.\n",
    "\n",
    "**4. Evaluation Alignment:**\n",
    "Training loss should align with evaluation metrics when possible.\n",
    "\n",
    "**5. Iterative Refinement:**\n",
    "Loss function design is often an iterative process based on empirical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Conclusion {#conclusion}\n",
    "\n",
    "### Summary of Key Insights\n",
    "\n",
    "**Mathematical Foundations:**\n",
    "1. **Probabilistic Basis:** Most loss functions arise from maximum likelihood estimation\n",
    "2. **Information Theory:** Cross-entropy connects to information-theoretic concepts\n",
    "3. **Optimization Properties:** Convexity, differentiability, and curvature affect training\n",
    "4. **Proper Scoring:** Good loss functions incentivize honest probability estimates\n",
    "\n",
    "**Practical Considerations:**\n",
    "1. **Numerical Stability:** Implementation details matter for reliable training\n",
    "2. **Gradient Flow:** Loss choice directly affects optimization dynamics\n",
    "3. **Problem Alignment:** Loss should match problem structure and evaluation metrics\n",
    "4. **Data Characteristics:** Class imbalance, noise, and outliers require specialized approaches\n",
    "\n",
    "**Design Principles:**\n",
    "1. **Start Simple:** Begin with standard losses before moving to specialized ones\n",
    "2. **Understand Trade-offs:** Every loss function embodies assumptions and trade-offs\n",
    "3. **Validate Empirically:** Theoretical properties don't always translate to practice\n",
    "4. **Consider the Full Pipeline:** Loss interacts with architecture, optimizer, and data\n",
    "\n",
    "### The Evolution of Loss Functions\n",
    "\n",
    "**Historical Progression:**\n",
    "- **Classical ML:** MSE, log-likelihood, hinge loss\n",
    "- **Deep Learning Era:** Cross-entropy becomes dominant\n",
    "- **Specialized Applications:** Task-specific losses (focal, contrastive, etc.)\n",
    "- **Modern Trends:** Learnable losses, adversarial objectives, meta-learning\n",
    "\n",
    "**Future Directions:**\n",
    "- **Adaptive Losses:** Automatically adjust to data characteristics\n",
    "- **Multi-Modal Learning:** Losses for heterogeneous data types\n",
    "- **Fairness-Aware Losses:** Incorporate ethical considerations\n",
    "- **Robust Losses:** Handle distribution shift and adversarial examples\n",
    "\n",
    "### Fundamental Relationships\n",
    "\n",
    "**The Trinity of ML:**\n",
    "```\n",
    "Model Architecture ←→ Loss Function ←→ Optimization Algorithm\n",
    "```\n",
    "These three components must be harmoniously designed for effective learning.\n",
    "\n",
    "**Loss-Evaluation Alignment:**\n",
    "Training objectives should align with evaluation metrics, but this isn't always possible due to:\n",
    "- Non-differentiability of some metrics\n",
    "- Computational constraints\n",
    "- Multi-objective trade-offs\n",
    "\n",
    "### Practical Wisdom\n",
    "\n",
    "**Golden Rules:**\n",
    "1. **Cross-entropy for classification:** Unless you have a specific reason to deviate\n",
    "2. **MSE for regression:** When you assume Gaussian noise\n",
    "3. **Validate on real data:** Mathematical elegance doesn't guarantee practical success\n",
    "4. **Monitor gradients:** Loss choice affects optimization dynamics\n",
    "5. **Consider problem structure:** Domain knowledge guides loss design\n",
    "\n",
    "**Common Pitfalls:**\n",
    "- **Over-engineering:** Using complex losses when simple ones suffice\n",
    "- **Ignoring implementation:** Numerical issues can ruin theoretically sound losses\n",
    "- **Misaligned objectives:** Training loss that doesn't reflect true goals\n",
    "- **Scale mismatches:** In multi-task learning, different loss scales cause issues\n",
    "\n",
    "### The Art and Science of Loss Design\n",
    "\n",
    "Loss function design sits at the intersection of:\n",
    "- **Mathematics:** Probability theory, information theory, optimization\n",
    "- **Statistics:** Maximum likelihood, proper scoring rules, robustness\n",
    "- **Computer Science:** Algorithms, numerical methods, implementation\n",
    "- **Domain Expertise:** Understanding the specific problem and data\n",
    "\n",
    "**Final Thought:**\n",
    "Loss functions are the bridge between our mathematical models and real-world objectives. They encode our assumptions about the world, our tolerance for different types of errors, and our beliefs about what constitutes good predictions. Understanding loss functions deeply—their mathematical properties, implementation details, and practical implications—is essential for anyone seeking to master machine learning.\n",
    "\n",
    "The journey from simple squared loss to sophisticated adversarial objectives reflects the evolution of machine learning itself: from simple pattern recognition to complex, multi-faceted intelligence systems. As the field continues to advance, new loss functions will emerge to handle new challenges, but the fundamental principles explored in this notebook will remain relevant.\n",
    "\n",
    "**Remember:** The best loss function is not necessarily the most mathematically elegant one, but the one that best captures your problem's essence and guides your model toward practically useful solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}