{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PyTorch Basics Part 8: Generative Models and Unsupervised Learning\n\nExploring autoencoders, GANs, VAEs, and self-supervised learning with mathematical foundations for generating and learning from unlabeled data\n\n## Mathematical Framework for Generative Modeling\n\n**Generative models** learn probability distributions over data to generate new samples and discover latent structure:\n\n### Core Mathematical Concepts\n\n**1. Generative vs Discriminative Models:**\n- **Discriminative**: $P(y|\\mathbf{x})$ - predict labels given data\n- **Generative**: $P(\\mathbf{x})$ or $P(\\mathbf{x}, y)$ - model data distribution\n\n**2. Density Estimation:**\nLearn probability density function $p_{\\boldsymbol{\\theta}}(\\mathbf{x})$ that approximates true data distribution $p_{\\text{data}}(\\mathbf{x})$.\n\n**3. Latent Variable Models:**\n$$p(\\mathbf{x}) = \\int p(\\mathbf{x}|\\mathbf{z})p(\\mathbf{z})d\\mathbf{z}$$\n\nwhere $\\mathbf{z} \\in \\mathbb{R}^d$ is latent variable, $\\mathbf{x} \\in \\mathbb{R}^D$ is observed data.\n\n**4. Maximum Likelihood Estimation:**\n$$\\boldsymbol{\\theta}^* = \\arg\\max_{\\boldsymbol{\\theta}} \\sum_{i=1}^N \\log p_{\\boldsymbol{\\theta}}(\\mathbf{x}_i)$$\n\n**5. Information-Theoretic Measures:**\n- **KL Divergence**: $D_{KL}(p||q) = \\int p(\\mathbf{x}) \\log \\frac{p(\\mathbf{x})}{q(\\mathbf{x})} d\\mathbf{x}$\n- **Jensen-Shannon Divergence**: $D_{JS}(p||q) = \\frac{1}{2}D_{KL}(p||m) + \\frac{1}{2}D_{KL}(q||m)$\n  where $m = \\frac{1}{2}(p+q)$\n\n**6. Representation Learning Objectives:**\n- **Reconstruction**: Minimize $\\|\\mathbf{x} - \\hat{\\mathbf{x}}\\|^2$\n- **Regularization**: Constrain latent space structure\n- **Disentanglement**: Learn interpretable factors of variation\n\n**7. Sampling Methods:**\n- **Ancestral sampling**: Sample $\\mathbf{z} \\sim p(\\mathbf{z})$, then $\\mathbf{x} \\sim p(\\mathbf{x}|\\mathbf{z})$\n- **MCMC methods**: For complex posteriors\n- **Variational approximation**: Tractable inference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders: Learning Compressed Representations\n",
    "\n",
    "Autoencoders learn to compress data into a lower-dimensional representation (encoding) and then reconstruct the original data (decoding). They're useful for dimensionality reduction, denoising, and feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Autoencoder implementation\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder: compress input to latent representation\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Decoder: reconstruct input from latent representation\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # Assuming input is normalized to [0,1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        latent = self.encoder(x)\n",
    "        # Decode\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "# Create synthetic high-dimensional data\n",
    "def create_synthetic_data(n_samples=1000, n_features=50, n_informative=5):\n",
    "    \"\"\"Create high-dimensional data with underlying low-dimensional structure\"\"\"\n",
    "    # Generate low-dimensional structure\n",
    "    base_data = np.random.randn(n_samples, n_informative)\n",
    "    \n",
    "    # Create high-dimensional data by linear combination + noise\n",
    "    mixing_matrix = np.random.randn(n_informative, n_features)\n",
    "    high_dim_data = base_data @ mixing_matrix\n",
    "    \n",
    "    # Add some noise\n",
    "    noise = 0.1 * np.random.randn(n_samples, n_features)\n",
    "    high_dim_data += noise\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    high_dim_data = (high_dim_data - high_dim_data.min()) / (high_dim_data.max() - high_dim_data.min())\n",
    "    \n",
    "    return torch.FloatTensor(high_dim_data), torch.FloatTensor(base_data)\n",
    "\n",
    "# Generate data\n",
    "X_high, X_true = create_synthetic_data(1000, 50, 3)\n",
    "print(f\"High-dimensional data shape: {X_high.shape}\")\n",
    "print(f\"True low-dimensional structure shape: {X_true.shape}\")\n",
    "\n",
    "# Create autoencoder\n",
    "autoencoder = SimpleAutoencoder(input_dim=50, hidden_dim=128, latent_dim=3)\n",
    "print(f\"Autoencoder parameters: {sum(p.numel() for p in autoencoder.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "sample_input = X_high[:5]\n",
    "reconstructed, latent = autoencoder(sample_input)\n",
    "print(f\"Input shape: {sample_input.shape}\")\n",
    "print(f\"Latent shape: {latent.shape}\")\n",
    "print(f\"Reconstructed shape: {reconstructed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Autoencoders\n",
    "\n",
    "Autoencoders are trained to minimize reconstruction error - the difference between the input and the reconstructed output. This forces the network to learn meaningful representations in the bottleneck layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for autoencoders\n",
    "def train_autoencoder(model, data_loader, num_epochs=100, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_x in data_loader:\n",
    "            # Forward pass\n",
    "            reconstructed, latent = model(batch_x)\n",
    "            \n",
    "            # Compute reconstruction loss\n",
    "            loss = criterion(reconstructed, batch_x)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(data_loader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Create data loader\n",
    "dataset = TensorDataset(X_high)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train autoencoder\n",
    "print(\"Training autoencoder...\")\n",
    "losses = train_autoencoder(autoencoder, data_loader, num_epochs=100)\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Evaluate reconstruction quality\n",
    "autoencoder.eval()\n",
    "with torch.no_grad():\n",
    "    test_reconstructed, test_latent = autoencoder(X_high[:100])\n",
    "    reconstruction_error = F.mse_loss(test_reconstructed, X_high[:100])\n",
    "    print(f\"Final reconstruction error: {reconstruction_error:.6f}\")\n",
    "\n",
    "# Visualize latent representations\n",
    "plt.subplot(1, 2, 2)\n",
    "latent_np = test_latent.numpy()\n",
    "plt.scatter(latent_np[:, 0], latent_np[:, 1], alpha=0.6)\n",
    "plt.title('Learned Latent Representation')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoders\n",
    "\n",
    "Denoising autoencoders learn robust representations by training to reconstruct clean data from corrupted inputs. This helps the model learn more meaningful features and improves generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising Autoencoder\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, dropout_rate=0.2):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),  # Add noise through dropout\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, add_noise=True):\n",
    "        if add_noise and self.training:\n",
    "            # Add Gaussian noise during training\n",
    "            noise = 0.1 * torch.randn_like(x)\n",
    "            noisy_x = torch.clamp(x + noise, 0, 1)\n",
    "        else:\n",
    "            noisy_x = x\n",
    "        \n",
    "        latent = self.encoder(noisy_x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        \n",
    "        return reconstructed, latent\n",
    "\n",
    "# Create and train denoising autoencoder\n",
    "denoising_ae = DenoisingAutoencoder(input_dim=50, hidden_dim=128, latent_dim=3)\n",
    "\n",
    "def train_denoising_ae(model, data_loader, num_epochs=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_x in data_loader:\n",
    "            # Forward pass with noise\n",
    "            reconstructed, _ = model(batch_x, add_noise=True)\n",
    "            \n",
    "            # Loss: reconstruct clean data from noisy input\n",
    "            loss = criterion(reconstructed, batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        losses.append(epoch_loss / len(data_loader))\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {losses[-1]:.6f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "print(\"Training denoising autoencoder...\")\n",
    "denoising_losses = train_denoising_ae(denoising_ae, data_loader, 80)\n",
    "\n",
    "# Compare denoising performance\n",
    "denoising_ae.eval()\n",
    "with torch.no_grad():\n",
    "    # Add noise to test data\n",
    "    test_data = X_high[:20]\n",
    "    noise = 0.2 * torch.randn_like(test_data)\n",
    "    noisy_test_data = torch.clamp(test_data + noise, 0, 1)\n",
    "    \n",
    "    # Reconstruct\n",
    "    denoised, _ = denoising_ae(noisy_test_data, add_noise=False)\n",
    "    \n",
    "    # Compute metrics\n",
    "    original_mse = F.mse_loss(noisy_test_data, test_data)\n",
    "    denoised_mse = F.mse_loss(denoised, test_data)\n",
    "    \n",
    "    print(f\"\\nDenoising Results:\")\n",
    "    print(f\"Noisy data MSE: {original_mse:.6f}\")\n",
    "    print(f\"Denoised data MSE: {denoised_mse:.6f}\")\n",
    "    print(f\"Improvement: {((original_mse - denoised_mse) / original_mse * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders (VAEs)\n",
    "\n",
    "VAEs extend autoencoders by learning a probabilistic latent space. Instead of encoding to a fixed point, they encode to a distribution (mean and variance), enabling generation of new samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variational Autoencoder implementation\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder network\n",
    "        self.encoder_hidden = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Latent space parameters\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)     # Mean\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim) # Log variance\n",
    "        \n",
    "        # Decoder network\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent parameters\"\"\"\n",
    "        hidden = self.encoder_hidden(x)\n",
    "        mu = self.fc_mu(hidden)\n",
    "        logvar = self.fc_logvar(hidden)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick: z = mu + sigma * epsilon\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode latent variable to reconstruction\"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        # Sample from latent distribution\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        # Decode\n",
    "        reconstructed = self.decode(z)\n",
    "        \n",
    "        return reconstructed, mu, logvar\n",
    "    \n",
    "    def generate(self, num_samples, device='cpu'):\n",
    "        \"\"\"Generate new samples from the learned distribution\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Sample from standard normal distribution\n",
    "            z = torch.randn(num_samples, self.fc_mu.out_features).to(device)\n",
    "            # Decode to generate new samples\n",
    "            generated = self.decode(z)\n",
    "        return generated\n",
    "\n",
    "# VAE loss function combines reconstruction loss and KL divergence\n",
    "def vae_loss_function(reconstructed, original, mu, logvar, beta=1.0):\n",
    "    \"\"\"VAE loss: reconstruction loss + KL divergence\"\"\"\n",
    "    # Reconstruction loss (binary cross-entropy)\n",
    "    reconstruction_loss = F.binary_cross_entropy(reconstructed, original, reduction='sum')\n",
    "    \n",
    "    # KL divergence loss (regularizes latent space to be close to standard normal)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = reconstruction_loss + beta * kl_loss\n",
    "    \n",
    "    return total_loss, reconstruction_loss, kl_loss\n",
    "\n",
    "# Create VAE\n",
    "vae = VAE(input_dim=50, hidden_dim=128, latent_dim=3)\n",
    "print(f\"VAE parameters: {sum(p.numel() for p in vae.parameters()):,}\")\n",
    "\n",
    "# Test VAE forward pass\n",
    "test_input = X_high[:5]\n",
    "recon, mu, logvar = vae(test_input)\n",
    "total_loss, recon_loss, kl_loss = vae_loss_function(recon, test_input, mu, logvar)\n",
    "\n",
    "print(f\"Test reconstruction shape: {recon.shape}\")\n",
    "print(f\"Test mu shape: {mu.shape}\")\n",
    "print(f\"Test logvar shape: {logvar.shape}\")\n",
    "print(f\"Total loss: {total_loss.item():.4f}\")\n",
    "print(f\"Reconstruction loss: {recon_loss.item():.4f}\")\n",
    "print(f\"KL loss: {kl_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Variational Autoencoders\n",
    "\n",
    "VAE training balances reconstruction quality with regularization of the latent space. The KL divergence term ensures the latent space follows a standard normal distribution, enabling generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for VAE\n",
    "def train_vae(model, data_loader, num_epochs=100, beta=1.0, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    losses = {'total': [], 'reconstruction': [], 'kl': []}\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = {'total': 0, 'reconstruction': 0, 'kl': 0}\n",
    "        \n",
    "        for batch_x in data_loader:\n",
    "            # Forward pass\n",
    "            reconstructed, mu, logvar = model(batch_x)\n",
    "            \n",
    "            # Compute loss\n",
    "            total_loss, recon_loss, kl_loss = vae_loss_function(\n",
    "                reconstructed, batch_x, mu, logvar, beta\n",
    "            )\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track losses\n",
    "            epoch_losses['total'] += total_loss.item()\n",
    "            epoch_losses['reconstruction'] += recon_loss.item()\n",
    "            epoch_losses['kl'] += kl_loss.item()\n",
    "        \n",
    "        # Average losses\n",
    "        for key in epoch_losses:\n",
    "            epoch_losses[key] /= len(data_loader)\n",
    "            losses[key].append(epoch_losses[key])\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            print(f\"  Total: {epoch_losses['total']:.4f}\")\n",
    "            print(f\"  Reconstruction: {epoch_losses['reconstruction']:.4f}\")\n",
    "            print(f\"  KL: {epoch_losses['kl']:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Train VAE\n",
    "print(\"Training VAE...\")\n",
    "vae_losses = train_vae(vae, data_loader, num_epochs=100, beta=1.0)\n",
    "\n",
    "# Plot training losses\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(vae_losses['total'])\n",
    "plt.title('Total Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(vae_losses['reconstruction'], label='Reconstruction')\n",
    "plt.plot(vae_losses['kl'], label='KL Divergence')\n",
    "plt.title('Loss Components')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Generate new samples\n",
    "vae.eval()\n",
    "generated_samples = vae.generate(100)\n",
    "\n",
    "# Visualize latent space\n",
    "with torch.no_grad():\n",
    "    test_mu, test_logvar = vae.encode(X_high[:200])\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(test_mu[:, 0].numpy(), test_mu[:, 1].numpy(), alpha=0.6, label='Encoded')\n",
    "# Sample from prior\n",
    "prior_samples = torch.randn(100, 2)\n",
    "plt.scatter(prior_samples[:, 0].numpy(), prior_samples[:, 1].numpy(), \n",
    "           alpha=0.6, label='Prior', marker='x')\n",
    "plt.title('Latent Space')\n",
    "plt.xlabel('Latent Dim 1')\n",
    "plt.ylabel('Latent Dim 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated samples shape: {generated_samples.shape}\")\n",
    "print(f\"Generated samples range: [{generated_samples.min():.3f}, {generated_samples.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks (GANs)\n",
    "\n",
    "GANs consist of two competing networks: a generator that creates fake data and a discriminator that tries to distinguish real from fake data. This adversarial training often produces high-quality generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, hidden_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(noise_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Tanh()  # Output in [-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        return self.network(noise)\n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()  # Output probability [0, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).view(-1)\n",
    "\n",
    "# Create simple 2D dataset for visualization\n",
    "def create_2d_data(n_samples=1000, dataset_type='moons'):\n",
    "    \"\"\"Create 2D datasets for GAN visualization\"\"\"\n",
    "    if dataset_type == 'moons':\n",
    "        data, _ = make_moons(n_samples=n_samples, noise=0.1, random_state=42)\n",
    "    elif dataset_type == 'blobs':\n",
    "        data, _ = make_blobs(n_samples=n_samples, centers=4, cluster_std=0.3, random_state=42)\n",
    "    else:  # circular\n",
    "        angles = np.random.uniform(0, 2*np.pi, n_samples)\n",
    "        radii = 2 + 0.5 * np.random.randn(n_samples)\n",
    "        data = np.column_stack([radii * np.cos(angles), radii * np.sin(angles)])\n",
    "    \n",
    "    # Normalize to [-1, 1] for tanh activation\n",
    "    data = 2 * (data - data.min()) / (data.max() - data.min()) - 1\n",
    "    return torch.FloatTensor(data)\n",
    "\n",
    "# Create 2D dataset\n",
    "real_data = create_2d_data(1000, 'moons')\n",
    "data_dim = real_data.shape[1]\n",
    "\n",
    "# Visualize real data\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6)\n",
    "plt.title('Real Data Distribution')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.grid(True)\n",
    "\n",
    "# Create GAN\n",
    "noise_dim = 2\n",
    "hidden_dim = 128\n",
    "\n",
    "generator = Generator(noise_dim, hidden_dim, data_dim)\n",
    "discriminator = Discriminator(data_dim, hidden_dim)\n",
    "\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "# Test generator\n",
    "test_noise = torch.randn(100, noise_dim)\n",
    "fake_data = generator(test_noise)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(fake_data[:, 0].detach().numpy(), fake_data[:, 1].detach().numpy(), alpha=0.6)\n",
    "plt.title('Initial Generated Data (Untrained)')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Real data shape: {real_data.shape}\")\n",
    "print(f\"Generated data shape: {fake_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GANs\n",
    "\n",
    "GAN training involves alternating between training the discriminator (to better distinguish real from fake) and the generator (to better fool the discriminator). This adversarial process can be unstable and requires careful tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN training function\n",
    "def train_gan(generator, discriminator, real_data, num_epochs=200, \n",
    "              batch_size=32, noise_dim=2, lr=0.0002):\n",
    "    \n",
    "    # Optimizers\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Data loader\n",
    "    dataset = TensorDataset(real_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Training metrics\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    \n",
    "    # Labels\n",
    "    real_label = 1.0\n",
    "    fake_label = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        \n",
    "        for batch_real in dataloader:\n",
    "            batch_real = batch_real[0]  # Extract from tuple\n",
    "            batch_size_actual = batch_real.size(0)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            discriminator.zero_grad()\n",
    "            \n",
    "            # Real data\n",
    "            real_labels = torch.full((batch_size_actual,), real_label, dtype=torch.float)\n",
    "            real_output = discriminator(batch_real)\n",
    "            d_loss_real = criterion(real_output, real_labels)\n",
    "            \n",
    "            # Fake data\n",
    "            noise = torch.randn(batch_size_actual, noise_dim)\n",
    "            fake_data = generator(noise)\n",
    "            fake_labels = torch.full((batch_size_actual,), fake_label, dtype=torch.float)\n",
    "            fake_output = discriminator(fake_data.detach())\n",
    "            d_loss_fake = criterion(fake_output, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            generator.zero_grad()\n",
    "            \n",
    "            # Generate fake data and try to fool discriminator\n",
    "            fake_output = discriminator(fake_data)\n",
    "            g_loss = criterion(fake_output, real_labels)  # Want discriminator to think it's real\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "        \n",
    "        # Average losses\n",
    "        d_losses.append(epoch_d_loss / len(dataloader))\n",
    "        g_losses.append(epoch_g_loss / len(dataloader))\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            print(f\"  D Loss: {d_losses[-1]:.4f}, G Loss: {g_losses[-1]:.4f}\")\n",
    "            print(f\"  D(real): {real_output.mean():.4f}, D(fake): {fake_output.mean():.4f}\")\n",
    "    \n",
    "    return d_losses, g_losses\n",
    "\n",
    "# Train GAN\n",
    "print(\"Training GAN...\")\n",
    "d_losses, g_losses = train_gan(generator, discriminator, real_data, \n",
    "                              num_epochs=200, batch_size=32)\n",
    "\n",
    "# Plot training losses\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(d_losses, label='Discriminator')\n",
    "plt.plot(g_losses, label='Generator')\n",
    "plt.title('Training Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Generate samples after training\n",
    "generator.eval()\n",
    "discriminator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Generate new samples\n",
    "    test_noise = torch.randn(1000, noise_dim)\n",
    "    generated_samples = generator(test_noise)\n",
    "    \n",
    "    # Evaluate discriminator on real and fake data\n",
    "    real_scores = discriminator(real_data[:1000])\n",
    "    fake_scores = discriminator(generated_samples)\n",
    "\n",
    "# Plot generated samples\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, label='Real', s=20)\n",
    "plt.scatter(generated_samples[:, 0], generated_samples[:, 1], \n",
    "           alpha=0.6, label='Generated', s=20)\n",
    "plt.title('Real vs Generated Data')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot discriminator scores\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(real_scores.numpy(), bins=30, alpha=0.7, label='Real', density=True)\n",
    "plt.hist(fake_scores.numpy(), bins=30, alpha=0.7, label='Generated', density=True)\n",
    "plt.title('Discriminator Scores')\n",
    "plt.xlabel('Score (Real Probability)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Real data scores - Mean: {real_scores.mean():.3f}, Std: {real_scores.std():.3f}\")\n",
    "print(f\"Generated data scores - Mean: {fake_scores.mean():.3f}, Std: {fake_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Learning\n",
    "\n",
    "Self-supervised learning creates supervisory signals from the data itself, without external labels. Common approaches include predicting masked tokens, next frames, or transformations applied to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-supervised learning: Predicting rotations\n",
    "class RotationPredictor(nn.Module):\n",
    "    \"\"\"Predict rotation angles applied to data (simplified example)\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, num_rotations=4):\n",
    "        super(RotationPredictor, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.rotation_classifier = nn.Linear(hidden_dim // 2, num_rotations)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        rotation_pred = self.rotation_classifier(features)\n",
    "        return rotation_pred, features\n",
    "\n",
    "# Create augmented data with rotations\n",
    "def create_rotation_task(data, rotation_angles=[0, 90, 180, 270]):\n",
    "    \"\"\"Create self-supervised rotation prediction task\"\"\"\n",
    "    augmented_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, angle in enumerate(rotation_angles):\n",
    "        # Simulate rotation by applying transformation matrix\n",
    "        # (This is a simplified 2D rotation for demonstration)\n",
    "        angle_rad = np.radians(angle)\n",
    "        rotation_matrix = np.array([\n",
    "            [np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "            [np.sin(angle_rad), np.cos(angle_rad)]\n",
    "        ])\n",
    "        \n",
    "        # Apply rotation to 2D data\n",
    "        if data.shape[1] == 2:\n",
    "            rotated = data @ rotation_matrix.T\n",
    "        else:\n",
    "            # For higher dimensional data, apply rotation to first 2 dimensions\n",
    "            rotated = data.clone()\n",
    "            rotated[:, :2] = data[:, :2] @ rotation_matrix.T\n",
    "        \n",
    "        augmented_data.append(rotated)\n",
    "        labels.extend([i] * len(data))\n",
    "    \n",
    "    all_data = torch.cat(augmented_data, dim=0)\n",
    "    all_labels = torch.LongTensor(labels)\n",
    "    \n",
    "    return all_data, all_labels\n",
    "\n",
    "# Create self-supervised learning task\n",
    "ssl_data, ssl_labels = create_rotation_task(real_data[:200])\n",
    "\n",
    "print(f\"Self-supervised data shape: {ssl_data.shape}\")\n",
    "print(f\"Self-supervised labels shape: {ssl_labels.shape}\")\n",
    "print(f\"Label distribution: {torch.bincount(ssl_labels)}\")\n",
    "\n",
    "# Visualize rotated data\n",
    "plt.figure(figsize=(12, 3))\n",
    "rotation_names = ['0°', '90°', '180°', '270°']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    mask = ssl_labels == i\n",
    "    plt.scatter(ssl_data[mask, 0], ssl_data[mask, 1], alpha=0.6, s=10)\n",
    "    plt.title(f'Rotation {rotation_names[i]}')\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Train rotation predictor\n",
    "rotation_model = RotationPredictor(input_dim=2, hidden_dim=64, num_rotations=4)\n",
    "\n",
    "def train_self_supervised(model, data, labels, num_epochs=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    dataset = TensorDataset(data, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_data, batch_labels in dataloader:\n",
    "            # Forward pass\n",
    "            rotation_pred, features = model(batch_data)\n",
    "            loss = criterion(rotation_pred, batch_labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(rotation_pred, 1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        losses.append(avg_loss)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "print(\"Training self-supervised rotation predictor...\")\n",
    "ssl_losses, ssl_accuracies = train_self_supervised(rotation_model, ssl_data, ssl_labels, 100)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(ssl_losses)\n",
    "plt.title('Self-Supervised Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ssl_accuracies)\n",
    "plt.title('Rotation Prediction Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final rotation prediction accuracy: {ssl_accuracies[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Learning\n",
    "\n",
    "Contrastive learning learns representations by pulling similar samples together and pushing dissimilar samples apart in the embedding space. This is particularly powerful for learning from unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple contrastive learning implementation\n",
    "class ContrastiveEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ContrastiveEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        # L2 normalize for cosine similarity\n",
    "        return F.normalize(features, p=2, dim=1)\n",
    "\n",
    "# Contrastive loss (simplified InfoNCE)\n",
    "def contrastive_loss(features1, features2, temperature=0.5):\n",
    "    \"\"\"Compute contrastive loss between two sets of features\"\"\"\n",
    "    batch_size = features1.shape[0]\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarity_matrix = torch.mm(features1, features2.t()) / temperature\n",
    "    \n",
    "    # Create labels (diagonal elements are positive pairs)\n",
    "    labels = torch.arange(batch_size).long()\n",
    "    \n",
    "    # Compute cross-entropy loss\n",
    "    loss = F.cross_entropy(similarity_matrix, labels)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Data augmentation for contrastive learning\n",
    "def augment_data(data, noise_std=0.1):\n",
    "    \"\"\"Apply simple augmentations\"\"\"\n",
    "    # Add Gaussian noise\n",
    "    augmented = data + torch.randn_like(data) * noise_std\n",
    "    return augmented\n",
    "\n",
    "# Create contrastive learning setup\n",
    "contrastive_encoder = ContrastiveEncoder(input_dim=2, hidden_dim=64, output_dim=16)\n",
    "\n",
    "def train_contrastive(model, data, num_epochs=200, batch_size=32, temperature=0.5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    dataset = TensorDataset(data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_data in dataloader:\n",
    "            batch_data = batch_data[0]\n",
    "            \n",
    "            # Create two augmented views of the same data\n",
    "            view1 = augment_data(batch_data, 0.1)\n",
    "            view2 = augment_data(batch_data, 0.1)\n",
    "            \n",
    "            # Encode both views\n",
    "            features1 = model(view1)\n",
    "            features2 = model(view2)\n",
    "            \n",
    "            # Compute contrastive loss\n",
    "            loss = contrastive_loss(features1, features2, temperature)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        losses.append(epoch_loss / len(dataloader))\n",
    "        \n",
    "        if (epoch + 1) % 40 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {losses[-1]:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Train contrastive model\n",
    "print(\"Training contrastive learning model...\")\n",
    "contrastive_losses = train_contrastive(contrastive_encoder, real_data, num_epochs=200)\n",
    "\n",
    "# Evaluate learned representations\n",
    "contrastive_encoder.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = contrastive_encoder(real_data)\n",
    "    \n",
    "    # Apply k-means clustering on learned embeddings\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(embeddings.numpy())\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(contrastive_losses)\n",
    "plt.title('Contrastive Learning Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(real_data[:, 0], real_data[:, 1], c=cluster_labels, cmap='viridis', alpha=0.7)\n",
    "plt.title('Clustering on Original Data')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Visualize embeddings (first 2 dimensions)\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], c=cluster_labels, cmap='viridis', alpha=0.7)\n",
    "plt.title('Learned Embeddings (2D projection)')\n",
    "plt.xlabel('Embedding Dim 1')\n",
    "plt.ylabel('Embedding Dim 2')\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Learned embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"Embedding range: [{embeddings.min():.3f}, {embeddings.max():.3f}]\")\n",
    "print(f\"Number of clusters found: {len(np.unique(cluster_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model Comparison and Best Practices\n",
    "\n",
    "Each generative model has different strengths, use cases, and training considerations. Understanding when to use each approach is crucial for successful applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generative Models and Unsupervised Learning: Summary and Best Practices\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_comparison = {\n",
    "    \"Autoencoders\": {\n",
    "        \"Strengths\": [\n",
    "            \"Simple to implement and train\",\n",
    "            \"Good for dimensionality reduction\",\n",
    "            \"Stable training process\",\n",
    "            \"Interpretable latent space\"\n",
    "        ],\n",
    "        \"Weaknesses\": [\n",
    "            \"Limited generation quality\",\n",
    "            \"Deterministic encoding\",\n",
    "            \"May not capture data distribution well\"\n",
    "        ],\n",
    "        \"Use Cases\": [\n",
    "            \"Dimensionality reduction\",\n",
    "            \"Anomaly detection\",\n",
    "            \"Data denoising\",\n",
    "            \"Feature learning\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"VAEs\": {\n",
    "        \"Strengths\": [\n",
    "            \"Probabilistic latent space\",\n",
    "            \"Principled framework\",\n",
    "            \"Good for interpolation\",\n",
    "            \"Stable training\"\n",
    "        ],\n",
    "        \"Weaknesses\": [\n",
    "            \"Blurry generations\",\n",
    "            \"KL divergence can be tricky\",\n",
    "            \"May not capture sharp details\"\n",
    "        ],\n",
    "        \"Use Cases\": [\n",
    "            \"Data generation\",\n",
    "            \"Latent space exploration\",\n",
    "            \"Semi-supervised learning\",\n",
    "            \"Representation learning\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"GANs\": {\n",
    "        \"Strengths\": [\n",
    "            \"High-quality generations\",\n",
    "            \"Sharp, realistic outputs\",\n",
    "            \"No assumptions about data distribution\",\n",
    "            \"Powerful for image generation\"\n",
    "        ],\n",
    "        \"Weaknesses\": [\n",
    "            \"Unstable training\",\n",
    "            \"Mode collapse issues\",\n",
    "            \"Difficult to evaluate\",\n",
    "            \"No explicit likelihood\"\n",
    "        ],\n",
    "        \"Use Cases\": [\n",
    "            \"High-quality image generation\",\n",
    "            \"Data augmentation\",\n",
    "            \"Style transfer\",\n",
    "            \"Super-resolution\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name, info in models_comparison.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Strengths:\")\n",
    "    for strength in info[\"Strengths\"]:\n",
    "        print(f\"    + {strength}\")\n",
    "    print(f\"  Weaknesses:\")\n",
    "    for weakness in info[\"Weaknesses\"]:\n",
    "        print(f\"    - {weakness}\")\n",
    "    print(f\"  Best for: {', '.join(info['Use Cases'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING BEST PRACTICES:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "training_tips = {\n",
    "    \"General\": [\n",
    "        \"Start with simple architectures and gradually increase complexity\",\n",
    "        \"Use appropriate learning rates (often lower than supervised learning)\",\n",
    "        \"Monitor training stability and convergence\",\n",
    "        \"Use validation data to prevent overfitting\",\n",
    "        \"Consider data preprocessing and normalization carefully\"\n",
    "    ],\n",
    "    \n",
    "    \"Autoencoders\": [\n",
    "        \"Choose bottleneck size carefully (not too small, not too large)\",\n",
    "        \"Use skip connections for better reconstruction\",\n",
    "        \"Add noise for denoising autoencoders\",\n",
    "        \"Consider sparse regularization for interpretability\"\n",
    "    ],\n",
    "    \n",
    "    \"VAEs\": [\n",
    "        \"Balance reconstruction and KL losses with β parameter\",\n",
    "        \"Use β-annealing (start with β=0, gradually increase)\",\n",
    "        \"Monitor KL collapse (posterior collapse)\",\n",
    "        \"Consider different prior distributions\"\n",
    "    ],\n",
    "    \n",
    "    \"GANs\": [\n",
    "        \"Use different learning rates for G and D\",\n",
    "        \"Apply spectral normalization for stability\",\n",
    "        \"Use gradient penalty instead of weight clipping\",\n",
    "        \"Monitor discriminator/generator balance\",\n",
    "        \"Use progressive growing for high-resolution images\"\n",
    "    ],\n",
    "    \n",
    "    \"Self-Supervised Learning\": [\n",
    "        \"Design pretext tasks relevant to downstream tasks\",\n",
    "        \"Use strong data augmentations\",\n",
    "        \"Consider contrastive learning for representation quality\",\n",
    "        \"Evaluate learned representations on downstream tasks\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, tips in training_tips.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for tip in tips:\n",
    "        print(f\"  • {tip}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION METRICS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "evaluation_metrics = {\n",
    "    \"Generation Quality\": [\n",
    "        \"Inception Score (IS) - for image quality\",\n",
    "        \"Fréchet Inception Distance (FID) - distribution similarity\",\n",
    "        \"Perceptual metrics - human evaluation\",\n",
    "        \"BLEU scores - for text generation\"\n",
    "    ],\n",
    "    \"Representation Quality\": [\n",
    "        \"Downstream task performance\",\n",
    "        \"Linear probe accuracy\",\n",
    "        \"Clustering metrics (silhouette score, ARI)\",\n",
    "        \"t-SNE/UMAP visualizations\"\n",
    "    ],\n",
    "    \"Model-Specific\": [\n",
    "        \"Reconstruction error (AE, VAE)\",\n",
    "        \"Log-likelihood (VAE)\",\n",
    "        \"KL divergence (VAE)\",\n",
    "        \"Mode coverage (GAN)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, metrics in evaluation_metrics.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  • {metric}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHOOSING THE RIGHT APPROACH:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "decision_guide = {\n",
    "    \"Need high-quality generations?\": \"Consider GANs or advanced VAEs\",\n",
    "    \"Want interpretable latent space?\": \"Use VAEs or β-VAEs\",\n",
    "    \"Limited computational resources?\": \"Start with autoencoders\",\n",
    "    \"Need stable training?\": \"Avoid GANs, prefer VAEs or autoencoders\",\n",
    "    \"Working with images?\": \"GANs often work best\",\n",
    "    \"Working with time series?\": \"Consider RNN-based VAEs or autoencoders\",\n",
    "    \"Need to generate diverse samples?\": \"Check for mode collapse in GANs\",\n",
    "    \"Want to learn representations?\": \"Self-supervised or contrastive learning\"\n",
    "}\n",
    "\n",
    "for question, answer in decision_guide.items():\n",
    "    print(f\"\\n{question}\")\n",
    "    print(f\"  → {answer}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Remember: The choice of generative model depends heavily on your specific\")\n",
    "print(\"use case, data type, computational constraints, and quality requirements.\")\n",
    "print(\"Always start simple and iterate based on results!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}