{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Practice Questions Part 7: Ensemble Methods and Boosting\n",
    "\n",
    "This notebook covers ensemble learning methods, with emphasis on bagging, boosting, and stacking techniques. Each question includes theoretical foundations, algorithmic implementations, and practical considerations for building robust ensemble models.\n",
    "\n",
    "**Topics Covered:**\n",
    "- Random Forest and bagging methods\n",
    "- AdaBoost and gradient boosting algorithms\n",
    "- XGBoost and advanced boosting techniques\n",
    "- Stacking and blending ensemble strategies\n",
    "- Ensemble diversity and variance reduction\n",
    "\n",
    "**Format:** Each question includes theory, implementation, and empirical analysis sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification, make_regression, load_breast_cancer, load_boston\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Random Forest and Bagging Implementation\n",
    "\n",
    "**Question:** Implement Random Forest from scratch and analyze how bootstrap sampling and feature randomness contribute to ensemble performance. Compare with bagging and single decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory\n",
    "\n",
    "**Bagging (Bootstrap Aggregating):**\n",
    "1. Create $B$ bootstrap samples from training data\n",
    "2. Train model on each bootstrap sample\n",
    "3. Aggregate predictions: majority vote (classification) or average (regression)\n",
    "\n",
    "**Random Forest Extensions:**\n",
    "- **Feature randomness**: At each split, consider only $\\sqrt{p}$ features (classification) or $p/3$ (regression)\n",
    "- **Extra randomness**: Random thresholds for splits (Extra Trees)\n",
    "\n",
    "**Variance Reduction:**\n",
    "For identical models with variance $\\sigma^2$ and correlation $\\rho$:\n",
    "$$\\text{Var}(\\text{ensemble}) = \\rho \\sigma^2 + \\frac{1-\\rho}{B} \\sigma^2$$\n",
    "\n",
    "**Out-of-Bag (OOB) Error:**\n",
    "- Each bootstrap sample excludes ~37% of original data\n",
    "- Use excluded samples for unbiased error estimation\n",
    "- $\\text{OOB Error} = \\frac{1}{n} \\sum_{i=1}^n I(y_i \\neq \\hat{y}_i^{\\text{OOB}})$\n",
    "\n",
    "**Feature Importance:**\n",
    "$$\\text{Importance}_j = \\frac{1}{B} \\sum_{b=1}^B \\sum_{t \\in T_b} p_t \\Delta I_t \\cdot I(\\text{split on feature } j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class RandomForestCustom:\n",
    "    \"\"\"Random Forest implementation from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_features='sqrt', max_depth=None, \n",
    "                 min_samples_split=2, min_samples_leaf=1, bootstrap=True, \n",
    "                 oob_score=False, random_state=None, task='classification'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.bootstrap = bootstrap\n",
    "        self.oob_score = oob_score\n",
    "        self.random_state = random_state\n",
    "        self.task = task\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        self.feature_importances_ = None\n",
    "        self.oob_score_ = None\n",
    "        self.oob_predictions_ = None\n",
    "        \n",
    "    def _get_max_features(self, n_features):\n",
    "        \"\"\"Calculate number of features to consider at each split.\"\"\"\n",
    "        if self.max_features == 'sqrt':\n",
    "            return int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            return int(np.log2(n_features))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            return min(self.max_features, n_features)\n",
    "        elif isinstance(self.max_features, float):\n",
    "            return int(self.max_features * n_features)\n",
    "        else:\n",
    "            return n_features\n",
    "    \n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        \"\"\"Create bootstrap sample.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        if self.bootstrap:\n",
    "            indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        else:\n",
    "            indices = np.arange(n_samples)\n",
    "        \n",
    "        return X[indices], y[indices], indices\n",
    "    \n",
    "    def _calculate_oob_predictions(self, X, y, bootstrap_indices):\n",
    "        \"\"\"Calculate out-of-bag predictions.\"\"\"\n",
    "        if not self.oob_score:\n",
    "            return\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        oob_predictions = np.full((n_samples, len(self.estimators_)), np.nan)\n",
    "        \n",
    "        for i, (estimator, indices) in enumerate(zip(self.estimators_, bootstrap_indices)):\n",
    "            # Find out-of-bag samples\n",
    "            oob_indices = np.setdiff1d(np.arange(n_samples), indices)\n",
    "            \n",
    "            if len(oob_indices) > 0:\n",
    "                if self.task == 'classification':\n",
    "                    oob_pred = estimator.predict(X[oob_indices])\n",
    "                else:\n",
    "                    oob_pred = estimator.predict(X[oob_indices])\n",
    "                \n",
    "                oob_predictions[oob_indices, i] = oob_pred\n",
    "        \n",
    "        # Aggregate OOB predictions\n",
    "        final_oob_predictions = []\n",
    "        for i in range(n_samples):\n",
    "            valid_predictions = oob_predictions[i, ~np.isnan(oob_predictions[i])]\n",
    "            if len(valid_predictions) > 0:\n",
    "                if self.task == 'classification':\n",
    "                    # Majority vote\n",
    "                    final_oob_predictions.append(Counter(valid_predictions).most_common(1)[0][0])\n",
    "                else:\n",
    "                    # Average\n",
    "                    final_oob_predictions.append(np.mean(valid_predictions))\n",
    "            else:\n",
    "                final_oob_predictions.append(np.nan)\n",
    "        \n",
    "        self.oob_predictions_ = np.array(final_oob_predictions)\n",
    "        \n",
    "        # Calculate OOB score\n",
    "        valid_mask = ~np.isnan(self.oob_predictions_)\n",
    "        if np.sum(valid_mask) > 0:\n",
    "            if self.task == 'classification':\n",
    "                self.oob_score_ = accuracy_score(\n",
    "                    y[valid_mask], \n",
    "                    self.oob_predictions_[valid_mask]\n",
    "                )\n",
    "            else:\n",
    "                self.oob_score_ = -mean_squared_error(\n",
    "                    y[valid_mask], \n",
    "                    self.oob_predictions_[valid_mask]\n",
    "                )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the Random Forest.\"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        max_features = self._get_max_features(n_features)\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        bootstrap_indices = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Create bootstrap sample\n",
    "            X_bootstrap, y_bootstrap, indices = self._bootstrap_sample(X, y)\n",
    "            bootstrap_indices.append(indices)\n",
    "            \n",
    "            # Create and fit decision tree\n",
    "            if self.task == 'classification':\n",
    "                estimator = DecisionTreeClassifier(\n",
    "                    max_features=max_features,\n",
    "                    max_depth=self.max_depth,\n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    min_samples_leaf=self.min_samples_leaf,\n",
    "                    random_state=None  # Let each tree be different\n",
    "                )\n",
    "            else:\n",
    "                estimator = DecisionTreeRegressor(\n",
    "                    max_features=max_features,\n",
    "                    max_depth=self.max_depth,\n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    min_samples_leaf=self.min_samples_leaf,\n",
    "                    random_state=None\n",
    "                )\n",
    "            \n",
    "            estimator.fit(X_bootstrap, y_bootstrap)\n",
    "            self.estimators_.append(estimator)\n",
    "        \n",
    "        # Calculate feature importances\n",
    "        self.feature_importances_ = np.mean(\n",
    "            [estimator.feature_importances_ for estimator in self.estimators_], axis=0\n",
    "        )\n",
    "        \n",
    "        # Calculate OOB score\n",
    "        self._calculate_oob_predictions(X, y, bootstrap_indices)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Get predictions from all estimators\n",
    "        predictions = np.array([estimator.predict(X) for estimator in self.estimators_])\n",
    "        \n",
    "        if self.task == 'classification':\n",
    "            # Majority vote\n",
    "            final_predictions = []\n",
    "            for i in range(X.shape[0]):\n",
    "                votes = predictions[:, i]\n",
    "                final_predictions.append(Counter(votes).most_common(1)[0][0])\n",
    "            return np.array(final_predictions)\n",
    "        else:\n",
    "            # Average\n",
    "            return np.mean(predictions, axis=0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities (classification only).\"\"\"\n",
    "        if self.task != 'classification':\n",
    "            raise ValueError(\"predict_proba only available for classification\")\n",
    "        \n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Get probability predictions from all estimators\n",
    "        all_probabilities = [estimator.predict_proba(X) for estimator in self.estimators_]\n",
    "        \n",
    "        # Average probabilities\n",
    "        return np.mean(all_probabilities, axis=0)\n",
    "\n",
    "# Generate datasets\n",
    "X_cls, y_cls = make_classification(n_samples=1000, n_features=20, n_informative=10, \n",
    "                                  n_redundant=5, n_clusters_per_class=1, random_state=42)\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.3, random_state=42)\n",
    "\n",
    "# Compare different ensemble approaches\n",
    "models = {\n",
    "    'Single Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Bagging': BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, random_state=42),\n",
    "    'Random Forest (sklearn)': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Random Forest (custom)': RandomForestCustom(n_estimators=100, oob_score=True, random_state=42),\n",
    "    'Extra Trees': RandomForestCustom(n_estimators=100, max_features='sqrt', bootstrap=False, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "fitted_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_cls, y_train_cls)\n",
    "    y_pred = model.predict(X_test_cls)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_cls, y_pred)\n",
    "    \n",
    "    # Get OOB score if available\n",
    "    oob_score = getattr(model, 'oob_score_', 'N/A')\n",
    "    \n",
    "    results[name] = {\n",
    "        'test_accuracy': accuracy,\n",
    "        'oob_score': oob_score\n",
    "    }\n",
    "    fitted_models[name] = model\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Ensemble Methods Comparison:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ensemble diversity and variance reduction\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Performance comparison\n",
    "model_names = list(results.keys())\n",
    "test_accuracies = [results[name]['test_accuracy'] for name in model_names]\n",
    "oob_scores = [results[name]['oob_score'] if results[name]['oob_score'] != 'N/A' else 0 for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[0, 0].bar(x_pos - width/2, test_accuracies, width, label='Test Accuracy', alpha=0.8)\n",
    "bars2 = axes[0, 0].bar(x_pos + width/2, oob_scores, width, label='OOB Score', alpha=0.8)\n",
    "\n",
    "axes[0, 0].set_xlabel('Models')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_title('Model Performance Comparison')\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ensemble size vs performance\n",
    "ensemble_sizes = range(1, 101, 10)\n",
    "rf_performance = []\n",
    "bagging_performance = []\n",
    "\n",
    "for size in ensemble_sizes:\n",
    "    # Random Forest\n",
    "    rf = RandomForestCustom(n_estimators=size, random_state=42)\n",
    "    rf.fit(X_train_cls, y_train_cls)\n",
    "    rf_acc = accuracy_score(y_test_cls, rf.predict(X_test_cls))\n",
    "    rf_performance.append(rf_acc)\n",
    "    \n",
    "    # Bagging\n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(), n_estimators=size, random_state=42)\n",
    "    bagging.fit(X_train_cls, y_train_cls)\n",
    "    bagging_acc = accuracy_score(y_test_cls, bagging.predict(X_test_cls))\n",
    "    bagging_performance.append(bagging_acc)\n",
    "\n",
    "axes[0, 1].plot(ensemble_sizes, rf_performance, 'o-', label='Random Forest', linewidth=2, markersize=6)\n",
    "axes[0, 1].plot(ensemble_sizes, bagging_performance, 's-', label='Bagging', linewidth=2, markersize=6)\n",
    "axes[0, 1].set_xlabel('Number of Estimators')\n",
    "axes[0, 1].set_ylabel('Test Accuracy')\n",
    "axes[0, 1].set_title('Ensemble Size vs Performance')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance comparison\n",
    "rf_model = fitted_models['Random Forest (custom)']\n",
    "single_tree = fitted_models['Single Tree']\n",
    "\n",
    "feature_names = [f'Feature_{i}' for i in range(X_cls.shape[1])]\n",
    "x_features = np.arange(len(feature_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 2].bar(x_features - width/2, rf_model.feature_importances_, width, \n",
    "              label='Random Forest', alpha=0.8)\n",
    "axes[0, 2].bar(x_features + width/2, single_tree.feature_importances_, width, \n",
    "              label='Single Tree', alpha=0.8)\n",
    "axes[0, 2].set_xlabel('Features')\n",
    "axes[0, 2].set_ylabel('Importance')\n",
    "axes[0, 2].set_title('Feature Importance Comparison')\n",
    "axes[0, 2].set_xticks(x_features)\n",
    "axes[0, 2].set_xticklabels([f'F{i}' for i in range(len(feature_names))], rotation=45)\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Variance analysis using bootstrap\n",
    "n_bootstrap = 50\n",
    "single_tree_vars = []\n",
    "rf_vars = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    # Bootstrap sample\n",
    "    bootstrap_idx = np.random.choice(len(X_train_cls), len(X_train_cls), replace=True)\n",
    "    X_bootstrap = X_train_cls[bootstrap_idx]\n",
    "    y_bootstrap = y_train_cls[bootstrap_idx]\n",
    "    \n",
    "    # Single tree\n",
    "    tree = DecisionTreeClassifier(random_state=None)\n",
    "    tree.fit(X_bootstrap, y_bootstrap)\n",
    "    tree_pred = tree.predict(X_test_cls)\n",
    "    single_tree_vars.append(accuracy_score(y_test_cls, tree_pred))\n",
    "    \n",
    "    # Random Forest\n",
    "    rf = RandomForestCustom(n_estimators=10, random_state=None)\n",
    "    rf.fit(X_bootstrap, y_bootstrap)\n",
    "    rf_pred = rf.predict(X_test_cls)\n",
    "    rf_vars.append(accuracy_score(y_test_cls, rf_pred))\n",
    "\n",
    "# Plot variance comparison\n",
    "models_var = ['Single Tree', 'Random Forest']\n",
    "variances = [np.var(single_tree_vars), np.var(rf_vars)]\n",
    "means = [np.mean(single_tree_vars), np.mean(rf_vars)]\n",
    "\n",
    "axes[1, 0].bar(models_var, variances, alpha=0.7, color=['red', 'green'])\n",
    "axes[1, 0].set_ylabel('Variance of Accuracy')\n",
    "axes[1, 0].set_title('Model Variance Comparison')\n",
    "for i, (model, var) in enumerate(zip(models_var, variances)):\n",
    "    axes[1, 0].text(i, var + 0.0001, f'{var:.4f}', ha='center', va='bottom')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Individual tree performance distribution\n",
    "rf_custom = fitted_models['Random Forest (custom)']\n",
    "individual_accuracies = []\n",
    "\n",
    "for estimator in rf_custom.estimators_:\n",
    "    pred = estimator.predict(X_test_cls)\n",
    "    acc = accuracy_score(y_test_cls, pred)\n",
    "    individual_accuracies.append(acc)\n",
    "\n",
    "axes[1, 1].hist(individual_accuracies, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].axvline(np.mean(individual_accuracies), color='red', linestyle='--', \n",
    "                  linewidth=2, label=f'Mean: {np.mean(individual_accuracies):.3f}')\n",
    "axes[1, 1].axvline(results['Random Forest (custom)']['test_accuracy'], color='green', \n",
    "                  linestyle='--', linewidth=2, label=f'Ensemble: {results[\"Random Forest (custom)\"][\"test_accuracy\"]:.3f}')\n",
    "axes[1, 1].set_xlabel('Individual Tree Accuracy')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Individual Tree Performance')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature randomness effect\n",
    "max_features_options = [1, 2, 5, 10, 15, 20]  # Number of features to consider\n",
    "feature_randomness_performance = []\n",
    "\n",
    "for max_feat in max_features_options:\n",
    "    rf_feat = RandomForestClassifier(n_estimators=50, max_features=max_feat, random_state=42)\n",
    "    rf_feat.fit(X_train_cls, y_train_cls)\n",
    "    acc = accuracy_score(y_test_cls, rf_feat.predict(X_test_cls))\n",
    "    feature_randomness_performance.append(acc)\n",
    "\n",
    "axes[1, 2].plot(max_features_options, feature_randomness_performance, 'o-', linewidth=2, markersize=8)\n",
    "axes[1, 2].axvline(np.sqrt(X_cls.shape[1]), color='red', linestyle='--', \n",
    "                  alpha=0.7, label=f'√p = {int(np.sqrt(X_cls.shape[1]))}')\n",
    "axes[1, 2].set_xlabel('Max Features per Split')\n",
    "axes[1, 2].set_ylabel('Test Accuracy')\n",
    "axes[1, 2].set_title('Effect of Feature Randomness')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print analysis\n",
    "print(f\"\\nVariance Reduction Analysis:\")\n",
    "print(f\"Single Tree Variance: {np.var(single_tree_vars):.6f}\")\n",
    "print(f\"Random Forest Variance: {np.var(rf_vars):.6f}\")\n",
    "print(f\"Variance Reduction: {(1 - np.var(rf_vars)/np.var(single_tree_vars))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nOOB Score Analysis:\")\n",
    "if rf_custom.oob_score_ is not None:\n",
    "    print(f\"Custom RF OOB Score: {rf_custom.oob_score_:.4f}\")\n",
    "    print(f\"Custom RF Test Score: {results['Random Forest (custom)']['test_accuracy']:.4f}\")\n",
    "    print(f\"OOB vs Test difference: {abs(rf_custom.oob_score_ - results['Random Forest (custom)']['test_accuracy']):.4f}\")\n",
    "\n",
    "print(f\"\\nIndividual Tree Performance:\")\n",
    "print(f\"Mean individual accuracy: {np.mean(individual_accuracies):.4f}\")\n",
    "print(f\"Ensemble accuracy: {results['Random Forest (custom)']['test_accuracy']:.4f}\")\n",
    "print(f\"Ensemble improvement: {(results['Random Forest (custom)']['test_accuracy'] - np.mean(individual_accuracies))*100:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: AdaBoost and Gradient Boosting Implementation\n",
    "\n",
    "**Question:** Implement AdaBoost and Gradient Boosting from scratch. Analyze how sequential learning and error correction contribute to ensemble performance compared to parallel ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory\n",
    "\n",
    "**AdaBoost Algorithm:**\n",
    "1. Initialize weights: $w_i^{(1)} = \\frac{1}{n}$ for all samples\n",
    "2. For $t = 1, 2, \\ldots, T$:\n",
    "   - Train weak learner $h_t$ on weighted data\n",
    "   - Calculate error: $\\epsilon_t = \\sum_{i=1}^n w_i^{(t)} I(h_t(x_i) \\neq y_i)$\n",
    "   - Calculate coefficient: $\\alpha_t = \\frac{1}{2} \\ln\\left(\\frac{1-\\epsilon_t}{\\epsilon_t}\\right)$\n",
    "   - Update weights: $w_i^{(t+1)} = w_i^{(t)} \\exp(-\\alpha_t y_i h_t(x_i))$\n",
    "   - Normalize weights\n",
    "3. Final prediction: $H(x) = \\text{sign}\\left(\\sum_{t=1}^T \\alpha_t h_t(x)\\right)$\n",
    "\n",
    "**Gradient Boosting:**\n",
    "1. Initialize: $F_0(x) = \\arg\\min_\\gamma \\sum_{i=1}^n L(y_i, \\gamma)$\n",
    "2. For $t = 1, 2, \\ldots, T$:\n",
    "   - Compute negative gradients: $r_{it} = -\\left[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}\\right]_{F=F_{t-1}}$\n",
    "   - Fit base learner $h_t$ to residuals $r_{it}$\n",
    "   - Find optimal step size: $\\gamma_t = \\arg\\min_\\gamma \\sum_{i=1}^n L(y_i, F_{t-1}(x_i) + \\gamma h_t(x_i))$\n",
    "   - Update: $F_t(x) = F_{t-1}(x) + \\gamma_t h_t(x)$\n",
    "\n",
    "**Key Differences:**\n",
    "- **AdaBoost**: Reweights samples, focuses on misclassified examples\n",
    "- **Gradient Boosting**: Fits to pseudo-residuals, general loss functions\n",
    "- **Sequential vs Parallel**: Boosting is sequential (each model depends on previous), bagging is parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostCustom:\n",
    "    \"\"\"AdaBoost implementation from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=50, learning_rate=1.0, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = []\n",
    "        self.estimator_errors_ = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit AdaBoost classifier.\"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Convert labels to -1, 1 for AdaBoost\n",
    "        y_ada = np.where(y == 0, -1, 1)\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Initialize weights\n",
    "        sample_weights = np.ones(n_samples) / n_samples\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = []\n",
    "        self.estimator_errors_ = []\n",
    "        \n",
    "        for t in range(self.n_estimators):\n",
    "            # Train weak learner with weighted samples\n",
    "            estimator = DecisionTreeClassifier(max_depth=1, random_state=None)  # Decision stump\n",
    "            estimator.fit(X, y, sample_weight=sample_weights)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = estimator.predict(X)\n",
    "            y_pred_ada = np.where(y_pred == 0, -1, 1)\n",
    "            \n",
    "            # Calculate weighted error\n",
    "            incorrect = y_pred_ada != y_ada\n",
    "            error = np.sum(sample_weights * incorrect) / np.sum(sample_weights)\n",
    "            \n",
    "            # Avoid division by zero and ensure error < 0.5\n",
    "            error = np.clip(error, 1e-10, 0.5 - 1e-10)\n",
    "            \n",
    "            # Calculate alpha (estimator weight)\n",
    "            alpha = self.learning_rate * 0.5 * np.log((1 - error) / error)\n",
    "            \n",
    "            # Update sample weights\n",
    "            sample_weights *= np.exp(-alpha * y_ada * y_pred_ada)\n",
    "            sample_weights /= np.sum(sample_weights)  # Normalize\n",
    "            \n",
    "            # Store estimator and its weight\n",
    "            self.estimators_.append(estimator)\n",
    "            self.estimator_weights_.append(alpha)\n",
    "            self.estimator_errors_.append(error)\n",
    "            \n",
    "            # Early stopping if perfect classification\n",
    "            if error == 0:\n",
    "                break\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using AdaBoost.\"\"\"\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Weighted combination of weak learners\n",
    "        decision_scores = np.zeros(X.shape[0])\n",
    "        \n",
    "        for estimator, alpha in zip(self.estimators_, self.estimator_weights_):\n",
    "            pred = estimator.predict(X)\n",
    "            pred_ada = np.where(pred == 0, -1, 1)\n",
    "            decision_scores += alpha * pred_ada\n",
    "        \n",
    "        # Convert back to 0, 1 labels\n",
    "        final_predictions = np.where(decision_scores >= 0, 1, 0)\n",
    "        return final_predictions\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Get decision scores.\"\"\"\n",
    "        X = np.array(X)\n",
    "        \n",
    "        decision_scores = np.zeros(X.shape[0])\n",
    "        \n",
    "        for estimator, alpha in zip(self.estimators_, self.estimator_weights_):\n",
    "            pred = estimator.predict(X)\n",
    "            pred_ada = np.where(pred == 0, -1, 1)\n",
    "            decision_scores += alpha * pred_ada\n",
    "        \n",
    "        return decision_scores\n",
    "\n",
    "class GradientBoostingCustom:\n",
    "    \"\"\"Gradient Boosting implementation from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        self.initial_prediction_ = None\n",
    "        self.train_scores_ = []\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"Stable sigmoid function.\"\"\"\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _log_loss_gradient(self, y_true, y_pred_prob):\n",
    "        \"\"\"Compute gradient of log loss.\"\"\"\n",
    "        return y_pred_prob - y_true\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit Gradient Boosting classifier.\"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        # Initialize with log-odds\n",
    "        positive_rate = np.mean(y)\n",
    "        positive_rate = np.clip(positive_rate, 1e-10, 1 - 1e-10)  # Avoid log(0)\n",
    "        self.initial_prediction_ = np.log(positive_rate / (1 - positive_rate))\n",
    "        \n",
    "        # Initialize predictions\n",
    "        f_x = np.full(len(y), self.initial_prediction_)\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        self.train_scores_ = []\n",
    "        \n",
    "        for t in range(self.n_estimators):\n",
    "            # Convert to probabilities\n",
    "            y_pred_prob = self._sigmoid(f_x)\n",
    "            \n",
    "            # Compute negative gradients (residuals)\n",
    "            residuals = -self._log_loss_gradient(y, y_pred_prob)\n",
    "            \n",
    "            # Fit regression tree to residuals\n",
    "            estimator = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                random_state=None\n",
    "            )\n",
    "            estimator.fit(X, residuals)\n",
    "            \n",
    "            # Update predictions\n",
    "            update = estimator.predict(X)\n",
    "            f_x += self.learning_rate * update\n",
    "            \n",
    "            # Store estimator\n",
    "            self.estimators_.append(estimator)\n",
    "            \n",
    "            # Calculate training score\n",
    "            y_pred_prob_updated = self._sigmoid(f_x)\n",
    "            train_accuracy = accuracy_score(y, (y_pred_prob_updated >= 0.5).astype(int))\n",
    "            self.train_scores_.append(train_accuracy)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using Gradient Boosting.\"\"\"\n",
    "        decision_scores = self.decision_function(X)\n",
    "        probabilities = self._sigmoid(decision_scores)\n",
    "        return (probabilities >= 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities.\"\"\"\n",
    "        decision_scores = self.decision_function(X)\n",
    "        probabilities = self._sigmoid(decision_scores)\n",
    "        return np.column_stack([1 - probabilities, probabilities])\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Get decision scores.\"\"\"\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Start with initial prediction\n",
    "        decision_scores = np.full(X.shape[0], self.initial_prediction_)\n",
    "        \n",
    "        # Add contributions from all estimators\n",
    "        for estimator in self.estimators_:\n",
    "            decision_scores += self.learning_rate * estimator.predict(X)\n",
    "        \n",
    "        return decision_scores\n",
    "\n",
    "# Generate datasets for boosting comparison\n",
    "X_boost, y_boost = make_classification(n_samples=1000, n_features=10, n_informative=5, \n",
    "                                      n_redundant=2, n_clusters_per_class=1, \n",
    "                                      class_sep=0.8, random_state=42)\n",
    "X_train_boost, X_test_boost, y_train_boost, y_test_boost = train_test_split(\n",
    "    X_boost, y_boost, test_size=0.3, random_state=42)\n",
    "\n",
    "# Compare boosting methods\n",
    "boosting_models = {\n",
    "    'Single Tree': DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "    'AdaBoost (sklearn)': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "    'AdaBoost (custom)': AdaBoostCustom(n_estimators=50, random_state=42),\n",
    "    'Gradient Boosting (sklearn)': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting (custom)': GradientBoostingCustom(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "boosting_results = {}\n",
    "fitted_boosting_models = {}\n",
    "\n",
    "for name, model in boosting_models.items():\n",
    "    model.fit(X_train_boost, y_train_boost)\n",
    "    y_pred = model.predict(X_test_boost)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_boost, y_pred)\n",
    "    \n",
    "    boosting_results[name] = {\n",
    "        'test_accuracy': accuracy\n",
    "    }\n",
    "    fitted_boosting_models[name] = model\n",
    "\n",
    "boosting_results_df = pd.DataFrame(boosting_results).T\n",
    "print(\"Boosting Methods Comparison:\")\n",
    "print(boosting_results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze boosting behavior and sequential learning\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Training curves for boosting methods\n",
    "ada_custom = fitted_boosting_models['AdaBoost (custom)']\n",
    "gb_custom = fitted_boosting_models['Gradient Boosting (custom)']\n",
    "\n",
    "# AdaBoost error evolution\n",
    "axes[0, 0].plot(range(1, len(ada_custom.estimator_errors_) + 1), \n",
    "               ada_custom.estimator_errors_, 'o-', linewidth=2, markersize=6)\n",
    "axes[0, 0].set_xlabel('Boosting Round')\n",
    "axes[0, 0].set_ylabel('Weighted Error')\n",
    "axes[0, 0].set_title('AdaBoost: Weighted Error Evolution')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AdaBoost alpha (estimator weights) evolution\n",
    "axes[0, 1].bar(range(1, len(ada_custom.estimator_weights_) + 1), \n",
    "              ada_custom.estimator_weights_, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Boosting Round')\n",
    "axes[0, 1].set_ylabel('Estimator Weight (α)')\n",
    "axes[0, 1].set_title('AdaBoost: Estimator Weights')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Gradient Boosting training accuracy evolution\n",
    "axes[0, 2].plot(range(1, len(gb_custom.train_scores_) + 1), \n",
    "               gb_custom.train_scores_, 'g-', linewidth=2)\n",
    "axes[0, 2].set_xlabel('Boosting Round')\n",
    "axes[0, 2].set_ylabel('Training Accuracy')\n",
    "axes[0, 2].set_title('Gradient Boosting: Training Progress')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Compare ensemble size effect for different methods\n",
    "ensemble_sizes = range(5, 101, 10)\n",
    "ada_performance = []\n",
    "gb_performance = []\n",
    "rf_performance_boost = []\n",
    "\n",
    "for size in ensemble_sizes:\n",
    "    # AdaBoost\n",
    "    ada = AdaBoostCustom(n_estimators=size, random_state=42)\n",
    "    ada.fit(X_train_boost, y_train_boost)\n",
    "    ada_acc = accuracy_score(y_test_boost, ada.predict(X_test_boost))\n",
    "    ada_performance.append(ada_acc)\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    gb = GradientBoostingCustom(n_estimators=size, random_state=42)\n",
    "    gb.fit(X_train_boost, y_train_boost)\n",
    "    gb_acc = accuracy_score(y_test_boost, gb.predict(X_test_boost))\n",
    "    gb_performance.append(gb_acc)\n",
    "    \n",
    "    # Random Forest (for comparison)\n",
    "    rf = RandomForestClassifier(n_estimators=size, random_state=42)\n",
    "    rf.fit(X_train_boost, y_train_boost)\n",
    "    rf_acc = accuracy_score(y_test_boost, rf.predict(X_test_boost))\n",
    "    rf_performance_boost.append(rf_acc)\n",
    "\n",
    "axes[1, 0].plot(ensemble_sizes, ada_performance, 'o-', label='AdaBoost', linewidth=2, markersize=6)\n",
    "axes[1, 0].plot(ensemble_sizes, gb_performance, 's-', label='Gradient Boosting', linewidth=2, markersize=6)\n",
    "axes[1, 0].plot(ensemble_sizes, rf_performance_boost, '^-', label='Random Forest', linewidth=2, markersize=6)\n",
    "axes[1, 0].set_xlabel('Number of Estimators')\n",
    "axes[1, 0].set_ylabel('Test Accuracy')\n",
    "axes[1, 0].set_title('Ensemble Methods Comparison')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate effect on Gradient Boosting\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "lr_performance = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    gb_lr = GradientBoostingCustom(n_estimators=100, learning_rate=lr, random_state=42)\n",
    "    gb_lr.fit(X_train_boost, y_train_boost)\n",
    "    acc = accuracy_score(y_test_boost, gb_lr.predict(X_test_boost))\n",
    "    lr_performance.append(acc)\n",
    "\n",
    "axes[1, 1].semilogx(learning_rates, lr_performance, 'o-', linewidth=2, markersize=8)\n",
    "axes[1, 1].set_xlabel('Learning Rate')\n",
    "axes[1, 1].set_ylabel('Test Accuracy')\n",
    "axes[1, 1].set_title('Gradient Boosting: Learning Rate Effect')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Decision boundary comparison (2D projection)\n",
    "# Use first 2 features for visualization\n",
    "X_2d_boost = X_train_boost[:, :2]\n",
    "ada_2d = AdaBoostCustom(n_estimators=20, random_state=42)\n",
    "gb_2d = GradientBoostingCustom(n_estimators=20, random_state=42)\n",
    "\n",
    "ada_2d.fit(X_2d_boost, y_train_boost)\n",
    "gb_2d.fit(X_2d_boost, y_train_boost)\n",
    "\n",
    "# Create mesh\n",
    "h = 0.02\n",
    "x_min, x_max = X_2d_boost[:, 0].min() - 1, X_2d_boost[:, 0].max() + 1\n",
    "y_min, y_max = X_2d_boost[:, 1].min() - 1, X_2d_boost[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z_ada = ada_2d.decision_function(mesh_points)\n",
    "Z_ada = Z_ada.reshape(xx.shape)\n",
    "\n",
    "axes[1, 2].contourf(xx, yy, Z_ada, alpha=0.8, cmap='RdYlBu')\n",
    "scatter = axes[1, 2].scatter(X_2d_boost[:, 0], X_2d_boost[:, 1], c=y_train_boost, \n",
    "                            cmap='RdYlBu', edgecolors='black')\n",
    "axes[1, 2].set_xlabel('Feature 1')\n",
    "axes[1, 2].set_ylabel('Feature 2')\n",
    "axes[1, 2].set_title('AdaBoost Decision Boundary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze sample weight evolution in AdaBoost\n",
    "print(\"\\nAdaBoost Analysis:\")\n",
    "print(f\"Number of weak learners used: {len(ada_custom.estimators_)}\")\n",
    "print(f\"Final weighted error: {ada_custom.estimator_errors_[-1]:.4f}\")\n",
    "print(f\"Maximum estimator weight: {max(ada_custom.estimator_weights_):.4f}\")\n",
    "print(f\"Total estimator weight: {sum(ada_custom.estimator_weights_):.4f}\")\n",
    "\n",
    "print(\"\\nGradient Boosting Analysis:\")\n",
    "print(f\"Initial prediction (log-odds): {gb_custom.initial_prediction_:.4f}\")\n",
    "print(f\"Final training accuracy: {gb_custom.train_scores_[-1]:.4f}\")\n",
    "print(f\"Accuracy improvement: {gb_custom.train_scores_[-1] - gb_custom.train_scores_[0]:.4f}\")\n",
    "\n",
    "# Compare sequential vs parallel learning\n",
    "print(\"\\nSequential vs Parallel Learning:\")\n",
    "print(f\"AdaBoost (sequential): {boosting_results['AdaBoost (custom)']['test_accuracy']:.4f}\")\n",
    "print(f\"Gradient Boosting (sequential): {boosting_results['Gradient Boosting (custom)']['test_accuracy']:.4f}\")\n",
    "\n",
    "# Train Random Forest on same data for comparison\n",
    "rf_comparison = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_comparison.fit(X_train_boost, y_train_boost)\n",
    "rf_acc = accuracy_score(y_test_boost, rf_comparison.predict(X_test_boost))\n",
    "print(f\"Random Forest (parallel): {rf_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Stacking and Advanced Ensemble Strategies\n",
    "\n",
    "**Question:** Implement stacking (stacked generalization) and compare with voting ensembles. Analyze how meta-learning improves ensemble performance and discuss practical considerations for ensemble diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory\n",
    "\n",
    "**Stacking (Stacked Generalization):**\n",
    "1. **Level-0 Models**: Train base models on training data\n",
    "2. **Meta-features**: Use cross-validation to generate predictions from base models\n",
    "3. **Meta-learner**: Train on meta-features to learn optimal combination\n",
    "\n",
    "**Mathematical Framework:**\n",
    "- Base models: $h_1(x), h_2(x), \\ldots, h_K(x)$\n",
    "- Meta-features: $\\mathbf{z} = [h_1(x), h_2(x), \\ldots, h_K(x)]^T$\n",
    "- Meta-learner: $g(\\mathbf{z}) = g(h_1(x), h_2(x), \\ldots, h_K(x))$\n",
    "\n",
    "**Voting Ensembles:**\n",
    "- **Hard Voting**: $\\hat{y} = \\text{mode}(h_1(x), h_2(x), \\ldots, h_K(x))$\n",
    "- **Soft Voting**: $\\hat{y} = \\arg\\max_c \\sum_{k=1}^K P_k(y=c|x)$\n",
    "\n",
    "**Ensemble Diversity Measures:**\n",
    "- **Disagreement**: $\\text{Dis}_{i,j} = \\frac{N^{01} + N^{10}}{N^{00} + N^{01} + N^{10} + N^{11}}$\n",
    "- **Q-statistic**: $Q_{i,j} = \\frac{N^{11}N^{00} - N^{01}N^{10}}{N^{11}N^{00} + N^{01}N^{10}}$\n",
    "- **Correlation coefficient**: $\\rho_{i,j} = \\frac{N^{11}N^{00} - N^{01}N^{10}}{\\sqrt{(N^{11}+N^{10})(N^{01}+N^{00})(N^{11}+N^{01})(N^{10}+N^{00})}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class StackingEnsemble:\n",
    "    \"\"\"Stacking ensemble implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_models, meta_model, cv=5, use_probabilities=False):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.cv = cv\n",
    "        self.use_probabilities = use_probabilities\n",
    "        \n",
    "        self.fitted_base_models_ = []\n",
    "        self.fitted_meta_model_ = None\n",
    "        \n",
    "    def _generate_meta_features(self, X, y, use_fitted_models=False):\n",
    "        \"\"\"Generate meta-features using cross-validation or fitted models.\"\"\"\n",
    "        if use_fitted_models:\n",
    "            # Use already fitted models (for prediction)\n",
    "            meta_features = []\n",
    "            for model in self.fitted_base_models_:\n",
    "                if self.use_probabilities and hasattr(model, 'predict_proba'):\n",
    "                    pred = model.predict_proba(X)\n",
    "                    if pred.shape[1] == 2:  # Binary classification\n",
    "                        pred = pred[:, 1:]  # Use only positive class probability\n",
    "                else:\n",
    "                    pred = model.predict(X).reshape(-1, 1)\n",
    "                meta_features.append(pred)\n",
    "        else:\n",
    "            # Generate meta-features using cross-validation\n",
    "            meta_features = []\n",
    "            cv_splitter = StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=42)\n",
    "            \n",
    "            for model in self.base_models:\n",
    "                if self.use_probabilities and hasattr(model, 'predict_proba'):\n",
    "                    # Use probability predictions\n",
    "                    cv_pred = cross_val_predict(model, X, y, cv=cv_splitter, method='predict_proba')\n",
    "                    if cv_pred.shape[1] == 2:  # Binary classification\n",
    "                        cv_pred = cv_pred[:, 1:]  # Use only positive class probability\n",
    "                else:\n",
    "                    # Use class predictions\n",
    "                    cv_pred = cross_val_predict(model, X, y, cv=cv_splitter).reshape(-1, 1)\n",
    "                \n",
    "                meta_features.append(cv_pred)\n",
    "        \n",
    "        return np.column_stack(meta_features)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the stacking ensemble.\"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Generate meta-features using cross-validation\n",
    "        meta_X = self._generate_meta_features(X, y)\n",
    "        \n",
    "        # Fit meta-learner\n",
    "        self.fitted_meta_model_ = self.meta_model\n",
    "        self.fitted_meta_model_.fit(meta_X, y)\n",
    "        \n",
    "        # Fit base models on full training data\n",
    "        self.fitted_base_models_ = []\n",
    "        for model in self.base_models:\n",
    "            fitted_model = model\n",
    "            fitted_model.fit(X, y)\n",
    "            self.fitted_base_models_.append(fitted_model)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using stacking.\"\"\"\n",
    "        # Generate meta-features using fitted base models\n",
    "        meta_X = self._generate_meta_features(X, None, use_fitted_models=True)\n",
    "        \n",
    "        # Use meta-learner to make final prediction\n",
    "        return self.fitted_meta_model_.predict(meta_X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities using stacking.\"\"\"\n",
    "        if not hasattr(self.fitted_meta_model_, 'predict_proba'):\n",
    "            raise ValueError(\"Meta-model doesn't support probability prediction\")\n",
    "        \n",
    "        meta_X = self._generate_meta_features(X, None, use_fitted_models=True)\n",
    "        return self.fitted_meta_model_.predict_proba(meta_X)\n",
    "\n",
    "def calculate_ensemble_diversity(predictions_matrix, y_true):\n",
    "    \"\"\"Calculate diversity measures for ensemble.\"\"\"\n",
    "    n_models = predictions_matrix.shape[1]\n",
    "    \n",
    "    diversity_measures = {\n",
    "        'disagreement': [],\n",
    "        'q_statistic': [],\n",
    "        'correlation': []\n",
    "    }\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        for j in range(i + 1, n_models):\n",
    "            pred_i = predictions_matrix[:, i]\n",
    "            pred_j = predictions_matrix[:, j]\n",
    "            \n",
    "            # Calculate confusion matrix between two classifiers\n",
    "            n_11 = np.sum((pred_i == y_true) & (pred_j == y_true))\n",
    "            n_10 = np.sum((pred_i == y_true) & (pred_j != y_true))\n",
    "            n_01 = np.sum((pred_i != y_true) & (pred_j == y_true))\n",
    "            n_00 = np.sum((pred_i != y_true) & (pred_j != y_true))\n",
    "            \n",
    "            total = n_11 + n_10 + n_01 + n_00\n",
    "            \n",
    "            # Disagreement measure\n",
    "            disagreement = (n_01 + n_10) / total\n",
    "            diversity_measures['disagreement'].append(disagreement)\n",
    "            \n",
    "            # Q-statistic\n",
    "            if (n_11 * n_00 + n_01 * n_10) != 0:\n",
    "                q_stat = (n_11 * n_00 - n_01 * n_10) / (n_11 * n_00 + n_01 * n_10)\n",
    "            else:\n",
    "                q_stat = 0\n",
    "            diversity_measures['q_statistic'].append(q_stat)\n",
    "            \n",
    "            # Correlation coefficient\n",
    "            denom = np.sqrt((n_11 + n_10) * (n_01 + n_00) * (n_11 + n_01) * (n_10 + n_00))\n",
    "            if denom != 0:\n",
    "                correlation = (n_11 * n_00 - n_01 * n_10) / denom\n",
    "            else:\n",
    "                correlation = 0\n",
    "            diversity_measures['correlation'].append(correlation)\n",
    "    \n",
    "    # Return average diversity measures\n",
    "    return {\n",
    "        'avg_disagreement': np.mean(diversity_measures['disagreement']),\n",
    "        'avg_q_statistic': np.mean(diversity_measures['q_statistic']),\n",
    "        'avg_correlation': np.mean(diversity_measures['correlation'])\n",
    "    }\n",
    "\n",
    "# Generate dataset for stacking comparison\n",
    "X_stack, y_stack = make_classification(n_samples=1500, n_features=15, n_informative=10, \n",
    "                                      n_redundant=3, n_clusters_per_class=2, \n",
    "                                      class_sep=0.9, random_state=42)\n",
    "X_train_stack, X_test_stack, y_train_stack, y_test_stack = train_test_split(\n",
    "    X_stack, y_stack, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define diverse base models\n",
    "base_models = [\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(n_neighbors=5)\n",
    "]\n",
    "\n",
    "# Compare different ensemble strategies\n",
    "ensemble_strategies = {\n",
    "    'Voting (Hard)': VotingClassifier(\n",
    "        estimators=[(f'model_{i}', model) for i, model in enumerate(base_models)],\n",
    "        voting='hard'\n",
    "    ),\n",
    "    'Voting (Soft)': VotingClassifier(\n",
    "        estimators=[(f'model_{i}', model) for i, model in enumerate(base_models)],\n",
    "        voting='soft'\n",
    "    ),\n",
    "    'Stacking (LR)': StackingEnsemble(\n",
    "        base_models=base_models.copy(),\n",
    "        meta_model=LogisticRegression(random_state=42, max_iter=1000),\n",
    "        use_probabilities=True\n",
    "    ),\n",
    "    'Stacking (RF)': StackingEnsemble(\n",
    "        base_models=base_models.copy(),\n",
    "        meta_model=RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "        use_probabilities=True\n",
    "    ),\n",
    "    'Stacking (sklearn)': StackingClassifier(\n",
    "        estimators=[(f'model_{i}', model) for i, model in enumerate(base_models)],\n",
    "        final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "        cv=5\n",
    "    )\n",
    "}\n",
    "\n",
    "stacking_results = {}\n",
    "fitted_ensemble_models = {}\n",
    "\n",
    "for name, ensemble in ensemble_strategies.items():\n",
    "    ensemble.fit(X_train_stack, y_train_stack)\n",
    "    y_pred = ensemble.predict(X_test_stack)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_stack, y_pred)\n",
    "    \n",
    "    stacking_results[name] = {\n",
    "        'test_accuracy': accuracy\n",
    "    }\n",
    "    fitted_ensemble_models[name] = ensemble\n",
    "\n",
    "# Add individual base model results\n",
    "for i, model in enumerate(base_models):\n",
    "    model_copy = model\n",
    "    model_copy.fit(X_train_stack, y_train_stack)\n",
    "    y_pred = model_copy.predict(X_test_stack)\n",
    "    accuracy = accuracy_score(y_test_stack, y_pred)\n",
    "    \n",
    "    model_name = type(model).__name__\n",
    "    stacking_results[f'Base: {model_name}'] = {\n",
    "        'test_accuracy': accuracy\n",
    "    }\n",
    "\n",
    "stacking_results_df = pd.DataFrame(stacking_results).T\n",
    "print(\"Ensemble Strategies Comparison:\")\n",
    "print(stacking_results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ensemble diversity and meta-learning\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Performance comparison of ensemble strategies\n",
    "ensemble_names = list(stacking_results.keys())\n",
    "ensemble_accuracies = [stacking_results[name]['test_accuracy'] for name in ensemble_names]\n",
    "\n",
    "# Separate base models and ensemble methods\n",
    "base_models_results = {k: v for k, v in stacking_results.items() if k.startswith('Base:')}\n",
    "ensemble_methods_results = {k: v for k, v in stacking_results.items() if not k.startswith('Base:')}\n",
    "\n",
    "base_names = list(base_models_results.keys())\n",
    "base_accuracies = [base_models_results[name]['test_accuracy'] for name in base_names]\n",
    "\n",
    "ensemble_method_names = list(ensemble_methods_results.keys())\n",
    "ensemble_method_accuracies = [ensemble_methods_results[name]['test_accuracy'] for name in ensemble_method_names]\n",
    "\n",
    "# Plot base models vs ensemble methods\n",
    "x_base = np.arange(len(base_names))\n",
    "x_ensemble = np.arange(len(ensemble_method_names))\n",
    "\n",
    "axes[0, 0].bar(x_base, base_accuracies, alpha=0.7, label='Base Models', color='lightblue')\n",
    "axes[0, 0].bar(x_ensemble + len(base_names) + 1, ensemble_method_accuracies, \n",
    "              alpha=0.7, label='Ensemble Methods', color='orange')\n",
    "\n",
    "all_names = base_names + [''] + ensemble_method_names\n",
    "all_positions = list(x_base) + [len(base_names)] + list(x_ensemble + len(base_names) + 1)\n",
    "\n",
    "axes[0, 0].set_xticks(all_positions)\n",
    "axes[0, 0].set_xticklabels([name.replace('Base: ', '').replace('Classifier', '').replace('Regression', 'LR') \n",
    "                           for name in all_names], rotation=45, ha='right')\n",
    "axes[0, 0].set_ylabel('Test Accuracy')\n",
    "axes[0, 0].set_title('Base Models vs Ensemble Methods')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and visualize ensemble diversity\n",
    "# Get predictions from all base models\n",
    "base_predictions = []\n",
    "fitted_base_models = []\n",
    "\n",
    "for model in base_models:\n",
    "    model_copy = model\n",
    "    model_copy.fit(X_train_stack, y_train_stack)\n",
    "    pred = model_copy.predict(X_test_stack)\n",
    "    base_predictions.append(pred)\n",
    "    fitted_base_models.append(model_copy)\n",
    "\n",
    "predictions_matrix = np.column_stack(base_predictions)\n",
    "diversity_metrics = calculate_ensemble_diversity(predictions_matrix, y_test_stack)\n",
    "\n",
    "# Diversity metrics visualization\n",
    "metrics = ['Disagreement', 'Q-statistic', 'Correlation']\n",
    "values = [diversity_metrics['avg_disagreement'], \n",
    "          diversity_metrics['avg_q_statistic'], \n",
    "          diversity_metrics['avg_correlation']]\n",
    "\n",
    "colors = ['green' if v > 0.1 else 'orange' if v > 0.05 else 'red' for v in values]\n",
    "bars = axes[0, 1].bar(metrics, values, color=colors, alpha=0.7)\n",
    "axes[0, 1].set_ylabel('Diversity Score')\n",
    "axes[0, 1].set_title('Ensemble Diversity Measures')\n",
    "axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "for bar, val in zip(bars, values):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                   f'{val:.3f}', ha='center', va='bottom')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Pairwise correlation matrix of base model predictions\n",
    "model_names_short = [type(model).__name__.replace('Classifier', '').replace('Naive', 'NB') \n",
    "                    for model in base_models]\n",
    "correlation_matrix = np.corrcoef(predictions_matrix.T)\n",
    "\n",
    "im = axes[0, 2].imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[0, 2].set_xticks(range(len(model_names_short)))\n",
    "axes[0, 2].set_yticks(range(len(model_names_short)))\n",
    "axes[0, 2].set_xticklabels(model_names_short, rotation=45)\n",
    "axes[0, 2].set_yticklabels(model_names_short)\n",
    "axes[0, 2].set_title('Base Model Prediction Correlations')\n",
    "\n",
    "# Add correlation values to heatmap\n",
    "for i in range(len(model_names_short)):\n",
    "    for j in range(len(model_names_short)):\n",
    "        text = axes[0, 2].text(j, i, f'{correlation_matrix[i, j]:.2f}',\n",
    "                              ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "plt.colorbar(im, ax=axes[0, 2])\n",
    "\n",
    "# Meta-learner analysis for stacking\n",
    "stacking_lr = fitted_ensemble_models['Stacking (LR)']\n",
    "\n",
    "# Get meta-features for analysis\n",
    "meta_X_train = stacking_lr._generate_meta_features(X_train_stack, y_train_stack)\n",
    "meta_X_test = stacking_lr._generate_meta_features(X_test_stack, None, use_fitted_models=True)\n",
    "\n",
    "# Meta-learner feature importance (if available)\n",
    "if hasattr(stacking_lr.fitted_meta_model_, 'coef_'):\n",
    "    meta_importances = np.abs(stacking_lr.fitted_meta_model_.coef_[0])\n",
    "    \n",
    "    axes[1, 0].bar(model_names_short, meta_importances, alpha=0.7, color='purple')\n",
    "    axes[1, 0].set_ylabel('Meta-learner Coefficient (abs)')\n",
    "    axes[1, 0].set_title('Meta-learner Feature Importance')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ensemble performance vs diversity trade-off\n",
    "# Test different subsets of base models\n",
    "from itertools import combinations\n",
    "\n",
    "subset_performances = []\n",
    "subset_diversities = []\n",
    "subset_sizes = []\n",
    "\n",
    "for size in range(2, len(base_models) + 1):\n",
    "    for subset_indices in combinations(range(len(base_models)), size):\n",
    "        # Create subset ensemble\n",
    "        subset_models = [base_models[i] for i in subset_indices]\n",
    "        subset_voting = VotingClassifier(\n",
    "            estimators=[(f'model_{i}', model) for i, model in enumerate(subset_models)],\n",
    "            voting='soft'\n",
    "        )\n",
    "        \n",
    "        # Fit and evaluate\n",
    "        subset_voting.fit(X_train_stack, y_train_stack)\n",
    "        subset_acc = accuracy_score(y_test_stack, subset_voting.predict(X_test_stack))\n",
    "        \n",
    "        # Calculate diversity for subset\n",
    "        subset_predictions = np.column_stack([base_predictions[i] for i in subset_indices])\n",
    "        subset_diversity = calculate_ensemble_diversity(subset_predictions, y_test_stack)\n",
    "        \n",
    "        subset_performances.append(subset_acc)\n",
    "        subset_diversities.append(subset_diversity['avg_disagreement'])\n",
    "        subset_sizes.append(size)\n",
    "\n",
    "# Plot diversity vs performance\n",
    "scatter = axes[1, 1].scatter(subset_diversities, subset_performances, \n",
    "                            c=subset_sizes, cmap='viridis', alpha=0.7, s=60)\n",
    "axes[1, 1].set_xlabel('Average Disagreement (Diversity)')\n",
    "axes[1, 1].set_ylabel('Ensemble Accuracy')\n",
    "axes[1, 1].set_title('Diversity vs Performance Trade-off')\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='Ensemble Size')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning curves for ensemble methods\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "voting_scores = []\n",
    "stacking_scores = []\n",
    "best_base_scores = []\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    n_samples = int(train_size * len(X_train_stack))\n",
    "    X_subset = X_train_stack[:n_samples]\n",
    "    y_subset = y_train_stack[:n_samples]\n",
    "    \n",
    "    # Voting ensemble\n",
    "    voting = VotingClassifier(\n",
    "        estimators=[(f'model_{i}', model) for i, model in enumerate(base_models)],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting.fit(X_subset, y_subset)\n",
    "    voting_acc = accuracy_score(y_test_stack, voting.predict(X_test_stack))\n",
    "    voting_scores.append(voting_acc)\n",
    "    \n",
    "    # Stacking ensemble\n",
    "    stacking = StackingEnsemble(\n",
    "        base_models=base_models.copy(),\n",
    "        meta_model=LogisticRegression(random_state=42, max_iter=1000),\n",
    "        use_probabilities=True\n",
    "    )\n",
    "    stacking.fit(X_subset, y_subset)\n",
    "    stacking_acc = accuracy_score(y_test_stack, stacking.predict(X_test_stack))\n",
    "    stacking_scores.append(stacking_acc)\n",
    "    \n",
    "    # Best base model\n",
    "    best_acc = 0\n",
    "    for model in base_models:\n",
    "        model_copy = model\n",
    "        model_copy.fit(X_subset, y_subset)\n",
    "        acc = accuracy_score(y_test_stack, model_copy.predict(X_test_stack))\n",
    "        best_acc = max(best_acc, acc)\n",
    "    best_base_scores.append(best_acc)\n",
    "\n",
    "train_sample_counts = train_sizes * len(X_train_stack)\n",
    "axes[1, 2].plot(train_sample_counts, voting_scores, 'o-', label='Voting Ensemble', linewidth=2)\n",
    "axes[1, 2].plot(train_sample_counts, stacking_scores, 's-', label='Stacking Ensemble', linewidth=2)\n",
    "axes[1, 2].plot(train_sample_counts, best_base_scores, '^-', label='Best Base Model', linewidth=2)\n",
    "axes[1, 2].set_xlabel('Training Set Size')\n",
    "axes[1, 2].set_ylabel('Test Accuracy')\n",
    "axes[1, 2].set_title('Learning Curves: Ensemble Strategies')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print analysis results\n",
    "print(f\"\\nEnsemble Diversity Analysis:\")\n",
    "print(f\"Average disagreement: {diversity_metrics['avg_disagreement']:.4f}\")\n",
    "print(f\"Average Q-statistic: {diversity_metrics['avg_q_statistic']:.4f}\")\n",
    "print(f\"Average correlation: {diversity_metrics['avg_correlation']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Performing Methods:\")\n",
    "sorted_results = sorted(stacking_results.items(), key=lambda x: x[1]['test_accuracy'], reverse=True)\n",
    "for i, (name, result) in enumerate(sorted_results[:5]):\n",
    "    print(f\"{i+1}. {name}: {result['test_accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nEnsemble Improvement over Best Base Model:\")\n",
    "best_base_acc = max([result['test_accuracy'] for name, result in stacking_results.items() if name.startswith('Base:')])\n",
    "best_ensemble_acc = max([result['test_accuracy'] for name, result in stacking_results.items() if not name.startswith('Base:')])\n",
    "improvement = (best_ensemble_acc - best_base_acc) * 100\n",
    "print(f\"Best base model: {best_base_acc:.4f}\")\n",
    "print(f\"Best ensemble: {best_ensemble_acc:.4f}\")\n",
    "print(f\"Improvement: {improvement:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Ensemble Methods Fundamentals:\n",
    "\n",
    "1. **Random Forest and Bagging**:\n",
    "   - **Bootstrap sampling** reduces variance by averaging over different data subsets\n",
    "   - **Feature randomness** reduces correlation between trees, enhancing diversity\n",
    "   - **OOB error** provides unbiased performance estimate without separate validation set\n",
    "   - Typically achieves 60-80% variance reduction compared to single trees\n",
    "\n",
    "2. **Boosting Methods**:\n",
    "   - **AdaBoost**: Sequential learning with sample reweighting; focuses on hard examples\n",
    "   - **Gradient Boosting**: Fits to pseudo-residuals; more general framework for different loss functions\n",
    "   - **Sequential vs Parallel**: Boosting builds models sequentially (each depends on previous), bagging builds in parallel\n",
    "   - Often achieves higher accuracy than bagging but more prone to overfitting\n",
    "\n",
    "3. **Stacking and Meta-Learning**:\n",
    "   - **Stacking** learns optimal combination of base models using meta-learner\n",
    "   - **Cross-validation** prevents overfitting when generating meta-features\n",
    "   - **Diversity** is crucial: uncorrelated errors lead to better ensemble performance\n",
    "   - Meta-learner can capture complex interactions between base model predictions\n",
    "\n",
    "### Practical Guidelines:\n",
    "\n",
    "**Choosing Ensemble Methods:**\n",
    "- **Random Forest**: Default choice for tabular data; robust and interpretable\n",
    "- **Gradient Boosting**: When maximum accuracy is needed; requires careful tuning\n",
    "- **Stacking**: When base models are very different; adds complexity but can improve performance\n",
    "- **Voting**: Simple and effective when base models have similar performance\n",
    "\n",
    "**Ensemble Diversity:**\n",
    "- Use different algorithms (tree-based, linear, probabilistic, distance-based)\n",
    "- Different hyperparameters for same algorithm\n",
    "- Different feature subsets or data transformations\n",
    "- Target disagreement rate of 10-30% between base models\n",
    "\n",
    "**Performance Considerations:**\n",
    "- **Training time**: Bagging (parallel) < Boosting (sequential) < Stacking (CV + meta-learning)\n",
    "- **Prediction time**: All methods require predictions from all base models\n",
    "- **Memory usage**: Stores all base models; can be significant for large ensembles\n",
    "- **Interpretability**: Decreases with ensemble complexity\n",
    "\n",
    "### Key Insights:\n",
    "- Ensemble improvement diminishes with highly correlated base models\n",
    "- Optimal ensemble size typically 50-200 models for Random Forest\n",
    "- Learning rate in boosting creates bias-variance tradeoff\n",
    "- Stacking works best with diverse, well-performing base models\n",
    "- OOB error closely approximates test error for bagging methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}