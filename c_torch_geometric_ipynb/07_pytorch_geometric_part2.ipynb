{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PyTorch Geometric Part 2: Graph Autoencoders\n\nThis notebook explores graph autoencoders for unsupervised learning on graphs with comprehensive mathematical exposition. We'll implement Graph Autoencoder (GAE) and Variational Graph Autoencoder (VGAE) architectures, deriving their theoretical foundations and practical implementations.\n\n## Mathematical Foundation of Graph Autoencoders\n\n### Core Concept: Latent Graph Representation Learning\n\nGraph autoencoders learn to encode graph structure $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$ and node features $\\mathbf{X}$ into low-dimensional latent representations $\\mathbf{Z}$, then reconstruct the original graph from these embeddings.\n\n**Fundamental Framework:**\n$$\\mathcal{G} \\xrightarrow{\\text{Encoder}} \\mathbf{Z} \\xrightarrow{\\text{Decoder}} \\hat{\\mathcal{G}}$$\n\nwhere:\n- **Input**: Graph $\\mathcal{G}$ with adjacency matrix $\\mathbf{A} \\in \\{0,1\\}^{N \\times N}$ and features $\\mathbf{X} \\in \\mathbb{R}^{N \\times d}$\n- **Latent Space**: Node embeddings $\\mathbf{Z} \\in \\mathbb{R}^{N \\times k}$ where $k \\ll d$\n- **Reconstruction**: Predicted adjacency $\\hat{\\mathbf{A}} \\in [0,1]^{N \\times N}$\n\n### Applications with Mathematical Formulations\n\n**1. Link Prediction:**\n$$P(A_{ij} = 1) = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$$\n\n**2. Node Clustering:**\n$$\\mathbf{z}_i \\approx \\mathbf{z}_j \\text{ if nodes } i,j \\text{ belong to same community}$$\n\n**3. Graph Generation:**\n$$\\mathbf{Z} \\sim p(\\mathbf{Z}) \\rightarrow \\hat{\\mathbf{A}} = \\text{Decode}(\\mathbf{Z})$$\n\n**4. Anomaly Detection:**\n$$\\text{Anomaly Score} = \\|\\mathbf{A} - \\hat{\\mathbf{A}}\\|_F^2$$\n\nThe mathematical foundation enables principled unsupervised learning on graph-structured data through dimensionality reduction and reconstruction objectives."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (uncomment if needed)\n",
    "# !pip install torch torch_geometric torch_scatter torch_sparse torch_cluster torch_spline_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures, RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling, remove_self_loops, add_self_loops\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Graph Autoencoder (GAE) Architecture\n\n### Mathematical Formulation\n\nGAE is a **deterministic autoencoder** that learns node embeddings through reconstruction of the adjacency matrix:\n\n**Encoder Function:**\n$$\\mathbf{Z} = \\text{GCN}(\\mathbf{X}, \\mathbf{A}) = f_{\\theta}(\\mathbf{X}, \\mathbf{A})$$\n\nwhere the encoder $f_{\\theta}$ is typically a multi-layer GCN:\n$$\\mathbf{H}^{(l+1)} = \\sigma\\left(\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}\\mathbf{H}^{(l)}\\mathbf{W}^{(l)}\\right)$$\n\n**Decoder Function:**\n$$\\hat{A}_{ij} = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$$\n\nThis **inner product decoder** assumes that edge probability depends on embedding similarity.\n\n**Complete GAE Pipeline:**\n1. **Input**: $\\mathbf{X} \\in \\mathbb{R}^{N \\times d}$, $\\mathbf{A} \\in \\{0,1\\}^{N \\times N}$\n2. **Encoding**: $\\mathbf{Z} = \\text{GCN}_{\\theta}(\\mathbf{X}, \\mathbf{A}) \\in \\mathbb{R}^{N \\times k}$\n3. **Decoding**: $\\hat{\\mathbf{A}} = \\sigma(\\mathbf{Z}\\mathbf{Z}^T) \\in [0,1]^{N \\times N}$\n\n**Loss Function:**\n$$\\mathcal{L}_{\\text{GAE}} = -\\mathbb{E}_{(i,j) \\sim \\mathcal{E}^+}[\\log \\hat{A}_{ij}] - \\mathbb{E}_{(i,j) \\sim \\mathcal{E}^-}[\\log(1 - \\hat{A}_{ij})]$$\n\nwhere:\n- $\\mathcal{E}^+$: Set of positive edges (existing edges)\n- $\\mathcal{E}^-$: Set of negative edges (non-existing edges, sampled)\n- $\\sigma(\\cdot)$: Sigmoid activation function\n\n**Key Properties:**\n- **Deterministic**: Same input always produces same embedding\n- **Efficient**: Single forward pass for encoding\n- **Scalable**: Linear complexity in number of edges\n- **Interpretable**: Inner product captures node similarity\n\nThe reconstruction objective forces the model to learn meaningful node representations that preserve graph structure."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Variational Graph Autoencoder (VGAE) Architecture\n\n### Mathematical Formulation\n\nVGAE extends GAE by introducing a **probabilistic latent space** with Bayesian inference:\n\n**Probabilistic Encoder:**\n$$q_{\\phi}(\\mathbf{Z}|\\mathbf{X}, \\mathbf{A}) = \\prod_{i=1}^N q_{\\phi}(\\mathbf{z}_i|\\mathbf{X}, \\mathbf{A})$$\n\nwhere each node embedding follows a multivariate Gaussian:\n$$q_{\\phi}(\\mathbf{z}_i|\\mathbf{X}, \\mathbf{A}) = \\mathcal{N}(\\boldsymbol{\\mu}_i, \\text{diag}(\\boldsymbol{\\sigma}_i^2))$$\n\n**Encoder Network Architecture:**\n$$\\boldsymbol{\\mu} = \\text{GCN}_{\\mu}(\\mathbf{X}, \\mathbf{A}) = \\mathbf{H}^{(L)}\\mathbf{W}_{\\mu}$$\n$$\\log \\boldsymbol{\\sigma} = \\text{GCN}_{\\sigma}(\\mathbf{X}, \\mathbf{A}) = \\mathbf{H}^{(L)}\\mathbf{W}_{\\sigma}$$\n\nwhere $\\mathbf{H}^{(L)}$ is the shared hidden representation from GCN layers.\n\n**Reparameterization Trick:**\n$$\\mathbf{z}_i = \\boldsymbol{\\mu}_i + \\boldsymbol{\\sigma}_i \\odot \\boldsymbol{\\epsilon}_i$$\n\nwhere $\\boldsymbol{\\epsilon}_i \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ enables gradient-based learning.\n\n**Probabilistic Decoder:**\n$$p_{\\theta}(\\mathbf{A}|\\mathbf{Z}) = \\prod_{i=1}^N \\prod_{j=1}^N p_{\\theta}(A_{ij}|\\mathbf{z}_i, \\mathbf{z}_j)$$\n\nwith Bernoulli likelihood:\n$$p_{\\theta}(A_{ij} = 1|\\mathbf{z}_i, \\mathbf{z}_j) = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$$\n\n**Variational Lower Bound (ELBO):**\n$$\\mathcal{L}_{\\text{VGAE}} = \\mathbb{E}_{q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})}[\\log p_{\\theta}(\\mathbf{A}|\\mathbf{Z})] - D_{KL}[q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A}) \\| p(\\mathbf{Z})]$$\n\n**KL Divergence Term:**\nAssuming standard Gaussian prior $p(\\mathbf{z}_i) = \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$:\n$$D_{KL}[q_{\\phi}(\\mathbf{z}_i) \\| p(\\mathbf{z}_i)] = \\frac{1}{2}\\sum_{j=1}^k \\left(1 + \\log(\\sigma_{ij}^2) - \\mu_{ij}^2 - \\sigma_{ij}^2\\right)$$\n\n**Total Loss:**\n$$\\mathcal{L}_{\\text{total}} = -\\mathcal{L}_{\\text{VGAE}} = \\underbrace{-\\mathbb{E}[\\log p_{\\theta}(\\mathbf{A}|\\mathbf{Z})]}_{\\text{Reconstruction Loss}} + \\underbrace{D_{KL}[q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A}) \\| p(\\mathbf{Z})]}_{\\text{Regularization}}$$\n\n**Key Advantages:**\n- **Uncertainty Quantification**: Variance parameters capture embedding uncertainty\n- **Regularized Latent Space**: KL term prevents overfitting and encourages smooth embeddings\n- **Generative Capability**: Can sample new embeddings from learned distribution\n- **Better Representation**: Probabilistic framework often leads to more robust embeddings"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Dataset Preparation and Link Prediction Setup\n\n### Mathematical Framework for Link Prediction\n\nLink prediction is formulated as a **binary classification problem** on node pairs:\n\n**Problem Definition:**\nGiven partial graph $\\mathcal{G}_{\\text{obs}} = (\\mathcal{V}, \\mathcal{E}_{\\text{obs}})$ where $\\mathcal{E}_{\\text{obs}} \\subset \\mathcal{E}_{\\text{true}}$, predict missing edges in $\\mathcal{E}_{\\text{missing}} = \\mathcal{E}_{\\text{true}} \\setminus \\mathcal{E}_{\\text{obs}}$.\n\n**Data Splitting Strategy:**\n$$\\mathcal{E}_{\\text{true}} = \\mathcal{E}_{\\text{train}} \\cup \\mathcal{E}_{\\text{val}} \\cup \\mathcal{E}_{\\text{test}}$$\n\nwhere:\n- $\\mathcal{E}_{\\text{train}}$: Edges available during training (typically 70-80%)\n- $\\mathcal{E}_{\\text{val}}$: Edges for hyperparameter tuning (10-15%)  \n- $\\mathcal{E}_{\\text{test}}$: Edges for final evaluation (10-20%)\n\n**Negative Sampling:**\nFor each positive edge $(i,j) \\in \\mathcal{E}^+$, sample negative edge $(i,k) \\notin \\mathcal{E}$ such that:\n$$|\\mathcal{E}^-| = |\\mathcal{E}^+|$$\n\nEnsuring balanced classification problem.\n\n**Edge Prediction Probability:**\n$$P(\\text{edge}_{ij} = 1) = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$$\n\n**Decision Rule:**\n$$\\hat{A}_{ij} = \\begin{cases} \n1 & \\text{if } P(\\text{edge}_{ij} = 1) > \\tau \\\\\n0 & \\text{otherwise}\n\\end{cases}$$\n\nwhere $\\tau$ is the decision threshold (typically 0.5).\n\n**Evaluation Metrics:**\n\n**1. Area Under Curve (AUC):**\n$$\\text{AUC} = \\int_0^1 \\text{TPR}(t) \\, d\\text{FPR}(t)$$\n\nwhere TPR = True Positive Rate, FPR = False Positive Rate.\n\n**2. Average Precision (AP):**\n$$\\text{AP} = \\sum_{k} \\left(\\text{Recall}(k) - \\text{Recall}(k-1)\\right) \\times \\text{Precision}(k)$$\n\n**Mathematical Properties:**\n- **AUC**: Measures ranking quality, range $[0,1]$, higher is better\n- **AP**: Emphasizes precision at high recall, suitable for imbalanced data\n- **Both metrics**: Threshold-independent, robust to class imbalance\n\nThis framework enables rigorous evaluation of graph autoencoder performance on link prediction tasks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data for link prediction\n",
    "dataset = Planetoid('/tmp/Cora', 'Cora', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "# Remove self loops and add them back (standardization)\n",
    "data.edge_index, _ = remove_self_loops(data.edge_index)\n",
    "data.edge_index, _ = add_self_loops(data.edge_index)\n",
    "\n",
    "print(f'Dataset: {dataset}')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {data.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Split edges for link prediction\n",
    "transform = RandomLinkSplit(num_val=0.1, num_test=0.2, is_undirected=True, split_labels=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "print(f'\\nAfter splitting:')\n",
    "print(f'Training edges: {train_data.edge_index.size(1)}')\n",
    "print(f'Validation edges: {val_data.edge_label_index.size(1)}')\n",
    "print(f'Test edges: {test_data.edge_label_index.size(1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Training Functions\n\n### Mathematical Framework for Training Graph Autoencoders\n\n**GAE Training Objective:**\n$$\\mathcal{L}_{\\text{GAE}} = -\\sum_{(i,j) \\in \\mathcal{E}^+} \\log \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j) - \\sum_{(i,j) \\in \\mathcal{E}^-} \\log(1 - \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j))$$\n\nThis is the **binary cross-entropy loss** for link prediction.\n\n**VGAE Training Objective:**\n$$\\mathcal{L}_{\\text{VGAE}} = \\mathcal{L}_{\\text{reconstruction}} + \\beta \\cdot \\mathcal{L}_{\\text{KL}}$$\n\nwhere:\n\n**Reconstruction Loss:**\n$$\\mathcal{L}_{\\text{reconstruction}} = -\\mathbb{E}_{q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})}[\\log p_{\\theta}(\\mathbf{A}|\\mathbf{Z})]$$\n\n**KL Divergence Loss:**\n$$\\mathcal{L}_{\\text{KL}} = D_{KL}[q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A}) \\| p(\\mathbf{Z})]$$\n\n**KL Divergence Computation:**\nFor each node $i$:\n$$D_{KL}[q_{\\phi}(\\mathbf{z}_i) \\| p(\\mathbf{z}_i)] = \\frac{1}{2}\\sum_{j=1}^k \\left(\\mu_{ij}^2 + \\sigma_{ij}^2 - \\log(\\sigma_{ij}^2) - 1\\right)$$\n\n**Total KL Loss:**\n$$\\mathcal{L}_{\\text{KL}} = \\frac{1}{N} \\sum_{i=1}^N D_{KL}[q_{\\phi}(\\mathbf{z}_i) \\| p(\\mathbf{z}_i)]$$\n\n**Gradient Computation:**\n\n**For GAE:** Standard backpropagation through GCN layers and inner product decoder.\n\n**For VGAE:** Uses reparameterization trick for gradients w.r.t. $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\sigma}$:\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\mu}_i} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_i} + \\frac{\\partial \\mathcal{L}_{\\text{KL}}}{\\partial \\boldsymbol{\\mu}_i}$$\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\log \\boldsymbol{\\sigma}_i} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_i} \\odot \\boldsymbol{\\sigma}_i + \\frac{\\partial \\mathcal{L}_{\\text{KL}}}{\\partial \\log \\boldsymbol{\\sigma}_i}$$\n\n**Negative Sampling Strategy:**\nSample negative edges uniformly from non-existing edges:\n$$\\mathcal{E}^- = \\{(i,j) : (i,j) \\notin \\mathcal{E}, \\, i \\neq j\\}$$\n\n**Optimization Algorithm:**\nBoth models use Adam optimizer with learning rate $\\alpha$:\n$$\\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_t - \\alpha \\frac{\\hat{\\mathbf{m}}_t}{\\sqrt{\\hat{\\mathbf{v}}_t} + \\epsilon}$$\n\n**Convergence Criteria:**\n- Monitor validation AUC/AP scores\n- Early stopping when validation performance plateaus\n- Typical convergence in 100-200 epochs\n\nThe mathematical framework ensures principled optimization of both deterministic and probabilistic graph autoencoders."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gae(model, train_data, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train Graph Autoencoder for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    \n",
    "    # Compute loss (reconstruction + negative sampling)\n",
    "    loss = model.recon_loss(z, train_data.edge_index)\n",
    "    \n",
    "    # Add negative sampling loss\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index,\n",
    "        num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_index.size(1)\n",
    "    )\n",
    "    \n",
    "    loss = loss + model.recon_loss(z, neg_edge_index, neg_edge_index=True)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def train_vgae(model, train_data, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train Variational Graph Autoencoder for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    \n",
    "    # Compute reconstruction loss\n",
    "    recon_loss = model.recon_loss(z, train_data.edge_index)\n",
    "    \n",
    "    # Add KL divergence loss\n",
    "    kl_loss = model.kl_loss() / train_data.num_nodes\n",
    "    \n",
    "    # Total loss\n",
    "    loss = recon_loss + kl_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), recon_loss.item(), kl_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Evaluation Functions\n\n### Mathematical Framework for Link Prediction Evaluation\n\n**Performance Metrics for Binary Classification:**\n\n**1. Area Under Receiver Operating Characteristic Curve (AUC-ROC):**\n\nThe ROC curve plots True Positive Rate vs. False Positive Rate:\n$$\\text{TPR}(\\tau) = \\frac{\\text{TP}(\\tau)}{\\text{TP}(\\tau) + \\text{FN}(\\tau)}$$\n$$\\text{FPR}(\\tau) = \\frac{\\text{FP}(\\tau)}{\\text{FP}(\\tau) + \\text{TN}(\\tau)}$$\n\nwhere $\\tau$ is the decision threshold.\n\n**AUC Computation:**\n$$\\text{AUC} = \\int_0^1 \\text{TPR}(\\text{FPR}^{-1}(x)) \\, dx = P(\\text{score}_{\\text{pos}} > \\text{score}_{\\text{neg}})$$\n\n**Probabilistic Interpretation:**\nAUC equals the probability that a randomly chosen positive edge has higher score than a randomly chosen negative edge.\n\n**2. Average Precision (AP):**\n\nAP summarizes the precision-recall curve:\n$$\\text{Precision}(\\tau) = \\frac{\\text{TP}(\\tau)}{\\text{TP}(\\tau) + \\text{FP}(\\tau)}$$\n$$\\text{Recall}(\\tau) = \\frac{\\text{TP}(\\tau)}{\\text{TP}(\\tau) + \\text{FN}(\\tau)}$$\n\n**AP Computation:**\n$$\\text{AP} = \\sum_{k=1}^n \\left[\\text{Recall}(k) - \\text{Recall}(k-1)\\right] \\times \\text{Precision}(k)$$\n\nwhere $k$ indexes sorted predictions by decreasing score.\n\n**Evaluation Procedure:**\n\n**Step 1: Score Computation**\nFor each edge candidate $(i,j)$:\n$$s_{ij} = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$$\n\n**Step 2: Label Assignment**\n$$y_{ij} = \\begin{cases} \n1 & \\text{if } (i,j) \\in \\mathcal{E}_{\\text{true}} \\\\\n0 & \\text{if } (i,j) \\in \\mathcal{E}_{\\text{negative}}\n\\end{cases}$$\n\n**Step 3: Ranking and Evaluation**\n- Sort all edge candidates by score $s_{ij}$ in descending order\n- Compute TPR, FPR at each threshold\n- Calculate AUC and AP from these curves\n\n**Statistical Properties:**\n- **AUC Range**: $[0, 1]$, random classifier achieves 0.5\n- **AP Range**: $[0, 1]$, depends on positive class ratio\n- **Robustness**: Both metrics are threshold-independent\n- **Interpretation**: Higher values indicate better link prediction performance\n\n**Cross-Validation for Robust Evaluation:**\n$$\\text{Score}_{\\text{CV}} = \\frac{1}{K} \\sum_{k=1}^K \\text{Score}_k$$\n\nwhere $K$ is the number of folds in cross-validation.\n\nThis mathematical framework provides rigorous evaluation of graph autoencoder performance on link prediction tasks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, pos_edge_index, neg_edge_index):\n",
    "    \"\"\"\n",
    "    Evaluate model on link prediction task\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        \n",
    "        # Get positive and negative edge scores\n",
    "        pos_scores = model.decode(z, pos_edge_index).sigmoid()\n",
    "        neg_scores = model.decode(z, neg_edge_index).sigmoid()\n",
    "        \n",
    "        # Combine scores and labels\n",
    "        scores = torch.cat([pos_scores, neg_scores])\n",
    "        labels = torch.cat([\n",
    "            torch.ones(pos_scores.size(0)),\n",
    "            torch.zeros(neg_scores.size(0))\n",
    "        ])\n",
    "        \n",
    "        # Calculate metrics\n",
    "        auc = roc_auc_score(labels.cpu(), scores.cpu())\n",
    "        ap = average_precision_score(labels.cpu(), scores.cpu())\n",
    "        \n",
    "    return auc, ap\n",
    "\n",
    "def generate_negative_edges(edge_index, num_nodes, num_neg_samples):\n",
    "    \"\"\"\n",
    "    Generate negative edges for evaluation\n",
    "    \"\"\"\n",
    "    return negative_sampling(\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=num_nodes,\n",
    "        num_neg_samples=num_neg_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Training GAE Model\n\n### Mathematical Analysis of GAE Training\n\n**Optimization Landscape:**\nThe GAE loss function is non-convex due to the neural network encoder:\n$$\\mathcal{L}_{\\text{GAE}}(\\boldsymbol{\\theta}) = -\\sum_{(i,j) \\in \\mathcal{E}^+} \\log \\sigma(\\mathbf{z}_i^T(\\boldsymbol{\\theta}) \\mathbf{z}_j(\\boldsymbol{\\theta})) - \\sum_{(i,j) \\in \\mathcal{E}^-} \\log(1 - \\sigma(\\mathbf{z}_i^T(\\boldsymbol{\\theta}) \\mathbf{z}_j(\\boldsymbol{\\theta})))$$\n\n**Gradient Flow Analysis:**\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\theta}} = \\sum_{(i,j)} \\left(\\hat{A}_{ij} - A_{ij}\\right) \\frac{\\partial}{\\partial \\boldsymbol{\\theta}}[\\mathbf{z}_i^T \\mathbf{z}_j]$$\n\nwhere $\\hat{A}_{ij} = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$ is the predicted edge probability.\n\n**Training Dynamics:**\n1. **Early Stage**: Model learns to distinguish connected vs. disconnected node pairs\n2. **Mid Stage**: Embeddings become more structured, capturing community information  \n3. **Late Stage**: Fine-tuning of embedding similarities for edge prediction\n\n**Convergence Properties:**\n- **Local Minima**: Multiple local optima exist due to permutation symmetry\n- **Saddle Points**: Abundant in high-dimensional parameter space\n- **Convergence Rate**: Typically $O(1/\\sqrt{t})$ for Adam optimizer\n\n**Regularization Effects:**\n- **Dropout**: Prevents overfitting to specific edge patterns\n- **Weight Decay**: $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{GAE}} + \\lambda \\|\\boldsymbol{\\theta}\\|_2^2$\n- **Early Stopping**: Prevents overfitting to training edges\n\n**Model Architecture Impact:**\n- **Embedding Dimension $k$**: Larger $k$ increases capacity but may overfit\n- **Encoder Depth**: Deeper networks capture multi-hop relationships\n- **Hidden Dimensions**: Affect representational power and computational cost\n\n**CPU-Optimized Configuration:**\n- Embedding dimension: $k = 16$ (reduced from typical 32-64)\n- Hidden dimension: $d_h = 32$ (balanced performance/memory)\n- Dropout rate: $p = 0.1$ (light regularization)\n- Learning rate: $\\alpha = 0.01$ (stable convergence)\n\nThe mathematical framework ensures efficient training while maintaining model expressiveness for link prediction tasks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GAE model\n",
    "device = torch.device('cpu')  # Using CPU for MacBook Air M2\n",
    "torch.set_num_threads(8)  # Optimize for M2 8-core CPU\n",
    "\n",
    "# Create encoder and GAE model\n",
    "encoder = GCNEncoder(dataset.num_features, 32, 16)  # Smaller dimensions for CPU\n",
    "gae_model = GAE(encoder).to(device)\n",
    "\n",
    "# Move data to device\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer_gae = torch.optim.Adam(gae_model.parameters(), lr=0.01)\n",
    "epochs = 100\n",
    "\n",
    "# Training loop\n",
    "gae_losses = []\n",
    "gae_val_aucs = []\n",
    "gae_val_aps = []\n",
    "\n",
    "print(\"Training GAE...\")\n",
    "for epoch in range(epochs):\n",
    "    loss = train_gae(gae_model, train_data, optimizer_gae, device)\n",
    "    gae_losses.append(loss)\n",
    "    \n",
    "    # Evaluate every 10 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        # Generate negative edges for validation\n",
    "        neg_edge_index = generate_negative_edges(\n",
    "            val_data.edge_label_index[:, val_data.edge_label == 1],\n",
    "            train_data.num_nodes,\n",
    "            val_data.edge_label_index[:, val_data.edge_label == 1].size(1)\n",
    "        )\n",
    "        \n",
    "        auc, ap = evaluate_model(\n",
    "            gae_model, train_data,\n",
    "            val_data.edge_label_index[:, val_data.edge_label == 1],\n",
    "            neg_edge_index\n",
    "        )\n",
    "        \n",
    "        gae_val_aucs.append(auc)\n",
    "        gae_val_aps.append(ap)\n",
    "        \n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Val AUC: {auc:.4f}, Val AP: {ap:.4f}')\n",
    "\n",
    "print(\"GAE training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Training VGAE Model\n\n### Mathematical Analysis of VGAE Training\n\n**Variational Inference Framework:**\nVGAE optimizes the Evidence Lower BOund (ELBO):\n$$\\log p(\\mathbf{A}|\\mathbf{X}) \\geq \\mathbb{E}_{q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})}[\\log p_{\\theta}(\\mathbf{A}|\\mathbf{Z})] - D_{KL}[q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A}) \\| p(\\mathbf{Z})]$$\n\n**Loss Function Decomposition:**\n$$\\mathcal{L}_{\\text{VGAE}} = \\mathcal{L}_{\\text{recon}} + \\beta \\mathcal{L}_{\\text{KL}}$$\n\n**Reconstruction Loss Gradients:**\n$$\\frac{\\partial \\mathcal{L}_{\\text{recon}}}{\\partial \\boldsymbol{\\mu}_i} = \\mathbb{E}_{\\boldsymbol{\\epsilon}}[\\frac{\\partial}{\\partial \\mathbf{z}_i} \\log p(\\mathbf{A}|\\mathbf{Z})] \\bigg|_{\\mathbf{z}_i = \\boldsymbol{\\mu}_i + \\boldsymbol{\\sigma}_i \\odot \\boldsymbol{\\epsilon}}$$\n\n$$\\frac{\\partial \\mathcal{L}_{\\text{recon}}}{\\partial \\log \\boldsymbol{\\sigma}_i} = \\mathbb{E}_{\\boldsymbol{\\epsilon}}[\\boldsymbol{\\epsilon} \\odot \\frac{\\partial}{\\partial \\mathbf{z}_i} \\log p(\\mathbf{A}|\\mathbf{Z})] \\bigg|_{\\mathbf{z}_i = \\boldsymbol{\\mu}_i + \\boldsymbol{\\sigma}_i \\odot \\boldsymbol{\\epsilon}}$$\n\n**KL Divergence Gradients:**\n$$\\frac{\\partial \\mathcal{L}_{\\text{KL}}}{\\partial \\boldsymbol{\\mu}_i} = \\boldsymbol{\\mu}_i$$\n\n$$\\frac{\\partial \\mathcal{L}_{\\text{KL}}}{\\partial \\log \\boldsymbol{\\sigma}_i} = 1 - \\boldsymbol{\\sigma}_i^2$$\n\n**Training Dynamics Analysis:**\n\n**Phase 1: Reconstruction Focus** (Early epochs)\n- KL loss is small, reconstruction loss dominates\n- Model learns basic graph structure patterns\n- Embeddings may have high variance\n\n**Phase 2: Regularization Balance** (Mid epochs)  \n- KL loss increases, providing regularization\n- Embeddings become more structured and smooth\n- Trade-off between reconstruction and regularization\n\n**Phase 3: Fine-tuning** (Late epochs)\n- Both losses stabilize\n- Embeddings capture detailed graph structure\n- Model achieves optimal reconstruction-regularization balance\n\n**Hyperparameter Effects:**\n\n**KL Weight $\\beta$:**\n- $\\beta = 0$: Reduces to standard autoencoder (no regularization)\n- $\\beta = 1$: Standard VAE formulation\n- $\\beta > 1$: Strong regularization, may underfit\n- $\\beta < 1$: Weak regularization, may overfit\n\n**Embedding Dimension Trade-off:**\n$$\\text{Model Capacity} \\propto k \\times \\log k$$\n$$\\text{KL Regularization} \\propto k$$\n\n**Optimization Challenges:**\n1. **Posterior Collapse**: $q_{\\phi}(\\mathbf{Z}) \\approx p(\\mathbf{Z})$, loss of information\n2. **KL Vanishing**: Early training may ignore KL term\n3. **Local Optima**: Multiple solutions due to symmetries\n\n**Mitigation Strategies:**\n- **KL Annealing**: Gradually increase $\\beta$ during training\n- **Free Bits**: Prevent KL from dropping below threshold\n- **Architectural Constraints**: Limit encoder capacity\n\nThe probabilistic framework provides more robust embeddings through Bayesian regularization while maintaining link prediction performance."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VGAE model\n",
    "vgae_encoder = VariationalGCNEncoder(dataset.num_features, 32, 16)\n",
    "vgae_model = VGAE(vgae_encoder).to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer_vgae = torch.optim.Adam(vgae_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "vgae_losses = []\n",
    "vgae_recon_losses = []\n",
    "vgae_kl_losses = []\n",
    "vgae_val_aucs = []\n",
    "vgae_val_aps = []\n",
    "\n",
    "print(\"\\nTraining VGAE...\")\n",
    "for epoch in range(epochs):\n",
    "    loss, recon_loss, kl_loss = train_vgae(vgae_model, train_data, optimizer_vgae, device)\n",
    "    vgae_losses.append(loss)\n",
    "    vgae_recon_losses.append(recon_loss)\n",
    "    vgae_kl_losses.append(kl_loss)\n",
    "    \n",
    "    # Evaluate every 10 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        # Generate negative edges for validation\n",
    "        neg_edge_index = generate_negative_edges(\n",
    "            val_data.edge_label_index[:, val_data.edge_label == 1],\n",
    "            train_data.num_nodes,\n",
    "            val_data.edge_label_index[:, val_data.edge_label == 1].size(1)\n",
    "        )\n",
    "        \n",
    "        auc, ap = evaluate_model(\n",
    "            vgae_model, train_data,\n",
    "            val_data.edge_label_index[:, val_data.edge_label == 1],\n",
    "            neg_edge_index\n",
    "        )\n",
    "        \n",
    "        vgae_val_aucs.append(auc)\n",
    "        vgae_val_aps.append(ap)\n",
    "        \n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Recon: {recon_loss:.4f}, '\n",
    "              f'KL: {kl_loss:.4f}, Val AUC: {auc:.4f}, Val AP: {ap:.4f}')\n",
    "\n",
    "print(\"VGAE training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Model Comparison and Visualization\n\n### Mathematical Analysis of Training Dynamics\n\n**Learning Curve Analysis:**\n\n**GAE Loss Evolution:**\n$$\\mathcal{L}_{\\text{GAE}}(t) = \\mathcal{L}_{\\text{GAE}}(\\infty) + C_1 e^{-\\alpha_1 t}$$\n\nwhere $t$ is training epoch, exhibiting exponential convergence to optimal loss.\n\n**VGAE Loss Components:**\n$$\\mathcal{L}_{\\text{VGAE}}(t) = \\mathcal{L}_{\\text{recon}}(t) + \\beta \\mathcal{L}_{\\text{KL}}(t)$$\n\n**Reconstruction Loss**: Similar exponential decay as GAE\n**KL Loss**: Often increases initially, then stabilizes\n$$\\mathcal{L}_{\\text{KL}}(t) = \\mathcal{L}_{\\text{KL}}(\\infty)(1 - e^{-\\alpha_2 t})$$\n\n**Validation Performance Analysis:**\n\n**AUC Convergence:**\n$$\\text{AUC}(t) = \\text{AUC}_{\\max} - (\\text{AUC}_{\\max} - \\text{AUC}_0) e^{-\\beta t}$$\n\n**Overfitting Detection:**\nMonitor validation vs. training performance gap:\n$$\\text{Generalization Gap} = \\text{AUC}_{\\text{train}}(t) - \\text{AUC}_{\\text{val}}(t)$$\n\n**Model Complexity Comparison:**\n\n**Parameter Count Analysis:**\n- **GAE**: $|\\theta_{\\text{GAE}}| = (d \\times h + h \\times k) \\times L$ where $L$ is number of layers\n- **VGAE**: $|\\theta_{\\text{VGAE}}| = |\\theta_{\\text{GAE}}| + h \\times k$ (additional variance parameters)\n\n**Computational Complexity:**\n- **Forward Pass**: $O(|\\mathcal{E}| \\times h + N \\times h \\times k)$ for both models\n- **Backward Pass**: Additional KL gradient computation for VGAE: $O(N \\times k)$\n\n**Statistical Analysis:**\n\n**Performance Comparison Framework:**\nUse paired t-test to compare AUC scores:\n$$t = \\frac{\\bar{d}}{\\frac{s_d}{\\sqrt{n}}}$$\n\nwhere $\\bar{d}$ is mean difference, $s_d$ is standard deviation of differences.\n\n**Effect Size (Cohen's d):**\n$$d = \\frac{\\mu_{\\text{VGAE}} - \\mu_{\\text{GAE}}}{\\sigma_{\\text{pooled}}}$$\n\n**Learning Rate Sensitivity:**\nBoth models show robustness to learning rate in range $[0.001, 0.01]$:\n$$\\text{Sensitivity} = \\frac{\\partial \\text{AUC}}{\\partial \\alpha} \\bigg|_{\\alpha = \\alpha_0}$$\n\n**Regularization Effects:**\n- **GAE**: Relies primarily on dropout and weight decay\n- **VGAE**: Inherent regularization through KL divergence provides better generalization\n\n**Convergence Diagnostics:**\n- **Loss Plateauing**: Indicates convergence or local minimum\n- **Validation Performance**: Monitor for early stopping\n- **Gradient Norms**: Track to detect vanishing/exploding gradients\n\nThe mathematical analysis reveals trade-offs between model complexity, training stability, and final performance."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training losses\n",
    "axes[0, 0].plot(gae_losses, label='GAE', alpha=0.8, color='blue')\n",
    "axes[0, 0].plot(vgae_losses, label='VGAE Total', alpha=0.8, color='red')\n",
    "axes[0, 0].plot(vgae_recon_losses, label='VGAE Recon', alpha=0.8, color='orange')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training Loss Comparison')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# KL divergence for VGAE\n",
    "axes[0, 1].plot(vgae_kl_losses, alpha=0.8, color='purple')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('KL Divergence Loss')\n",
    "axes[0, 1].set_title('VGAE KL Divergence')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation AUC\n",
    "epochs_eval = range(0, epochs, 20)\n",
    "axes[1, 0].plot(epochs_eval, gae_val_aucs, 'o-', label='GAE', alpha=0.8, color='blue')\n",
    "axes[1, 0].plot(epochs_eval, vgae_val_aucs, 'o-', label='VGAE', alpha=0.8, color='red')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Validation AUC')\n",
    "axes[1, 0].set_title('Validation AUC Comparison')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation AP\n",
    "axes[1, 1].plot(epochs_eval, gae_val_aps, 'o-', label='GAE', alpha=0.8, color='blue')\n",
    "axes[1, 1].plot(epochs_eval, vgae_val_aps, 'o-', label='VGAE', alpha=0.8, color='red')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Validation AP')\n",
    "axes[1, 1].set_title('Validation AP Comparison')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Test Evaluation\n",
    "\n",
    "Let's evaluate both models on the test set to get their final performance scores. We'll compare their ability to predict held-out edges and distinguish them from negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test evaluation\n",
    "print(\"=== Final Test Evaluation ===\")\n",
    "\n",
    "# Generate negative test edges\n",
    "test_neg_edge_index = generate_negative_edges(\n",
    "    test_data.edge_label_index[:, test_data.edge_label == 1],\n",
    "    train_data.num_nodes,\n",
    "    test_data.edge_label_index[:, test_data.edge_label == 1].size(1)\n",
    ")\n",
    "\n",
    "# Evaluate GAE\n",
    "gae_test_auc, gae_test_ap = evaluate_model(\n",
    "    gae_model, train_data,\n",
    "    test_data.edge_label_index[:, test_data.edge_label == 1],\n",
    "    test_neg_edge_index\n",
    ")\n",
    "\n",
    "# Evaluate VGAE\n",
    "vgae_test_auc, vgae_test_ap = evaluate_model(\n",
    "    vgae_model, train_data,\n",
    "    test_data.edge_label_index[:, test_data.edge_label == 1],\n",
    "    test_neg_edge_index\n",
    ")\n",
    "\n",
    "print(f\"{'Model':<8} {'Test AUC':<10} {'Test AP':<10}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"{'GAE':<8} {gae_test_auc:<10.4f} {gae_test_ap:<10.4f}\")\n",
    "print(f\"{'VGAE':<8} {vgae_test_auc:<10.4f} {vgae_test_ap:<10.4f}\")\n",
    "\n",
    "# Model complexity comparison\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "gae_params = count_parameters(gae_model)\n",
    "vgae_params = count_parameters(vgae_model)\n",
    "\n",
    "print(f\"\\n=== Model Complexity ===\")\n",
    "print(f\"GAE parameters: {gae_params}\")\n",
    "print(f\"VGAE parameters: {vgae_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Node Embeddings and Clustering Analysis\n\n### Mathematical Framework for Embedding Quality Assessment\n\n**Embedding Space Analysis:**\n\nThe learned embeddings $\\mathbf{Z} \\in \\mathbb{R}^{N \\times k}$ should exhibit desirable geometric properties:\n\n**1. Cluster Separability:**\n$$\\text{Inter-cluster distance} > \\text{Intra-cluster distance}$$\n\nFormally, for clusters $\\mathcal{C}_1, \\mathcal{C}_2$:\n$$\\min_{i \\in \\mathcal{C}_1, j \\in \\mathcal{C}_2} \\|\\mathbf{z}_i - \\mathbf{z}_j\\|_2 > \\max_{i,j \\in \\mathcal{C}_1} \\|\\mathbf{z}_i - \\mathbf{z}_j\\|_2$$\n\n**2. Graph Structure Preservation:**\n$$\\|\\mathbf{z}_i - \\mathbf{z}_j\\|_2 \\approx f(d_{\\mathcal{G}}(i,j))$$\n\nwhere $d_{\\mathcal{G}}(i,j)$ is the shortest path distance in the graph.\n\n**Clustering Evaluation Metrics:**\n\n**1. Adjusted Rand Index (ARI):**\n$$\\text{ARI} = \\frac{\\sum_{ij} \\binom{n_{ij}}{2} - \\left[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2}\\right] / \\binom{n}{2}}{\\frac{1}{2}\\left[\\sum_i \\binom{a_i}{2} + \\sum_j \\binom{b_j}{2}\\right] - \\left[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2}\\right] / \\binom{n}{2}}$$\n\nwhere:\n- $n_{ij}$: Number of objects in both cluster $i$ and class $j$\n- $a_i = \\sum_j n_{ij}$: Total objects in cluster $i$  \n- $b_j = \\sum_i n_{ij}$: Total objects in class $j$\n\n**2. Normalized Mutual Information (NMI):**\n$$\\text{NMI} = \\frac{2 \\times I(\\mathcal{C}, \\mathcal{Y})}{H(\\mathcal{C}) + H(\\mathcal{Y})}$$\n\nwhere:\n- $I(\\mathcal{C}, \\mathcal{Y}) = \\sum_{c,y} P(c,y) \\log \\frac{P(c,y)}{P(c)P(y)}$: Mutual information\n- $H(\\mathcal{C}) = -\\sum_c P(c) \\log P(c)$: Entropy of cluster assignments\n- $H(\\mathcal{Y}) = -\\sum_y P(y) \\log P(y)$: Entropy of true labels\n\n**K-Means Clustering Objective:**\n$$\\arg\\min_{\\mathcal{C}} \\sum_{i=1}^k \\sum_{\\mathbf{z} \\in \\mathcal{C}_i} \\|\\mathbf{z} - \\boldsymbol{\\mu}_i\\|_2^2$$\n\nwhere $\\boldsymbol{\\mu}_i = \\frac{1}{|\\mathcal{C}_i|} \\sum_{\\mathbf{z} \\in \\mathcal{C}_i} \\mathbf{z}$ is the cluster centroid.\n\n**Embedding Quality Indicators:**\n\n**1. Silhouette Score:**\n$$s_i = \\frac{b_i - a_i}{\\max(a_i, b_i)}$$\n\nwhere:\n- $a_i$: Average distance to other points in same cluster\n- $b_i$: Average distance to points in nearest different cluster\n\n**2. Davies-Bouldin Index:**\n$$\\text{DB} = \\frac{1}{k} \\sum_{i=1}^k \\max_{j \\neq i} \\frac{\\sigma_i + \\sigma_j}{d_{ij}}$$\n\nwhere $\\sigma_i$ is intra-cluster distance and $d_{ij}$ is inter-cluster distance.\n\n**Comparison Framework:**\n\n**Statistical Significance Testing:**\nUse Wilcoxon signed-rank test for comparing clustering performance:\n$$Z = \\frac{W - \\mu_W}{\\sigma_W}$$\n\nwhere $W$ is the test statistic for paired differences.\n\n**Effect Size Analysis:**\n$$r = \\frac{Z}{\\sqrt{N}}$$\n\nwhere $N$ is the total number of observations.\n\n**Embedding Dimension Impact:**\n$$\\text{Clustering Quality} \\propto \\log(k) \\times \\text{Signal-to-Noise Ratio}$$\n\nHigher dimensions can capture more information but may include noise that hurts clustering performance.\n\nThe mathematical framework enables rigorous assessment of embedding quality for downstream clustering tasks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from both models\n",
    "gae_model.eval()\n",
    "vgae_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get original data for full graph\n",
    "    original_data = dataset[0].to(device)\n",
    "    \n",
    "    # GAE embeddings\n",
    "    gae_embeddings = gae_model.encode(original_data.x, original_data.edge_index).cpu().numpy()\n",
    "    \n",
    "    # VGAE embeddings (mean of the distribution)\n",
    "    vgae_embeddings = vgae_model.encode(original_data.x, original_data.edge_index).cpu().numpy()\n",
    "    \n",
    "    # True labels for clustering evaluation\n",
    "    true_labels = original_data.y.cpu().numpy()\n",
    "\n",
    "print(f\"GAE embedding shape: {gae_embeddings.shape}\")\n",
    "print(f\"VGAE embedding shape: {vgae_embeddings.shape}\")\n",
    "print(f\"Number of true classes: {len(np.unique(true_labels))}\")\n",
    "\n",
    "# Clustering evaluation\n",
    "def evaluate_clustering(embeddings, true_labels, n_clusters):\n",
    "    \"\"\"\n",
    "    Evaluate clustering quality using embeddings\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    ari = adjusted_rand_score(true_labels, cluster_labels)\n",
    "    nmi = normalized_mutual_info_score(true_labels, cluster_labels)\n",
    "    \n",
    "    return ari, nmi, cluster_labels\n",
    "\n",
    "# Evaluate clustering for both models\n",
    "n_classes = len(np.unique(true_labels))\n",
    "\n",
    "gae_ari, gae_nmi, gae_clusters = evaluate_clustering(gae_embeddings, true_labels, n_classes)\n",
    "vgae_ari, vgae_nmi, vgae_clusters = evaluate_clustering(vgae_embeddings, true_labels, n_classes)\n",
    "\n",
    "print(f\"\\n=== Clustering Performance ===\")\n",
    "print(f\"{'Model':<8} {'ARI':<8} {'NMI':<8}\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"{'GAE':<8} {gae_ari:<8.4f} {gae_nmi:<8.4f}\")\n",
    "print(f\"{'VGAE':<8} {vgae_ari:<8.4f} {vgae_nmi:<8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Embeddings Visualization\n\n### Mathematical Foundation of Dimensionality Reduction\n\n**t-Distributed Stochastic Neighbor Embedding (t-SNE):**\n\nt-SNE preserves local neighborhood structure when reducing from high-dimensional embeddings $\\mathbf{Z} \\in \\mathbb{R}^{N \\times k}$ to 2D visualization space $\\mathbf{Y} \\in \\mathbb{R}^{N \\times 2}$.\n\n**Step 1: High-Dimensional Similarities**\n$$p_{j|i} = \\frac{\\exp(-\\|\\mathbf{z}_i - \\mathbf{z}_j\\|^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i} \\exp(-\\|\\mathbf{z}_i - \\mathbf{z}_k\\|^2 / 2\\sigma_i^2)}$$\n\n$$p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2N}$$\n\nwhere $\\sigma_i$ is chosen such that perplexity $\\text{Perp}(P_i) = 2^{H(P_i)}$ equals a target value (typically 30).\n\n**Step 2: Low-Dimensional Similarities**\n$$q_{ij} = \\frac{(1 + \\|\\mathbf{y}_i - \\mathbf{y}_j\\|^2)^{-1}}{\\sum_{k \\neq l} (1 + \\|\\mathbf{y}_k - \\mathbf{y}_l\\|^2)^{-1}}$$\n\nUses Student t-distribution with 1 degree of freedom to handle crowding problem.\n\n**Step 3: Optimization Objective**\n$$\\mathcal{L} = \\text{KL}(P||Q) = \\sum_i \\sum_j p_{ij} \\log \\frac{p_{ij}}{q_{ij}}$$\n\n**Gradient Computation:**\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}_i} = 4 \\sum_j (p_{ij} - q_{ij})(\\mathbf{y}_i - \\mathbf{y}_j)(1 + \\|\\mathbf{y}_i - \\mathbf{y}_j\\|^2)^{-1}$$\n\n**Interpretation Guidelines:**\n\n**1. Cluster Cohesion:**\nTight clusters in t-SNE indicate nodes with similar embeddings:\n$$\\text{Cluster Quality} = \\frac{\\text{Inter-cluster distance}}{\\text{Intra-cluster distance}}$$\n\n**2. Separation Assessment:**\nWell-separated clusters suggest good class discrimination:\n$$\\text{Separation Score} = \\min_{c_1 \\neq c_2} \\frac{d(\\text{centroid}_{c_1}, \\text{centroid}_{c_2})}{\\max(\\text{radius}_{c_1}, \\text{radius}_{c_2})}$$\n\n**3. Neighborhood Preservation:**\n$$\\text{Trustworthiness} = 1 - \\frac{2}{NK(2N-3K-1)} \\sum_{i=1}^N \\sum_{j \\in U_K(i)} (r(i,j) - K)$$\n\nwhere $U_K(i)$ are the $K$-nearest neighbors of point $i$ in the low-dimensional space that are not among its $K$-nearest neighbors in high-dimensional space.\n\n**Embedding Quality Indicators:**\n\n**1. Local Structure Preservation:**\n$$\\text{Local Score} = \\frac{1}{N} \\sum_{i=1}^N \\frac{|N_k^{\\text{high}}(i) \\cap N_k^{\\text{low}}(i)|}{k}$$\n\n**2. Global Structure Preservation:**\n$$\\text{Global Score} = \\text{Correlation}(\\text{dist}_{\\text{high}}, \\text{dist}_{\\text{low}})$$\n\n**Visualization Diagnostics:**\n\n**1. Perplexity Sensitivity:**\n- Low perplexity (5-15): Emphasizes local structure\n- High perplexity (50-100): Emphasizes global structure\n- Optimal range: 20-50 for most applications\n\n**2. Convergence Assessment:**\nMonitor KL divergence convergence:\n$$\\Delta \\mathcal{L} = |\\mathcal{L}(t) - \\mathcal{L}(t-1)| < \\epsilon$$\n\n**GAE vs. VGAE Visualization Comparison:**\n\n**Expected Differences:**\n- **GAE**: May show more scattered embeddings due to deterministic nature\n- **VGAE**: Often produces more structured, compact clusters due to KL regularization\n\n**Quantitative Assessment:**\n$$\\text{Cluster Compactness} = \\frac{1}{C} \\sum_{c=1}^C \\frac{1}{|c|} \\sum_{i \\in c} \\|\\mathbf{y}_i - \\boldsymbol{\\mu}_c\\|_2$$\n\nThe mathematical framework enables principled interpretation of embedding visualizations and comparison between different autoencoder architectures."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings using t-SNE\n",
    "print(\"Applying t-SNE to embeddings...\")\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "gae_embeddings_2d = tsne.fit_transform(gae_embeddings)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "vgae_embeddings_2d = tsne.fit_transform(vgae_embeddings)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# GAE embeddings\n",
    "scatter1 = axes[0].scatter(gae_embeddings_2d[:, 0], gae_embeddings_2d[:, 1], \n",
    "                          c=true_labels, cmap='tab10', alpha=0.7, s=20)\n",
    "axes[0].set_title('GAE Embeddings (t-SNE)')\n",
    "axes[0].set_xlabel('t-SNE Dimension 1')\n",
    "axes[0].set_ylabel('t-SNE Dimension 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# VGAE embeddings\n",
    "scatter2 = axes[1].scatter(vgae_embeddings_2d[:, 0], vgae_embeddings_2d[:, 1], \n",
    "                          c=true_labels, cmap='tab10', alpha=0.7, s=20)\n",
    "axes[1].set_title('VGAE Embeddings (t-SNE)')\n",
    "axes[1].set_xlabel('t-SNE Dimension 1')\n",
    "axes[1].set_ylabel('t-SNE Dimension 2')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Node Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. Reconstruction Quality Analysis\n\n### Mathematical Framework for Reconstruction Assessment\n\n**Reconstruction Score Distribution Analysis:**\n\nThe reconstruction scores $s_{ij} = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$ should exhibit different distributions for positive and negative edges:\n\n**For Positive Edges:** $s_{ij} \\sim \\mathcal{D}_{\\text{pos}}$ with higher mean\n**For Negative Edges:** $s_{ij} \\sim \\mathcal{D}_{\\text{neg}}$ with lower mean\n\n**Ideal Separation:**\n$$\\mathbb{E}[s_{ij}^+] - \\mathbb{E}[s_{ij}^-] > k \\times \\sqrt{\\text{Var}[s_{ij}^+] + \\text{Var}[s_{ij}^-]}$$\n\nwhere $k \\geq 2$ for good separation.\n\n**Statistical Analysis of Reconstruction:**\n\n**1. Signal-to-Noise Ratio:**\n$$\\text{SNR} = \\frac{(\\mu_{\\text{pos}} - \\mu_{\\text{neg}})^2}{\\sigma_{\\text{pos}}^2 + \\sigma_{\\text{neg}}^2}$$\n\nHigher SNR indicates better discriminative power.\n\n**2. Overlap Coefficient:**\n$$\\text{Overlap} = \\frac{\\int \\min(\\mathcal{D}_{\\text{pos}}(x), \\mathcal{D}_{\\text{neg}}(x)) dx}{\\int \\mathcal{D}_{\\text{pos}}(x) dx}$$\n\nLower overlap indicates better separation.\n\n**3. KL Divergence Between Distributions:**\n$$D_{KL}(\\mathcal{D}_{\\text{pos}} \\| \\mathcal{D}_{\\text{neg}}) = \\int \\mathcal{D}_{\\text{pos}}(x) \\log \\frac{\\mathcal{D}_{\\text{pos}}(x)}{\\mathcal{D}_{\\text{neg}}(x)} dx$$\n\n**Reconstruction Error Analysis:**\n\n**Per-Edge Reconstruction Error:**\n$$\\epsilon_{ij} = |A_{ij} - \\hat{A}_{ij}|$$\n\n**Graph-Level Reconstruction Metrics:**\n\n**1. Frobenius Norm Error:**\n$$\\text{Error}_F = \\|\\mathbf{A} - \\hat{\\mathbf{A}}\\|_F = \\sqrt{\\sum_{i,j} (A_{ij} - \\hat{A}_{ij})^2}$$\n\n**2. Normalized Reconstruction Error:**\n$$\\text{Error}_{\\text{norm}} = \\frac{\\|\\mathbf{A} - \\hat{\\mathbf{A}}\\|_F}{\\|\\mathbf{A}\\|_F}$$\n\n**3. Spectral Reconstruction Quality:**\nCompare eigenvalues of original and reconstructed adjacency matrices:\n$$\\text{Spectral Error} = \\sum_{i=1}^k |\\lambda_i(\\mathbf{A}) - \\lambda_i(\\hat{\\mathbf{A}})|$$\n\n**Threshold Analysis:**\n\n**Optimal Threshold Selection:**\n$$\\tau^* = \\arg\\max_{\\tau} \\text{F1}(\\tau) = \\arg\\max_{\\tau} \\frac{2 \\times \\text{Precision}(\\tau) \\times \\text{Recall}(\\tau)}{\\text{Precision}(\\tau) + \\text{Recall}(\\tau)}$$\n\n**ROC Analysis:**\n$$\\text{AUC} = \\int_0^1 \\text{TPR}(\\text{FPR}^{-1}(t)) dt = P(\\text{score}_+ > \\text{score}_-)$$\n\n**Precision-Recall Analysis:**\n$$\\text{AP} = \\int_0^1 \\text{Precision}(\\text{Recall}^{-1}(r)) dr$$\n\n**Model-Specific Analysis:**\n\n**GAE Reconstruction Properties:**\n- Deterministic scores for same input\n- May exhibit mode collapse for similar nodes\n- Score distribution often more peaked\n\n**VGAE Reconstruction Properties:**\n- Stochastic sampling introduces variability\n- KL regularization may smooth score distributions\n- Often better calibrated probabilities\n\n**Calibration Assessment:**\n$$\\text{ECE} = \\sum_{m=1}^M \\frac{|B_m|}{n} |\\text{acc}(B_m) - \\text{conf}(B_m)|$$\n\nwhere $B_m$ are bins of predictions with similar confidence scores.\n\n**Reconstruction Quality Diagnostics:**\n\n**1. Score Histogram Analysis:**\n- Bimodal distribution indicates good separation\n- Unimodal distribution suggests poor discrimination\n- High variance may indicate unstable embeddings\n\n**2. Calibration Plots:**\nPlot predicted probability vs. actual frequency of positive edges.\n\n**3. Confidence Intervals:**\nFor VGAE, analyze uncertainty in reconstruction scores:\n$$\\text{CI}_{95\\%} = \\hat{A}_{ij} \\pm 1.96 \\times \\text{SE}(\\hat{A}_{ij})$$\n\nThe mathematical framework provides comprehensive assessment of reconstruction quality and model reliability."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze reconstruction quality\n",
    "def analyze_reconstruction(model, data, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Analyze reconstruction scores for positive and negative edges\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        \n",
    "        # Sample some positive edges\n",
    "        pos_edges = data.edge_index[:, :num_samples]\n",
    "        pos_scores = model.decode(z, pos_edges).sigmoid().cpu().numpy()\n",
    "        \n",
    "        # Sample negative edges\n",
    "        neg_edges = generate_negative_edges(data.edge_index, data.num_nodes, num_samples)\n",
    "        neg_scores = model.decode(z, neg_edges).sigmoid().cpu().numpy()\n",
    "        \n",
    "    return pos_scores, neg_scores\n",
    "\n",
    "# Get reconstruction scores\n",
    "gae_pos_scores, gae_neg_scores = analyze_reconstruction(gae_model, original_data)\n",
    "vgae_pos_scores, vgae_neg_scores = analyze_reconstruction(vgae_model, original_data)\n",
    "\n",
    "# Plot reconstruction score distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# GAE reconstruction scores\n",
    "axes[0].hist(gae_pos_scores, bins=50, alpha=0.7, label='Positive Edges', color='green')\n",
    "axes[0].hist(gae_neg_scores, bins=50, alpha=0.7, label='Negative Edges', color='red')\n",
    "axes[0].set_xlabel('Reconstruction Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('GAE Reconstruction Scores')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# VGAE reconstruction scores\n",
    "axes[1].hist(vgae_pos_scores, bins=50, alpha=0.7, label='Positive Edges', color='green')\n",
    "axes[1].hist(vgae_neg_scores, bins=50, alpha=0.7, label='Negative Edges', color='red')\n",
    "axes[1].set_xlabel('Reconstruction Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('VGAE Reconstruction Scores')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"=== Reconstruction Score Statistics ===\")\n",
    "print(f\"{'Model':<6} {'Pos Mean':<10} {'Pos Std':<10} {'Neg Mean':<10} {'Neg Std':<10}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'GAE':<6} {gae_pos_scores.mean():<10.4f} {gae_pos_scores.std():<10.4f} \"\n",
    "      f\"{gae_neg_scores.mean():<10.4f} {gae_neg_scores.std():<10.4f}\")\n",
    "print(f\"{'VGAE':<6} {vgae_pos_scores.mean():<10.4f} {vgae_pos_scores.std():<10.4f} \"\n",
    "      f\"{vgae_neg_scores.mean():<10.4f} {vgae_neg_scores.std():<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. CPU Optimization Tips for Graph Autoencoders\n\n### Mathematical Framework for Computational Optimization\n\n**Computational Complexity Analysis:**\n\n**Memory Complexity:**\n$$M_{\\text{total}} = M_{\\text{features}} + M_{\\text{embeddings}} + M_{\\text{gradients}} + M_{\\text{adjacency}}$$\n\nwhere:\n- $M_{\\text{features}} = N \\times d \\times \\text{sizeof}(\\text{float})$\n- $M_{\\text{embeddings}} = N \\times k \\times \\text{sizeof}(\\text{float})$ \n- $M_{\\text{gradients}} = 2 \\times |\\theta| \\times \\text{sizeof}(\\text{float})$ (for Adam)\n- $M_{\\text{adjacency}} = N^2 \\times \\text{sizeof}(\\text{bool})$ (dense) or $2|\\mathcal{E}| \\times \\text{sizeof}(\\text{int})$ (sparse)\n\n**Time Complexity per Training Step:**\n\n**Forward Pass:**\n- **GCN Layers**: $O(|\\mathcal{E}| \\times d_{\\text{hidden}} + N \\times d_{\\text{hidden}}^2)$\n- **Decoding**: $O(|\\mathcal{E}_{\\text{batch}}| \\times k)$ for sampled edges\n- **Total Forward**: $O(|\\mathcal{E}| \\times d + N \\times d^2)$\n\n**Backward Pass:**\n- **Similar to forward but with gradient computation overhead**\n- **VGAE Additional**: $O(N \\times k)$ for KL divergence gradients\n\n**Optimization Strategies:**\n\n**1. Architecture Scaling:**\n$$\\text{Parameters} = d \\times h + h \\times k + \\text{bias terms}$$\n\n**Optimal Scaling for M2 MacBook Air:**\n- Input dimension: $d = 1433$ (fixed by dataset)\n- Hidden dimension: $h = 32$ (reduced from typical 64-128)\n- Embedding dimension: $k = 16$ (reduced from typical 32-64)\n\n**Parameter Count:**\n$$|\\theta| = 1433 \\times 32 + 32 \\times 16 + \\text{biases} \\approx 46,400$$\n\n**2. Memory Optimization:**\n\n**Gradient Checkpointing:**\n$$M_{\\text{activations}} = \\sqrt{L} \\times M_{\\text{layer}}$$\n\ninstead of $L \\times M_{\\text{layer}}$ for $L$ layers.\n\n**Mixed Precision Training:**\nUse FP16 for forward pass, FP32 for gradients:\n$$M_{\\text{reduction}} \\approx 50\\%$$\n\n**Sparse Adjacency Representation:**\n$$M_{\\text{sparse}} = 2|\\mathcal{E}| \\times 4 \\text{ bytes} \\ll N^2 \\times 1 \\text{ byte}$$\n\n**3. Computational Optimization:**\n\n**Batch Size Scaling:**\n$$\\text{Throughput} = \\frac{B \\times \\text{Gradient Updates}}{\\text{Wall Clock Time}}$$\n\nOptimal batch size for CPU: $B = 32-128$ edges per batch.\n\n**Negative Sampling Efficiency:**\n$$\\text{Sampling Complexity} = O(|\\mathcal{E}^+| \\times \\log(N^2 - |\\mathcal{E}|))$$\n\n**4. PyTorch-Specific Optimizations:**\n\n**Thread Configuration:**\n```python\ntorch.set_num_threads(8)  # M2 has 8 cores\ntorch.set_num_interop_threads(2)  # Reduce overhead\n```\n\n**Memory Management:**\n```python\ntorch.backends.mkldnn.enabled = True  # Intel MKL-DNN\ntorch.backends.cudnn.benchmark = False  # CPU mode\n```\n\n**Autograd Optimization:**\n```python\nwith torch.autograd.detect_anomaly():  # Debug mode\n    # Training code\n```\n\n**5. Training Efficiency:**\n\n**Learning Rate Scheduling:**\n$$\\alpha(t) = \\alpha_0 \\times \\gamma^{\\lfloor t/\\text{step\\_size} \\rfloor}$$\n\n**Early Stopping Criterion:**\n$$\\text{Stop if } \\text{AUC}_{\\text{val}}(t) - \\text{AUC}_{\\text{val}}(t-p) < \\epsilon$$\n\nfor patience $p$ and threshold $\\epsilon$.\n\n**6. Evaluation Optimization:**\n\n**Subsampled Evaluation:**\nInstead of evaluating on all possible edges, sample subset:\n$$|\\mathcal{E}_{\\text{eval}}| = \\min(10^4, |\\mathcal{E}_{\\text{total}}|)$$\n\n**Performance Monitoring:**\n\n**CPU Utilization:**\n$$\\text{Efficiency} = \\frac{\\text{CPU Time Used}}{\\text{Wall Clock Time} \\times \\text{Number of Cores}}$$\n\n**Memory Usage:**\n$$\\text{Peak Memory} = \\max_t \\sum_{\\text{tensor}} \\text{size}(\\text{tensor}(t))$$\n\n**Throughput Measurement:**\n$$\\text{Edges per Second} = \\frac{|\\mathcal{E}_{\\text{processed}}|}{\\text{Training Time}}$$\n\nThese mathematical optimizations ensure efficient graph autoencoder training on resource-constrained CPU environments while maintaining model quality."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Optimization Tips for Graph Autoencoders\n",
    "print(\"=== CPU Optimization Tips for Graph Autoencoders ===\")\n",
    "\n",
    "print(\"\\n1. Model Architecture Optimizations:\")\n",
    "print(\"   - Use smaller embedding dimensions (16-32 instead of 64-128)\")\n",
    "print(\"   - Limit encoder to 2-3 layers max\")\n",
    "print(\"   - Use cached=True in GCN layers for repeated computations\")\n",
    "print(\"   - Consider using lighter activation functions (ReLU over ELU)\")\n",
    "\n",
    "print(\"\\n2. Training Optimizations:\")\n",
    "print(\"   - Use fewer negative samples during training\")\n",
    "print(\"   - Implement gradient accumulation for large graphs\")\n",
    "print(\"   - Use learning rate scheduling for better convergence\")\n",
    "print(\"   - Early stopping based on validation metrics\")\n",
    "\n",
    "print(\"\\n3. Memory Management:\")\n",
    "print(\"   - Process graphs in smaller subgraphs if possible\")\n",
    "print(\"   - Use in-place operations where applicable\")\n",
    "print(\"   - Clear intermediate tensors explicitly\")\n",
    "print(\"   - Monitor memory usage with torch.profiler\")\n",
    "\n",
    "print(\"\\n4. Evaluation Efficiency:\")\n",
    "print(\"   - Sample edges for evaluation instead of using all edges\")\n",
    "print(\"   - Use batch processing for large-scale link prediction\")\n",
    "print(\"   - Cache embeddings for multiple evaluation rounds\")\n",
    "\n",
    "# Example of memory-efficient evaluation\n",
    "def memory_efficient_evaluation(model, data, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Memory-efficient evaluation for large graphs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Encode once and reuse\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        \n",
    "        # Process in batches\n",
    "        all_scores = []\n",
    "        for i in range(0, data.edge_index.size(1), batch_size):\n",
    "            batch_edges = data.edge_index[:, i:i+batch_size]\n",
    "            batch_scores = model.decode(z, batch_edges).sigmoid()\n",
    "            all_scores.append(batch_scores)\n",
    "            \n",
    "        return torch.cat(all_scores)\n",
    "\n",
    "print(f\"\\nCurrent setup optimized for M2 MacBook Air:\")\n",
    "print(f\"- PyTorch threads: {torch.get_num_threads()}\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Embedding dimension: 16 (CPU-friendly size)\")\n",
    "print(f\"- Hidden dimension: 32 (balanced performance/memory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n### Comprehensive Mathematical Foundation of Graph Autoencoders\n\nIn this notebook, we have explored the mathematical foundations and practical implementations of graph autoencoders for unsupervised learning:\n\n### **Graph Autoencoder (GAE)**\n- **Mathematical Core**: $\\hat{\\mathbf{A}} = \\sigma(\\mathbf{Z}\\mathbf{Z}^T)$ where $\\mathbf{Z} = \\text{GCN}(\\mathbf{X}, \\mathbf{A})$\n- **Loss Function**: Binary cross-entropy for link prediction\n- **Key Properties**: Deterministic, efficient, interpretable inner product decoder\n- **Advantages**: Simple implementation, stable training, good baseline performance\n- **Limitations**: No uncertainty quantification, potential overfitting to specific edge patterns\n\n### **Variational Graph Autoencoder (VGAE)**\n- **Mathematical Core**: $q_{\\phi}(\\mathbf{Z}|\\mathbf{X},\\mathbf{A}) = \\prod_{i=1}^N \\mathcal{N}(\\boldsymbol{\\mu}_i, \\text{diag}(\\boldsymbol{\\sigma}_i^2))$\n- **ELBO Objective**: $\\mathcal{L} = \\mathbb{E}[\\log p(\\mathbf{A}|\\mathbf{Z})] - D_{KL}[q(\\mathbf{Z}|\\mathbf{X},\\mathbf{A}) \\| p(\\mathbf{Z})]$\n- **Key Properties**: Probabilistic latent space, KL regularization, reparameterization trick\n- **Advantages**: Uncertainty quantification, robust embeddings, generative capability\n- **Limitations**: More complex training, additional hyperparameters (KL weight)\n\n### **Mathematical Insights**\n\n**Theoretical Comparison:**\n$$\\text{GAE} \\subset \\text{VGAE} \\text{ when } \\boldsymbol{\\sigma} \\rightarrow 0$$\n\n**Complexity Analysis:**\n- **GAE Parameters**: $O(d \\times h + h \\times k)$\n- **VGAE Parameters**: $O(d \\times h + 2h \\times k)$ (additional variance parameters)\n- **Computational Cost**: Both $O(|\\mathcal{E}| \\times d^2 + N \\times d^2)$ per epoch\n\n**Performance Trade-offs:**\n- **Link Prediction**: VGAE often slightly better due to regularization\n- **Node Clustering**: VGAE typically superior due to structured embedding space\n- **Computational Efficiency**: GAE faster due to simpler objective\n- **Memory Usage**: VGAE requires ~25% more memory for variance parameters\n\n### **Key Applications and Mathematical Formulations**\n\n**1. Link Prediction:**\n$$P(\\text{edge}_{ij} = 1) = \\sigma(\\mathbf{z}_i^T \\mathbf{z}_j)$$\n- Evaluation: AUC-ROC and Average Precision metrics\n- Challenge: Negative sampling strategy affects performance\n\n**2. Node Clustering:**\n$$\\text{Cluster Assignment} = \\arg\\min_{\\mathcal{C}} \\sum_{i=1}^k \\sum_{\\mathbf{z} \\in \\mathcal{C}_i} \\|\\mathbf{z} - \\boldsymbol{\\mu}_i\\|_2^2$$\n- Evaluation: ARI and NMI metrics\n- VGAE advantage: KL regularization promotes cluster-friendly embeddings\n\n**3. Graph Generation:**\n$$\\mathbf{Z}_{\\text{new}} \\sim p(\\mathbf{Z}) \\rightarrow \\mathbf{A}_{\\text{new}} = \\text{Decode}(\\mathbf{Z}_{\\text{new}})$$\n- Only feasible with VGAE due to probabilistic framework\n- Applications: Data augmentation, synthetic graph creation\n\n**4. Anomaly Detection:**\n$$\\text{Anomaly Score} = \\|\\mathbf{A} - \\hat{\\mathbf{A}}\\|_F^2$$\n- Both models applicable\n- VGAE provides uncertainty estimates for anomaly confidence\n\n### **Practical Guidelines**\n\n**Architecture Selection:**\n| Use Case | Recommended Model | Rationale |\n|----------|------------------|-----------|\n| **Simple Link Prediction** | GAE | Faster, easier to tune |\n| **Node Clustering** | VGAE | Better regularization |\n| **Graph Generation** | VGAE | Probabilistic sampling |\n| **Uncertainty Quantification** | VGAE | Variance parameters |\n| **Large-Scale Graphs** | GAE | Lower computational cost |\n\n**Hyperparameter Guidelines:**\n- **Embedding Dimension**: $k = 16-32$ for most applications\n- **Hidden Dimension**: $h = 32-64$ for CPU, $h = 128-256$ for GPU\n- **Learning Rate**: $\\alpha = 0.01$ with decay scheduling\n- **KL Weight (VGAE)**: $\\beta = 1.0$ with optional annealing\n\n### **Future Directions**\n\n**Mathematical Extensions:**\n- **Hierarchical Variational Autoencoders**: Multi-level latent representations\n- **Normalizing Flows**: More flexible posterior distributions\n- **Attention-based Decoders**: Beyond inner product similarity\n- **Dynamic Graph Autoencoders**: Temporal graph evolution\n\n**Next Notebook Preview:**\nThe next notebook will explore **Graph Transformers**, covering:\n- **Self-Attention on Graphs**: $\\text{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{softmax}\\left(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}}\\right)\\mathbf{V}$\n- **Positional Encodings**: Incorporating graph structural information\n- **Transformer Architectures**: Graph-specific modifications of transformer blocks\n\nThis mathematical foundation in graph autoencoders provides the necessary background for understanding more advanced graph neural network architectures and their applications in unsupervised learning scenarios."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}